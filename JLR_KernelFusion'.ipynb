{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c8ae3542",
      "metadata": {
        "id": "c8ae3542"
      },
      "source": [
        " JLR Triton/CUDA Demo (Fixed & Complete)\n",
        "**Complete pipeline**: GPU setup â†’ Kernel verification â†’ EvoNorm â†’ CNN training â†’ Profiling â†’ Reports\n",
        " Run cells in order! Each section builds on the previous."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96cd9131",
      "metadata": {
        "id": "96cd9131"
      },
      "source": [
        "## 0ï¸âƒ£ GPU Setup & Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e19e6da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e19e6da",
        "outputId": "4e70b4a5-018b-4466-adf1-b70376a93eb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… CUDA available: True\n",
            "ðŸŽ® GPU: Tesla T4\n",
            "ðŸ’¾ GPU Memory: 15.83 GB\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, torch\n",
        "print('âœ… CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    device_name = torch.cuda.get_device_name(0)\n",
        "    print(f'ðŸŽ® GPU: {device_name}')\n",
        "    print(f'ðŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n",
        "    os.system('nvidia-smi -L || true')\n",
        "else:\n",
        "    print('âš ï¸ WARNING: No CUDA GPU detected! Using CPU (will be slow)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16c9dec8",
      "metadata": {
        "id": "16c9dec8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ðŸ“¦ Install dependencies (uncomment if needed)\n",
        "# %pip install -q torch torchvision --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "# %pip install -q triton pandas matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e16bc921",
      "metadata": {
        "id": "e16bc921"
      },
      "source": [
        "## 1ï¸âƒ£ Imports, Setup, Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbffa9e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbffa9e5",
        "outputId": "8cfd78cc-80d0-4c13-eff2-ae6e71072e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”§ Device: cuda\n",
            "âœ… Directories created\n",
            "âœ… Utilities loaded\n"
          ]
        }
      ],
      "source": [
        "import os, math, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import triton\n",
        "import triton.language as tl\n",
        "import torch\n",
        "import time\n",
        "\n",
        "import time\n",
        "import torch\n",
        "\n",
        "def profile_time_and_memory(func, *args, repeat: int = 1, **kwargs):\n",
        "    \"\"\"\n",
        "    Run `func` multiple times, measure avg time (ms) and peak GPU memory (MB).\n",
        "    \"\"\"\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    result = None\n",
        "    t0 = time.perf_counter()\n",
        "    for _ in range(repeat):\n",
        "        result = func(*args, **kwargs)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    elapsed_ms = (time.perf_counter() - t0) * 1e3 / repeat\n",
        "    peak_mem_mb = torch.cuda.max_memory_allocated() / 1024**2\n",
        "    return result, elapsed_ms, peak_mem_mb\n",
        "\n",
        "\n",
        "\n",
        "# Seeds & device\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'ðŸ”§ Device: {device}')\n",
        "\n",
        "# Create directories\n",
        "os.makedirs('reports/demo_pack', exist_ok=True)\n",
        "os.makedirs('profiling/benchmark_results', exist_ok=True)\n",
        "os.makedirs('profiling/nsight_scripts', exist_ok=True)\n",
        "print('âœ… Directories created')\n",
        "\n",
        "# Safe display\n",
        "try:\n",
        "    from IPython.display import display\n",
        "except:\n",
        "    def display(x): print(x)\n",
        "\n",
        "def time_ms(fn, iters=60, warmup=10):\n",
        "    \"\"\"Measure average execution time in milliseconds\"\"\"\n",
        "    with torch.no_grad():\n",
        "        for _ in range(warmup):\n",
        "            fn()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        s = torch.cuda.Event(True)\n",
        "        e = torch.cuda.Event(True)\n",
        "        s.record()\n",
        "        for _ in range(iters):\n",
        "            fn()\n",
        "        e.record()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        return s.elapsed_time(e) / iters\n",
        "\n",
        "print('âœ… Utilities loaded')\n",
        "\n",
        "def analyze_performance_summary(bench_df):\n",
        "    \"\"\"Generate a comprehensive performance analysis summary\"\"\"\n",
        "    if 'speedup' not in bench_df.columns:\n",
        "        bench_df['speedup'] = bench_df['torch_ms'] / bench_df['triton_ms']\n",
        "\n",
        "    summary = {\n",
        "        'total_operations': len(bench_df),\n",
        "        'average_speedup': bench_df['speedup'].mean(),\n",
        "        'median_speedup': bench_df['speedup'].median(),\n",
        "        'max_speedup': bench_df['speedup'].max(),\n",
        "        'min_speedup': bench_df['speedup'].min(),\n",
        "        'triton_faster_count': (bench_df['speedup'] > 1).sum(),\n",
        "        'pytorch_faster_count': (bench_df['speedup'] < 1).sum(),\n",
        "        'break_even_count': (bench_df['speedup'] == 1).sum(),\n",
        "        'best_operation': bench_df.loc[bench_df['speedup'].idxmax(), 'op'],\n",
        "        'worst_operation': bench_df.loc[bench_df['speedup'].idxmin(), 'op']\n",
        "    }\n",
        "\n",
        "    return summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pj9aQa3as7z_",
      "metadata": {
        "id": "pj9aQa3as7z_"
      },
      "outputs": [],
      "source": [
        "# The profile_time_and_memory function in cell dbffa9e5 is the intended one for this notebook.\n",
        "# This redefinition is causing a TypeError in later cells due to the missing 'repeat' argument.\n",
        "# Removing this redefinition to ensure the correct function from dbffa9e5 is used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d53416de",
      "metadata": {
        "id": "d53416de"
      },
      "source": [
        "## 2ï¸âƒ£ Triton Kernels: ReLU, Sigmoid, Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3571eb12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3571eb12",
        "outputId": "bcae9e8b-5767-4adf-dfb5-d186a8bb8fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Basic kernels defined\n"
          ]
        }
      ],
      "source": [
        "\n",
        "@triton.jit\n",
        "def relu_kernel(x_ptr, y_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n",
        "    pid = tl.program_id(axis=0)\n",
        "    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offs < n_elements\n",
        "    x = tl.load(x_ptr + offs, mask=mask, other=0.0)\n",
        "    y = tl.maximum(x, 0.0)\n",
        "    tl.store(y_ptr + offs, y, mask=mask)\n",
        "\n",
        "def relu_triton(x):\n",
        "    assert x.is_cuda and x.is_contiguous()\n",
        "    y = torch.empty_like(x)\n",
        "    n = x.numel()\n",
        "    BLOCK = 1024\n",
        "    grid = lambda meta: (triton.cdiv(n, meta['BLOCK_SIZE']),)\n",
        "    relu_kernel[grid](x, y, n, BLOCK_SIZE=BLOCK)\n",
        "    return y\n",
        "\n",
        "@triton.jit\n",
        "def sigmoid_kernel(x_ptr, y_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n",
        "    pid = tl.program_id(axis=0)\n",
        "    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offs < n_elements\n",
        "    x = tl.load(x_ptr + offs, mask=mask, other=0.0)\n",
        "    y = 1.0 / (1.0 + tl.exp(-x))\n",
        "    tl.store(y_ptr + offs, y, mask=mask)\n",
        "\n",
        "def sigmoid_triton(x):\n",
        "    assert x.is_cuda and x.is_contiguous()\n",
        "    y = torch.empty_like(x)\n",
        "    n = x.numel()\n",
        "    grid = lambda meta: (triton.cdiv(n, meta['BLOCK_SIZE']),)\n",
        "    sigmoid_kernel[grid](x, y, n, BLOCK_SIZE=1024)\n",
        "    return y\n",
        "\n",
        "@triton.jit\n",
        "def softmax_rowwise_kernel(x_ptr, y_ptr, n_rows, n_cols,\n",
        "                           stride_xr, stride_xc, stride_yr, stride_yc,\n",
        "                           BLOCK_SIZE: tl.constexpr):\n",
        "    row_id = tl.program_id(axis=0)\n",
        "    cols = tl.arange(0, BLOCK_SIZE)\n",
        "    row_ptr_x = x_ptr + row_id * stride_xr\n",
        "    row_ptr_y = y_ptr + row_id * stride_yr\n",
        "    mask = cols < n_cols\n",
        "    x = tl.load(row_ptr_x + cols * stride_xc, mask=mask, other=-float('inf'))\n",
        "    x_max = tl.max(x, axis=0)\n",
        "    x = x - x_max\n",
        "    expx = tl.exp(x)\n",
        "    denom = tl.sum(expx, axis=0)\n",
        "    out = expx / denom\n",
        "    tl.store(row_ptr_y + cols * stride_yc, out, mask=mask)\n",
        "\n",
        "def softmax_triton_lastdim(x):\n",
        "    assert x.is_cuda and x.is_contiguous()\n",
        "    cols = x.shape[-1]\n",
        "    rows = x.numel() // cols\n",
        "    x2 = x.view(rows, cols)\n",
        "    y2 = torch.empty_like(x2)\n",
        "    BLOCK = 1024\n",
        "    assert cols <= BLOCK, f'Dims must be <= {BLOCK}'\n",
        "    grid = (rows,)\n",
        "    softmax_rowwise_kernel[grid](\n",
        "        x2, y2, rows, cols,\n",
        "        x2.stride(0), x2.stride(1), y2.stride(0), y2.stride(1),\n",
        "        BLOCK_SIZE=BLOCK\n",
        "    )\n",
        "    return y2.view_as(x)\n",
        "\n",
        "print('âœ… Basic kernels defined')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6db12e6d",
      "metadata": {
        "id": "6db12e6d"
      },
      "source": [
        "## 3ï¸âƒ£ Triton LayerNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "003d0d8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "003d0d8e",
        "outputId": "4dd39ecd-5efe-4d9e-8a68-e50039b7b0f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… LayerNorm kernel defined\n"
          ]
        }
      ],
      "source": [
        "\n",
        "@triton.jit\n",
        "def layernorm_fwd_kernel(x_ptr, y_ptr, gamma_ptr, beta_ptr,\n",
        "                         n_rows, n_cols,\n",
        "                         stride_xr, stride_xc, stride_yr, stride_yc,\n",
        "                         eps: tl.constexpr, BLOCK_SIZE: tl.constexpr):\n",
        "    row = tl.program_id(0)\n",
        "    cols = tl.arange(0, BLOCK_SIZE)\n",
        "    mask = cols < n_cols\n",
        "    x_row = x_ptr + row * stride_xr + cols * stride_xc\n",
        "    y_row = y_ptr + row * stride_yr + cols * stride_yc\n",
        "    x = tl.load(x_row, mask=mask, other=0.0).to(tl.float32)\n",
        "    m = tl.sum(x, axis=0) / n_cols\n",
        "    xc = x - m\n",
        "    v = tl.sum(xc * xc, axis=0) / n_cols\n",
        "    inv = tl.rsqrt(v + eps)\n",
        "    gamma = tl.load(gamma_ptr + cols, mask=mask, other=1.0).to(tl.float32)\n",
        "    beta = tl.load(beta_ptr + cols, mask=mask, other=0.0).to(tl.float32)\n",
        "    y = (xc * inv) * gamma + beta\n",
        "    tl.store(y_row, y, mask=mask)\n",
        "\n",
        "def layernorm_triton(x, gamma, beta, eps=1e-5):\n",
        "    assert x.is_cuda and x.is_contiguous()\n",
        "    cols = x.shape[-1]\n",
        "    rows = x.numel() // cols\n",
        "    x2 = x.view(rows, cols).contiguous()\n",
        "    y2 = torch.empty_like(x2)\n",
        "    BLOCK = 1 << (cols - 1).bit_length()\n",
        "    BLOCK = min(BLOCK, 4096)\n",
        "    grid = (rows,)\n",
        "    layernorm_fwd_kernel[grid](\n",
        "        x2, y2, gamma, beta, rows, cols,\n",
        "        x2.stride(0), x2.stride(1), y2.stride(0), y2.stride(1),\n",
        "        eps=eps, BLOCK_SIZE=BLOCK\n",
        "    )\n",
        "    return y2.view_as(x)\n",
        "\n",
        "print('âœ… LayerNorm kernel defined')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3afe1d0",
      "metadata": {
        "id": "c3afe1d0"
      },
      "source": [
        "## ðŸ§ª VERIFICATION: Test Kernel Correctness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aca5e0e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aca5e0e2",
        "outputId": "a56fa18f-bd2a-4115-bf9e-e596561a94fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ§ª Testing Kernel Correctness...\n",
            "\n",
            "âœ… ReLU            | Max diff: 0.00e+00 | Match: True\n",
            "âœ… Sigmoid         | Max diff: 1.79e-07 | Match: True\n",
            "âœ… Softmax         | Max diff: 1.49e-08 | Match: True\n",
            "âœ… LayerNorm       | Max diff: 7.15e-07 | Match: True\n",
            "\n",
            "âœ… Verification complete!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print('\\nðŸ§ª Testing Kernel Correctness...\\n')\n",
        "\n",
        "def test_kernel(name, triton_fn, torch_fn, x, *args, rtol=1e-4, atol=1e-5):\n",
        "    \"\"\"Test if triton kernel matches PyTorch\"\"\"\n",
        "    try:\n",
        "        y_triton = triton_fn(x, *args)\n",
        "        y_torch = torch_fn(x, *args)\n",
        "        match = torch.allclose(y_triton, y_torch, rtol=rtol, atol=atol)\n",
        "        max_diff = (y_triton - y_torch).abs().max().item()\n",
        "        status = 'âœ…' if match else 'âŒ'\n",
        "        print(f'{status} {name:15s} | Max diff: {max_diff:.2e} | Match: {match}')\n",
        "        return match\n",
        "    except Exception as e:\n",
        "        print(f'âŒ {name:15s} | ERROR: {e}')\n",
        "        return False\n",
        "\n",
        "x_test = torch.randn(128, 256, device=device, dtype=torch.float32)\n",
        "\n",
        "test_kernel('ReLU', relu_triton, lambda x: F.relu(x), x_test)\n",
        "test_kernel('Sigmoid', sigmoid_triton, lambda x: torch.sigmoid(x), x_test)\n",
        "test_kernel('Softmax', softmax_triton_lastdim, lambda x: F.softmax(x, dim=-1), x_test)\n",
        "\n",
        "gamma = torch.ones(256, device=device, dtype=torch.float32)\n",
        "beta = torch.zeros(256, device=device, dtype=torch.float32)\n",
        "test_kernel('LayerNorm',\n",
        "            lambda x, g, b: layernorm_triton(x, g, b),\n",
        "            lambda x, g, b: F.layer_norm(x, (256,), g, b),\n",
        "            x_test, gamma, beta)\n",
        "\n",
        "print('\\nâœ… Verification complete!\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "417c9bd8",
      "metadata": {
        "id": "417c9bd8"
      },
      "source": [
        "## 4ï¸âƒ£ EvoNorm-B0 (Reference, Apply, Fused)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4071cee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4071cee",
        "outputId": "1b174e9c-217a-4495-8629-6be4eb8c2fcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… EvoNorm-B0 kernels defined\n"
          ]
        }
      ],
      "source": [
        "def evonorm_b0_reference(x, v, groups=32, eps=1e-5):\n",
        "    \"\"\"PyTorch reference implementation (NCHW)\"\"\"\n",
        "    assert x.dim() == 4, \"Expected NCHW\"\n",
        "    N, C, H, W = x.shape\n",
        "    assert C % groups == 0\n",
        "    v = v.view(1, C, 1, 1)\n",
        "    Cg = C // groups\n",
        "    xg = x.view(N, groups, Cg, H, W)\n",
        "    var = xg.var(dim=(2,3,4), unbiased=False, keepdim=True)\n",
        "    inv_std = torch.rsqrt(var + eps).expand(N, groups, Cg, H, W).reshape(N, C, H, W)\n",
        "    return x * torch.sigmoid(v * x) * inv_std\n",
        "\n",
        "@triton.jit\n",
        "def evonorm_b0_fused_kernel(\n",
        "    x_ptr, v_ptr, y_ptr, N, C, H, W, groups,\n",
        "    eps: tl.constexpr, BLOCK: tl.constexpr,\n",
        "):\n",
        "    pid = tl.program_id(0)\n",
        "    g = pid % groups\n",
        "    n = pid // groups\n",
        "    Cg = C // groups\n",
        "    HW = H * W\n",
        "    group_elems = Cg * HW\n",
        "    base = n * (C * HW) + g * (Cg * HW)\n",
        "\n",
        "    # Pass 1: Compute variance\n",
        "    acc1 = tl.zeros([1], dtype=tl.float32)\n",
        "    acc2 = tl.zeros([1], dtype=tl.float32)\n",
        "    offs = tl.arange(0, BLOCK)\n",
        "    for start in range(0, group_elems, BLOCK):\n",
        "        idx = base + start + offs\n",
        "        mask = (start + offs) < group_elems\n",
        "        x = tl.load(x_ptr + idx, mask=mask, other=0.0).to(tl.float32)\n",
        "        acc1 += tl.sum(x, axis=0)\n",
        "        acc2 += tl.sum(x * x, axis=0)\n",
        "\n",
        "    ge = tl.full([1], group_elems, dtype=tl.float32)\n",
        "    mean = acc1 / ge\n",
        "    var = acc2 / ge - mean * mean\n",
        "    inv = 1.0 / tl.sqrt(var + eps)\n",
        "\n",
        "    # Pass 2: Apply normalization\n",
        "    for start in range(0, group_elems, BLOCK):\n",
        "        idx = base + start + offs\n",
        "        mask = (start + offs) < group_elems\n",
        "        x = tl.load(x_ptr + idx, mask=mask, other=0.0).to(tl.float32)\n",
        "        rel = start + offs\n",
        "        c_in_group = rel // HW\n",
        "        c_global = g * Cg + c_in_group\n",
        "        v = tl.load(v_ptr + c_global, mask=mask, other=0.0).to(tl.float32)\n",
        "        sig = 1.0 / (1.0 + tl.exp(-(v * x)))\n",
        "        y = x * sig * inv\n",
        "        tl.store(y_ptr + idx, y, mask=mask)\n",
        "\n",
        "def evonorm_b0_triton_fused(x, v, groups=32, eps=1e-5):\n",
        "    assert x.is_cuda and v.is_cuda\n",
        "    N, C, H, W = x.shape\n",
        "    assert C % groups == 0\n",
        "    x = x.contiguous()\n",
        "    y = torch.empty_like(x)\n",
        "    Cg = C // groups\n",
        "    # Calculate group elements and find the next power of 2 for the block size\n",
        "    group_elems = Cg * H * W\n",
        "    BLOCK = int(2**math.ceil(math.log2(group_elems)))\n",
        "    # Limit the BLOCK size to 1024 as a reasonable maximum\n",
        "    BLOCK = min(BLOCK, 1024)\n",
        "    grid = (N * groups,)\n",
        "    evonorm_b0_fused_kernel[grid](\n",
        "        x.view(-1), v, y.view(-1), N, C, H, W, groups,\n",
        "        eps=eps, BLOCK=BLOCK\n",
        "    )\n",
        "    return y\n",
        "\n",
        "print('âœ… EvoNorm-B0 kernels defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d437ab9a",
      "metadata": {
        "id": "d437ab9a"
      },
      "source": [
        "## ðŸ§ª VERIFICATION: Test EvoNorm Correctness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc8d98a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc8d98a4",
        "outputId": "5abeb535-ad41-47f9-e39b-0a0bd2df3689"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ§ª Testing EvoNorm-B0...\n",
            "\n",
            "âœ… EvoNorm-B0 Fused | Max diff: 9.54e-07 | Match: True\n",
            "âœ… EvoNorm verification complete!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('\\nðŸ§ª Testing EvoNorm-B0...\\n')\n",
        "x_ev = torch.randn(2, 32, 28, 28, device=device, dtype=torch.float32)\n",
        "v_ev = torch.randn(32, device=device, dtype=torch.float32)\n",
        "\n",
        "y_ref = evonorm_b0_reference(x_ev, v_ev, groups=32)\n",
        "y_fused = evonorm_b0_triton_fused(x_ev, v_ev, groups=32)\n",
        "\n",
        "match = torch.allclose(y_ref, y_fused, rtol=1e-3, atol=1e-4)\n",
        "max_diff = (y_ref - y_fused).abs().max().item()\n",
        "\n",
        "status = 'âœ…' if match else 'âŒ'\n",
        "print(f'{status} EvoNorm-B0 Fused | Max diff: {max_diff:.2e} | Match: {match}')\n",
        "print('âœ… EvoNorm verification complete!\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa22159e",
      "metadata": {
        "id": "aa22159e"
      },
      "source": [
        "## 5ï¸âƒ£ Conv + EvoNorm Fused Epilogue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74635dbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74635dbc",
        "outputId": "fd461513-6233-4fde-9dad-c6b8bb31decf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Conv+EvoNorm fused epilogue defined\n"
          ]
        }
      ],
      "source": [
        "@triton.jit\n",
        "def conv_evonorm_epilogue_kernel(\n",
        "    y_in_ptr, bias_ptr, v_ptr, y_out_ptr,\n",
        "    N, C, H, W, groups,\n",
        "    use_bias: tl.constexpr, eps: tl.constexpr, BLOCK: tl.constexpr,\n",
        "):\n",
        "    pid = tl.program_id(axis=0)\n",
        "    g = pid % groups\n",
        "    n = pid // groups\n",
        "    Cg = C // groups\n",
        "    HW = H * W\n",
        "    group_elems = Cg * HW\n",
        "    base = n * (C * HW) + g * (Cg * HW)\n",
        "\n",
        "    # Pass 1: Compute variance (on bias-corrected values if bias exists)\n",
        "    s1 = tl.zeros([1], dtype=tl.float32)\n",
        "    s2 = tl.zeros([1], dtype=tl.float32)\n",
        "    offs = tl.arange(0, BLOCK)\n",
        "\n",
        "    for start in range(0, group_elems, BLOCK):\n",
        "        idx = base + start + offs\n",
        "        mask = (start + offs) < group_elems\n",
        "        x = tl.load(y_in_ptr + idx, mask=mask, other=0.0).to(tl.float32)\n",
        "\n",
        "        # Add bias for statistics computation\n",
        "        if use_bias:\n",
        "            rel = start + offs\n",
        "            c_in_group = rel // HW\n",
        "            c_global = g * Cg + c_in_group\n",
        "            b = tl.load(bias_ptr + c_global, mask=mask, other=0.0).to(tl.float32)\n",
        "            x = x + b\n",
        "\n",
        "        s1 += tl.sum(x, axis=0)\n",
        "        s2 += tl.sum(x * x, axis=0)\n",
        "\n",
        "    ge = tl.full([1], group_elems, dtype=tl.float32)\n",
        "    mean = s1 / ge\n",
        "    var = s2 / ge - mean * mean\n",
        "    inv = 1.0 / tl.sqrt(var + eps)\n",
        "\n",
        "    # Pass 2: Apply EvoNorm (using same bias-corrected x)\n",
        "    for start in range(0, group_elems, BLOCK):\n",
        "        idx = base + start + offs\n",
        "        mask = (start + offs) < group_elems\n",
        "\n",
        "        # Load conv output\n",
        "        x = tl.load(y_in_ptr + idx, mask=mask, other=0.0).to(tl.float32)\n",
        "\n",
        "        rel = start + offs\n",
        "        c_in_group = rel // HW\n",
        "        c_global = g * Cg + c_in_group\n",
        "\n",
        "        # Add bias (same as pass 1)\n",
        "        if use_bias:\n",
        "            b = tl.load(bias_ptr + c_global, mask=mask, other=0.0).to(tl.float32)\n",
        "            x = x + b\n",
        "\n",
        "        # EvoNorm: x * sigmoid(v * x) * inv_std\n",
        "        v_val = tl.load(v_ptr + c_global, mask=mask, other=0.0).to(tl.float32)\n",
        "        sig = 1.0 / (1.0 + tl.exp(-v_val * x))\n",
        "        y = x * sig * inv\n",
        "\n",
        "        tl.store(y_out_ptr + idx, y, mask=mask)\n",
        "\n",
        "def triton_conv_evonorm_epilogue(y_conv, v, bias=None, groups=32, eps=1e-5):\n",
        "    assert y_conv.is_cuda\n",
        "    N, C, H, W = y_conv.shape\n",
        "    assert C % groups == 0\n",
        "    y_conv = y_conv.contiguous()\n",
        "    y_out = torch.empty_like(y_conv)\n",
        "    Cg = C // groups\n",
        "    group_elems = Cg * H * W\n",
        "    assert group_elems > 0, \"group_elems must be > 0, check H/W and groups\"\n",
        "\n",
        "    BLOCK = 1\n",
        "    while BLOCK < group_elems:\n",
        "        BLOCK <<= 1\n",
        "    BLOCK = max(32, min(BLOCK, 1024))\n",
        "\n",
        "\n",
        "    grid = (N * groups,)\n",
        "    use_bias = 1 if (bias is not None) else 0\n",
        "    bias_ptr = bias if bias is not None else y_conv.new_empty(1)\n",
        "    conv_evonorm_epilogue_kernel[grid](\n",
        "        y_conv.view(-1), bias_ptr, v, y_out.view(-1),\n",
        "        N, C, H, W, groups,\n",
        "        use_bias=use_bias, eps=eps, BLOCK=BLOCK\n",
        "    )\n",
        "    return y_out\n",
        "\n",
        "print('âœ… Conv+EvoNorm fused epilogue defined')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IKMAKuWH2FUG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKMAKuWH2FUG",
        "outputId": "f9d3b1f7-bb76-455b-cd9d-b67e3dbfa9d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Autograd wrapper: evonorm_b0_triton_autograd\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.autograd import Function\n",
        "\n",
        "class _EvoNormB0EpilogueFn(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, v, bias=None, groups: int = 32, eps: float = 1e-5):\n",
        "        # Use existing fast Triton forward\n",
        "        y = triton_conv_evonorm_epilogue(x, v, bias=bias, groups=groups, eps=eps)\n",
        "        # Save for backward\n",
        "        ctx.groups = groups\n",
        "        ctx.eps = eps\n",
        "        ctx.have_bias = bias is not None\n",
        "        if bias is None:\n",
        "            bias = torch.zeros(x.shape[1], device=x.device, dtype=x.dtype)\n",
        "        ctx.save_for_backward(x, v, bias)\n",
        "        return y\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_y):\n",
        "        groups = ctx.groups\n",
        "        eps = ctx.eps\n",
        "        have_bias = ctx.have_bias\n",
        "        x, v, bias = ctx.saved_tensors\n",
        "\n",
        "        # Recompute y with PyTorch ops and get dL/dx, dL/dv, dL/db via autograd\n",
        "        with torch.enable_grad():\n",
        "            x_ = x.detach().requires_grad_(True)\n",
        "            v_ = v.detach().requires_grad_(True)\n",
        "            b_ = bias.detach().requires_grad_(True)\n",
        "\n",
        "            z = x_ + b_.view(1, -1, 1, 1)\n",
        "            # Reference EvoNorm-B0 (same as your cell #13)\n",
        "            N, C, H, W = z.shape\n",
        "            Cg = C // groups\n",
        "            xg = z.view(N, groups, Cg, H, W)\n",
        "            var = xg.var(dim=(2,3,4), unbiased=False, keepdim=True)\n",
        "            inv_std = torch.rsqrt(var + eps).expand(N, groups, Cg, H, W).reshape(N, C, H, W)\n",
        "            y_ref = z * torch.sigmoid(v_.view(1, C, 1, 1) * z) * inv_std\n",
        "\n",
        "            grads = torch.autograd.grad(y_ref, (x_, v_, b_), grad_y, allow_unused=True)\n",
        "            grad_x = grads[0]\n",
        "            grad_v = grads[1]\n",
        "            grad_b = grads[2] if have_bias else None\n",
        "\n",
        "        # Return grads aligned to inputs of apply: (x, v, bias, groups, eps)\n",
        "        return grad_x, grad_v, grad_b, None, None\n",
        "\n",
        "def evonorm_b0_triton_autograd(x, v, bias=None, groups=32, eps=1e-5):\n",
        "    return _EvoNormB0EpilogueFn.apply(x, v, bias, groups, eps)\n",
        "\n",
        "print(\"âœ… Autograd wrapper: evonorm_b0_triton_autograd\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bvB2JDHPrFUI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvB2JDHPrFUI",
        "outputId": "0375ac43-2712-4cee-a0cf-7695b8e58cdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max diff: 9.54e-07\n",
            "Mean diff: 2.70e-08\n"
          ]
        }
      ],
      "source": [
        "# Numerical test\n",
        "torch.manual_seed(42)\n",
        "x = torch.randn(2, 32, 28, 28, device='cuda')\n",
        "v = torch.randn(32, device='cuda')\n",
        "\n",
        "# Reference\n",
        "ref = evonorm_b0_reference(x, v, groups=32)\n",
        "\n",
        "# Your fused version (after replacing the kernel)\n",
        "fused = triton_conv_evonorm_epilogue(x, v, bias=None, groups=32)\n",
        "\n",
        "print(f\"Max diff: {(ref - fused).abs().max().item():.2e}\")\n",
        "print(f\"Mean diff: {(ref - fused).abs().mean().item():.2e}\")\n",
        "\n",
        "# Should be < 1e-5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43c14a19",
      "metadata": {
        "id": "43c14a19"
      },
      "source": [
        "## 6ï¸âƒ£ Minimal CNN (MNIST) + EvoNorm epilogue & Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01a7bad7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "01a7bad7",
        "outputId": "add46c17-afa7-461a-d23c-815895b1d367"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 59.8MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 1.64MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 14.6MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 8.95MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â± Training Reference for 10 epochs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Reference] Epoch 01/10  train_loss=0.1105  train_acc=0.9655  test_loss=0.0495  test_acc=0.9835  (16.89s)\n",
            "[Reference] Epoch 02/10  train_loss=0.0352  train_acc=0.9891  test_loss=0.0503  test_acc=0.9844  (16.85s)\n",
            "[Reference] Epoch 03/10  train_loss=0.0228  train_acc=0.9928  test_loss=0.0287  test_acc=0.9911  (15.66s)\n",
            "[Reference] Epoch 04/10  train_loss=0.0157  train_acc=0.9950  test_loss=0.0341  test_acc=0.9898  (15.72s)\n",
            "[Reference] Epoch 05/10  train_loss=0.0124  train_acc=0.9958  test_loss=0.0317  test_acc=0.9911  (16.10s)\n",
            "[Reference] Epoch 06/10  train_loss=0.0107  train_acc=0.9967  test_loss=0.0362  test_acc=0.9911  (15.59s)\n",
            "[Reference] Epoch 07/10  train_loss=0.0079  train_acc=0.9973  test_loss=0.0392  test_acc=0.9907  (16.54s)\n",
            "[Reference] Epoch 08/10  train_loss=0.0072  train_acc=0.9978  test_loss=0.0319  test_acc=0.9909  (15.49s)\n",
            "[Reference] Epoch 09/10  train_loss=0.0083  train_acc=0.9973  test_loss=0.0335  test_acc=0.9923  (15.35s)\n",
            "[Reference] Epoch 10/10  train_loss=0.0059  train_acc=0.9981  test_loss=0.0423  test_acc=0.9891  (15.95s)\n",
            "âœ… Saved: profiling/benchmark_results/mnist_reference_learning_curve.csv\n",
            "\n",
            "â± Training Fused for 10 epochs...\n",
            "[Fused] Epoch 01/10  train_loss=0.1158  train_acc=0.9644  test_loss=0.0374  test_acc=0.9872  (15.84s)\n",
            "[Fused] Epoch 02/10  train_loss=0.0347  train_acc=0.9894  test_loss=0.0357  test_acc=0.9895  (15.50s)\n",
            "[Fused] Epoch 03/10  train_loss=0.0242  train_acc=0.9919  test_loss=0.0384  test_acc=0.9887  (15.48s)\n",
            "[Fused] Epoch 04/10  train_loss=0.0150  train_acc=0.9954  test_loss=0.0342  test_acc=0.9893  (16.33s)\n",
            "[Fused] Epoch 05/10  train_loss=0.0119  train_acc=0.9960  test_loss=0.0319  test_acc=0.9909  (17.99s)\n",
            "[Fused] Epoch 06/10  train_loss=0.0104  train_acc=0.9965  test_loss=0.0327  test_acc=0.9909  (17.11s)\n",
            "[Fused] Epoch 07/10  train_loss=0.0096  train_acc=0.9969  test_loss=0.0300  test_acc=0.9921  (18.01s)\n",
            "[Fused] Epoch 08/10  train_loss=0.0079  train_acc=0.9971  test_loss=0.0302  test_acc=0.9918  (17.15s)\n",
            "[Fused] Epoch 09/10  train_loss=0.0086  train_acc=0.9969  test_loss=0.0432  test_acc=0.9885  (17.24s)\n",
            "[Fused] Epoch 10/10  train_loss=0.0065  train_acc=0.9979  test_loss=0.0313  test_acc=0.9923  (17.45s)\n",
            "âœ… Saved: profiling/benchmark_results/mnist_fused_learning_curve.csv\n",
            "\n",
            "ðŸ”¥ Training Reference with Focal Loss for 10 epochs...\n",
            "[Reference_Focal] Epoch 01/10  train_loss=0.0690  train_acc=0.9595  test_loss=0.0946  test_acc=0.9803  (16.77s)\n",
            "[Reference_Focal] Epoch 02/10  train_loss=0.0167  train_acc=0.9869  test_loss=0.0613  test_acc=0.9874  (17.12s)\n",
            "[Reference_Focal] Epoch 03/10  train_loss=0.0105  train_acc=0.9912  test_loss=0.0716  test_acc=0.9844  (17.08s)\n",
            "[Reference_Focal] Epoch 04/10  train_loss=0.0079  train_acc=0.9931  test_loss=0.0417  test_acc=0.9893  (17.45s)\n",
            "[Reference_Focal] Epoch 05/10  train_loss=0.0058  train_acc=0.9949  test_loss=0.0515  test_acc=0.9859  (17.01s)\n",
            "[Reference_Focal] Epoch 06/10  train_loss=0.0052  train_acc=0.9951  test_loss=0.0523  test_acc=0.9866  (18.25s)\n",
            "[Reference_Focal] Epoch 07/10  train_loss=0.0031  train_acc=0.9970  test_loss=0.0338  test_acc=0.9902  (17.24s)\n",
            "[Reference_Focal] Epoch 08/10  train_loss=0.0041  train_acc=0.9959  test_loss=0.0380  test_acc=0.9883  (18.18s)\n",
            "[Reference_Focal] Epoch 09/10  train_loss=0.0044  train_acc=0.9961  test_loss=0.0345  test_acc=0.9892  (16.98s)\n",
            "[Reference_Focal] Epoch 10/10  train_loss=0.0041  train_acc=0.9962  test_loss=0.0357  test_acc=0.9879  (17.92s)\n",
            "âœ… Saved: profiling/benchmark_results/mnist_reference_focal_learning_curve.csv\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ”¥ Training Reference with Focal Loss for 10 epochs...\n",
            "[Reference_Focal] Epoch 01/10  train_loss=0.0673  train_acc=0.9607  test_loss=0.0727  test_acc=0.9852  (16.53s)\n",
            "[Reference_Focal] Epoch 02/10  train_loss=0.0155  train_acc=0.9884  test_loss=0.0666  test_acc=0.9884  (17.10s)\n",
            "[Reference_Focal] Epoch 03/10  train_loss=0.0092  train_acc=0.9921  test_loss=0.0509  test_acc=0.9863  (16.09s)\n",
            "[Reference_Focal] Epoch 04/10  train_loss=0.0076  train_acc=0.9933  test_loss=0.0468  test_acc=0.9892  (17.46s)\n",
            "[Reference_Focal] Epoch 05/10  train_loss=0.0065  train_acc=0.9943  test_loss=0.0385  test_acc=0.9902  (16.39s)\n",
            "[Reference_Focal] Epoch 06/10  train_loss=0.0046  train_acc=0.9955  test_loss=0.0351  test_acc=0.9912  (18.22s)\n",
            "[Reference_Focal] Epoch 07/10  train_loss=0.0040  train_acc=0.9963  test_loss=0.0397  test_acc=0.9896  (16.84s)\n",
            "[Reference_Focal] Epoch 08/10  train_loss=0.0044  train_acc=0.9958  test_loss=0.0304  test_acc=0.9902  (18.13s)\n",
            "[Reference_Focal] Epoch 09/10  train_loss=0.0046  train_acc=0.9954  test_loss=0.0304  test_acc=0.9902  (17.22s)\n",
            "[Reference_Focal] Epoch 10/10  train_loss=0.0028  train_acc=0.9969  test_loss=0.0395  test_acc=0.9875  (17.95s)\n",
            "âœ… Saved: profiling/benchmark_results/mnist_reference_focal_learning_curve.csv\n",
            "[overfit-512] e1 loss=0.076 acc=0.984\n",
            "[overfit-512] e2 loss=0.049 acc=0.982\n",
            "[overfit-512] e3 loss=0.021 acc=0.992\n",
            "[overfit-512] e4 loss=0.009 acc=0.994\n",
            "[overfit-512] e5 loss=0.009 acc=0.994\n",
            "âœ“ Weights match: conv=True, v1=True, b1=True, fc_weight=True\n",
            "â± Training 1 epoch each (quick demo) ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"timings\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Fused\",\n          \"Reference\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0570851075017331,\n        \"min\": 16.673448085784912,\n        \"max\": 18.168392181396484,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          18.168392181396484,\n          16.673448085784912\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009058240435873483,\n        \"min\": 0.007769173121483375,\n        \"max\": 0.00905020176904824,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.00905020176904824,\n          0.007769173121483375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00021213203435594088,\n        \"min\": 0.9971166666666667,\n        \"max\": 0.9974166666666666,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.9971166666666667,\n          0.9974166666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005711638161323343,\n        \"min\": 0.037235866105919106,\n        \"max\": 0.045313342257030306,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.037235866105919106,\n          0.045313342257030306\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0015556349186103902,\n        \"min\": 0.9895,\n        \"max\": 0.9917,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.9917,\n          0.9895\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "timings"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-26472152-0272-4850-9744-e06263529231\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>train_sec</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_acc</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reference</td>\n",
              "      <td>16.673448</td>\n",
              "      <td>0.007769</td>\n",
              "      <td>0.997417</td>\n",
              "      <td>0.045313</td>\n",
              "      <td>0.9895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fused</td>\n",
              "      <td>18.168392</td>\n",
              "      <td>0.009050</td>\n",
              "      <td>0.997117</td>\n",
              "      <td>0.037236</td>\n",
              "      <td>0.9917</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26472152-0272-4850-9744-e06263529231')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-26472152-0272-4850-9744-e06263529231 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-26472152-0272-4850-9744-e06263529231');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e05117c7-76d7-4abd-8f7b-386bb5745a14\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e05117c7-76d7-4abd-8f7b-386bb5745a14')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e05117c7-76d7-4abd-8f7b-386bb5745a14 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_fbea4382-cd15-4bb0-809d-1c4b10d7bd2c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('timings')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fbea4382-cd15-4bb0-809d-1c4b10d7bd2c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('timings');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       model  train_sec  train_loss  train_acc  test_loss  test_acc\n",
              "0  Reference  16.673448    0.007769   0.997417   0.045313    0.9895\n",
              "1      Fused  18.168392    0.009050   0.997117   0.037236    0.9917"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: profiling/benchmark_results/mnist_evonorm_timings.csv\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "import triton\n",
        "import triton.language as tl\n",
        "import math\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-class Focal Loss for classification.\n",
        "    logits: (N, C), targets: (N,) with class indices\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha: float = 1.0, gamma: float = 2.0, reduction: str = \"mean\"):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        # Cross-entropy per sample, no reduction\n",
        "        ce = F.cross_entropy(logits, targets, reduction=\"none\")  # (N,)\n",
        "\n",
        "        # p_t = probability of the true class\n",
        "        pt = torch.exp(-ce)  # (N,)\n",
        "\n",
        "        # Focal Loss scaling\n",
        "        focal = self.alpha * (1.0 - pt) ** self.gamma * ce  # (N,)\n",
        "\n",
        "        if self.reduction == \"mean\":\n",
        "            return focal.mean()\n",
        "        elif self.reduction == \"sum\":\n",
        "            return focal.sum()\n",
        "        else:\n",
        "            return focal\n",
        "\n",
        "\n",
        "# --- Definitions from cell 74635dbc (Conv + EvoNorm Fused Epilogue) ---\n",
        "@triton.jit\n",
        "def conv_evonorm_epilogue_kernel(\n",
        "    y_in_ptr, bias_ptr, v_ptr, y_out_ptr,\n",
        "    N, C, H, W, groups,\n",
        "    use_bias: tl.constexpr, eps: tl.constexpr, BLOCK: tl.constexpr,\n",
        "):\n",
        "    pid = tl.program_id(0)\n",
        "    g = pid % groups\n",
        "    n = pid // groups\n",
        "    Cg = C // groups\n",
        "    HW = H * W\n",
        "    group_elems = Cg * HW\n",
        "    base = n * (C * HW) + g * (Cg * HW)\n",
        "\n",
        "    # Pass 1: Compute variance (on bias-corrected values if bias exists)\n",
        "    s1 = tl.zeros([1], dtype=tl.float32)\n",
        "    s2 = tl.zeros([1], dtype=tl.float32)\n",
        "    offs = tl.arange(0, BLOCK)\n",
        "\n",
        "    for start in range(0, group_elems, BLOCK):\n",
        "        idx = base + start + offs\n",
        "        mask = (start + offs) < group_elems\n",
        "        x = tl.load(y_in_ptr + idx, mask=mask, other=0.0).to(tl.float32)\n",
        "\n",
        "        # Add bias for statistics computation\n",
        "        if use_bias:\n",
        "            rel = start + offs\n",
        "            c_in_group = rel // HW\n",
        "            c_global = g * Cg + c_in_group\n",
        "            b = tl.load(bias_ptr + c_global, mask=mask, other=0.0).to(tl.float32)\n",
        "            x = x + b\n",
        "\n",
        "        s1 += tl.sum(x, axis=0)\n",
        "        s2 += tl.sum(x * x, axis=0)\n",
        "\n",
        "    ge = tl.full([1], group_elems, dtype=tl.float32)\n",
        "    mean = s1 / ge\n",
        "    var = s2 / ge - mean * mean\n",
        "    inv = 1.0 / tl.sqrt(var + eps)\n",
        "\n",
        "    # Pass 2: Apply EvoNorm (using same bias-corrected x)\n",
        "    for start in range(0, group_elems, BLOCK):\n",
        "        idx = base + start + offs\n",
        "        mask = (start + offs) < group_elems\n",
        "\n",
        "        # Load conv output\n",
        "        x = tl.load(y_in_ptr + idx, mask=mask, other=0.0).to(tl.float32)\n",
        "\n",
        "        rel = start + offs\n",
        "        c_in_group = rel // HW\n",
        "        c_global = g * Cg + c_in_group\n",
        "\n",
        "        # Add bias (same as pass 1)\n",
        "        if use_bias:\n",
        "            b = tl.load(bias_ptr + c_global, mask=mask, other=0.0).to(tl.float32)\n",
        "            x = x + b\n",
        "\n",
        "        # EvoNorm: x * sigmoid(v * x) * inv_std\n",
        "        v_val = tl.load(v_ptr + c_global, mask=mask, other=0.0).to(tl.float32)\n",
        "        sig = 1.0 / (1.0 + tl.exp(-v_val * x))\n",
        "        y = x * sig * inv\n",
        "\n",
        "        tl.store(y_out_ptr + idx, y, mask=mask)\n",
        "\n",
        "def triton_conv_evonorm_epilogue(y_conv, v, bias=None, groups=32, eps=1e-5):\n",
        "    assert y_conv.is_cuda\n",
        "    N, C, H, W = y_conv.shape\n",
        "    assert C % groups == 0\n",
        "    y_conv = y_conv.contiguous()\n",
        "    y_out = torch.empty_like(y_conv)\n",
        "    Cg = C // groups\n",
        "    group_elems = Cg * H * W\n",
        "    # Calculate BLOCK as the smallest power of 2 greater than or equal to group_elems,\n",
        "    # up to a reasonable maximum like 1024.\n",
        "    BLOCK = 1\n",
        "    while BLOCK < group_elems:\n",
        "        BLOCK *= 2\n",
        "    BLOCK = min(BLOCK, 1024)\n",
        "\n",
        "    grid = (N * groups,)\n",
        "    use_bias = 1 if (bias is not None) else 0\n",
        "    bias_ptr = bias if bias is not None else y_conv.new_empty(1)\n",
        "    conv_evonorm_epilogue_kernel[grid](\n",
        "        y_conv.view(-1), bias_ptr, v, y_out.view(-1),\n",
        "        N, C, H, W, groups,\n",
        "        use_bias=use_bias, eps=eps, BLOCK=BLOCK\n",
        "    )\n",
        "    return y_out\n",
        "# --- End of definitions from cell 74635dbc ---\n",
        "\n",
        "# --- Definitions from cell IKMAKuWH2FUG (Autograd wrapper for EvoNorm) ---\n",
        "_k = 0.7978845608028654 # sqrt(2/pi) - copied from gelu_tanh_kernel for consistency\n",
        "\n",
        "class _EvoNormB0EpilogueFn(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, v, bias=None, groups: int = 32, eps: float = 1e-5):\n",
        "        # Use existing fast Triton forward\n",
        "        y = triton_conv_evonorm_epilogue(x, v, bias=bias, groups=groups, eps=eps)\n",
        "        # Save for backward\n",
        "        ctx.groups = groups\n",
        "        ctx.eps = eps\n",
        "        ctx.have_bias = bias is not None\n",
        "        if bias is None:\n",
        "            bias = torch.zeros(x.shape[1], device=x.device, dtype=x.dtype)\n",
        "        ctx.save_for_backward(x, v, bias)\n",
        "        return y\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_y):\n",
        "        groups = ctx.groups\n",
        "        eps = ctx.eps\n",
        "        have_bias = ctx.have_bias\n",
        "        x, v, bias = ctx.saved_tensors\n",
        "\n",
        "        # Recompute y with PyTorch ops and get dL/dx, dL/dv, dL/db via autograd\n",
        "        with torch.enable_grad():\n",
        "            x_ = x.detach().requires_grad_(True)\n",
        "            v_ = v.detach().requires_grad_(True)\n",
        "            b_ = bias.detach().requires_grad_(True)\n",
        "\n",
        "            z = x_ + b_.view(1, -1, 1, 1)\n",
        "            # Reference EvoNorm-B0 (same as your cell #13)\n",
        "            N, C, H, W = z.shape\n",
        "            Cg = C // groups\n",
        "            xg = z.view(N, groups, Cg, H, W)\n",
        "            var = xg.var(dim=(2,3,4), unbiased=False, keepdim=True)\n",
        "            inv_std = torch.rsqrt(var + eps).expand(N, groups, Cg, H, W).reshape(N, C, H, W)\n",
        "            y_ref = z * torch.sigmoid(v_.view(1, C, 1, 1) * z) * inv_std\n",
        "\n",
        "            grads = torch.autograd.grad(y_ref, (x_, v_, b_), grad_y, allow_unused=True)\n",
        "            grad_x = grads[0]\n",
        "            grad_v = grads[1]\n",
        "            grad_b = grads[2] if have_bias else None\n",
        "\n",
        "        # Return grads aligned to inputs of apply: (x, v, bias, groups, eps)\n",
        "        return grad_x, grad_v, grad_b, None, None\n",
        "\n",
        "def evonorm_b0_triton_autograd(x, v, bias=None, groups=32, eps=1e-5):\n",
        "    return _EvoNormB0EpilogueFn.apply(x, v, bias, groups, eps)\n",
        "# --- End of definitions from cell IKMAKuWH2FUG ---\n",
        "\n",
        "\n",
        "# âœ… Normalized MNIST data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_ds = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "class SmallCNN(torch.nn.Module):\n",
        "    def __init__(self, use_fused=False, groups=32):\n",
        "        super().__init__()\n",
        "        self.use_fused = use_fused\n",
        "        self.groups = groups\n",
        "        self.conv1 = torch.nn.Conv2d(1, 32, 3, padding=1)   # 28x28 -> 28x28\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, 3, padding=1)  # 28x28 -> 28x28\n",
        "        self.pool  = torch.nn.MaxPool2d(2)                  # 28x28 -> 14x14\n",
        "        self.conv3 = torch.nn.Conv2d(64, 64, 3, padding=1)  # 14x14 -> 14x14\n",
        "        self.head  = torch.nn.Sequential(\n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Linear(64*14*14, 128),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Linear(128, 10)\n",
        "        )\n",
        "        # EvoNorm params for fused epilogue (per conv output channel)\n",
        "        self.v1 = torch.nn.Parameter(torch.randn(32))\n",
        "        self.v2 = torch.nn.Parameter(torch.randn(64))\n",
        "        self.v3 = torch.nn.Parameter(torch.randn(64))\n",
        "        self.b1 = torch.nn.Parameter(torch.zeros(32))\n",
        "        self.b2 = torch.nn.Parameter(torch.zeros(64))\n",
        "        self.b3 = torch.nn.Parameter(torch.zeros(64))\n",
        "\n",
        "    def epilogue(self, y, v, b):\n",
        "        if self.use_fused:\n",
        "            # Triton fused epilogue with autograd wrapper\n",
        "            return evonorm_b0_triton_autograd(y, v, bias=b, groups=self.groups)\n",
        "        else:\n",
        "            # Reference PyTorch EvoNorm-B0\n",
        "            N, C, H, W = y.shape\n",
        "            Cg = C // self.groups\n",
        "            xg = y.view(N, self.groups, Cg, H, W)\n",
        "            var = xg.var(dim=(2,3,4), unbiased=False, keepdim=True)\n",
        "            inv = torch.rsqrt(var + 1e-5).expand(N, self.groups, Cg, H, W).reshape(N, C, H, W)\n",
        "            return (y + b.view(1, C, 1, 1)) * torch.sigmoid(v.view(1, C, 1, 1) * (y + b.view(1, C, 1, 1))) * inv\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x);  y = self.epilogue(y, self.v1, self.b1)\n",
        "        y = self.conv2(y);  y = self.epilogue(y, self.v2, self.b2)\n",
        "        y = self.pool(y)\n",
        "        y = self.conv3(y);  y = self.epilogue(y, self.v3, self.b3)\n",
        "        logits = self.head(y)  # raw logits for CrossEntropyLoss\n",
        "        return logits\n",
        "\n",
        "def train_one_epoch(model, opt, loader, device, criterion=None):\n",
        "    model.train()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        logits = model(imgs)\n",
        "\n",
        "        # Use custom loss if provided, else standard CE\n",
        "        if criterion is None:\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "        else:\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        loss_sum += loss.item() * labels.size(0)\n",
        "        total += labels.size(0)\n",
        "        correct += (logits.argmax(dim=1) == labels).sum().item()\n",
        "    return loss_sum / total, correct / total\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        logits = model(imgs)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        loss_sum += loss.item() * labels.size(0)\n",
        "        total += labels.size(0)\n",
        "        correct += (logits.argmax(dim=1) == labels).sum().item()\n",
        "    return loss_sum/total, correct/total\n",
        "    # ==== 10-epoch training with curves & CSV ====\n",
        "import os, time, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "EPOCHS = 10\n",
        "os.makedirs(\"profiling/benchmark_results\", exist_ok=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def train_epochs(model, optimizer, train_loader, test_loader, label: str, device: torch.device = None, epochs: int = EPOCHS, criterion=None):\n",
        "    hist = {\n",
        "        \"epoch\": [],\n",
        "        \"train_loss\": [], \"train_acc\": [],\n",
        "        \"test_loss\": [],  \"test_acc\": [],\n",
        "        \"train_ms\": [],   \"train_peak_mem_mb\": [],\n",
        "        \"test_ms\": [],    \"test_peak_mem_mb\": [],\n",
        "        \"secs\": [],\n",
        "    }\n",
        "    for epoch in range(1, epochs+1):\n",
        "        # time & memory for one epoch (training only)\n",
        "        (tr_res, tr_ms, tr_mem_mb) = profile_time_and_memory(\n",
        "            train_one_epoch, model, optimizer, train_loader, device, criterion\n",
        "        )\n",
        "        tr_loss, tr_acc = tr_res\n",
        "\n",
        "        # time & memory for one pass on test\n",
        "        (te_res, te_ms, te_mem_mb) = profile_time_and_memory(\n",
        "            evaluate, model, test_loader\n",
        "        )\n",
        "        te_loss, te_acc = te_res\n",
        "\n",
        "        secs = tr_ms / 1000.0  # or (tr_ms + te_ms) / 1000.0 if you want full epoch\n",
        "\n",
        "        # Populate hist for the current epoch\n",
        "        hist[\"epoch\"].append(epoch)\n",
        "        hist[\"train_loss\"].append(tr_loss)\n",
        "        hist[\"train_acc\"].append(tr_acc)\n",
        "        hist[\"test_loss\"].append(te_loss)\n",
        "        hist[\"test_acc\"].append(te_acc)\n",
        "        hist[\"train_ms\"].append(tr_ms)\n",
        "        hist[\"train_peak_mem_mb\"].append(tr_mem_mb)\n",
        "        hist[\"test_ms\"].append(te_ms)\n",
        "        hist[\"test_peak_mem_mb\"].append(te_mem_mb)\n",
        "        hist[\"secs\"].append(secs)\n",
        "\n",
        "        print(f\"[{label}] Epoch {epoch:02d}/{epochs}  \"\n",
        "              f\"train_loss={tr_loss:.4f}  train_acc={tr_acc:.4f}  \"\n",
        "              f\"test_loss={te_loss:.4f}  test_acc={te_acc:.4f}  ({secs:.2f}s)\")\n",
        "\n",
        "    # Moved outside the loop and correctly indented\n",
        "    df = pd.DataFrame(hist)\n",
        "    out_csv = f\"profiling/benchmark_results/mnist_{label.lower()}_learning_curve.csv\"\n",
        "    df.to_csv(out_csv, index=False)\n",
        "    print(f\"âœ… Saved: {out_csv}\")\n",
        "    return df\n",
        "\n",
        "# Create models\n",
        "m_ref = SmallCNN(use_fused=False, groups=32).to(device)\n",
        "m_fused = SmallCNN(use_fused=True,  groups=32).to(device)\n",
        "\n",
        "# ðŸ”‘ Ensure identical starting weights\n",
        "m_fused.load_state_dict(m_ref.state_dict())\n",
        "\n",
        "# Optimizers (fresh) â€” tweak LR if you like\n",
        "opt_ref   = torch.optim.Adam(m_ref.parameters(),   lr=1e-3)\n",
        "opt_fused = torch.optim.Adam(m_fused.parameters(), lr=1e-3)\n",
        "\n",
        "\n",
        "print(\"\\nâ± Training Reference for 10 epochs...\")\n",
        "df_ref = train_epochs(m_ref, opt_ref, train_loader, test_loader, label=\"Reference\", device=device, epochs=EPOCHS)\n",
        "\n",
        "print(\"\\nâ± Training Fused for 10 epochs...\")\n",
        "df_fused = train_epochs(m_fused, opt_fused, train_loader, test_loader, label=\"Fused\", device=device, epochs=EPOCHS)\n",
        "\n",
        "# ---- Focal Loss setup ----\n",
        "focal_criterion = FocalLoss(alpha=1.0, gamma=2.0).to(device)\n",
        "\n",
        "# 2. Create NEW models for Focal Loss training\n",
        "m_ref_focal = SmallCNN(use_fused=False, groups=32).to(device)\n",
        "m_fused_focal = SmallCNN(use_fused=True,  groups=32).to(device)\n",
        "\n",
        "# Make sure weights start IDENTICAL\n",
        "m_fused_focal.load_state_dict(m_ref_focal.state_dict())\n",
        "\n",
        "# 3. New optimizers for the Focal Loss run\n",
        "opt_ref_focal   = torch.optim.Adam(m_ref_focal.parameters(), lr=1e-3)\n",
        "opt_fused_focal = torch.optim.Adam(m_fused_focal.parameters(), lr=1e-3)\n",
        "\n",
        "# 4. Train using Focal Loss\n",
        "print(\"\\nðŸ”¥ Training Reference with Focal Loss for 10 epochs...\")\n",
        "df_ref_focal = train_epochs(\n",
        "    m_ref_focal,\n",
        "    opt_ref_focal,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    label=\"Reference_Focal\",\n",
        "    device=device,\n",
        "    epochs=10,\n",
        "    criterion=focal_criterion\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---- Plot learning curves ----\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(df_ref[\"epoch\"], df_ref[\"test_acc\"], label=\"Ref Test Acc\")\n",
        "plt.plot(df_fused[\"epoch\"], df_fused[\"test_acc\"], label=\"Fused Test Acc\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"MNIST Test Accuracy\"); plt.legend(); plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(df_ref[\"epoch\"], df_ref[\"test_loss\"], label=\"Ref Test Loss\")\n",
        "plt.plot(df_fused[\"epoch\"], df_fused[\"test_loss\"], label=\"Fused Test Loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"MNIST Test Loss\"); plt.legend(); plt.grid(True)\n",
        "plt.show()\n",
        "# ============================\n",
        "# â­ FOCAL LOSS TRAINING SECTION\n",
        "# ============================\n",
        "\n",
        "# 1. Create Focal Loss instance\n",
        "focal_criterion = FocalLoss(alpha=1.0, gamma=2.0).to(device)\n",
        "\n",
        "# 2. New models for Focal Loss (fresh weights)\n",
        "m_ref_focal = SmallCNN(use_fused=False, groups=32).to(device)\n",
        "m_fused_focal = SmallCNN(use_fused=True,  groups=32).to(device)\n",
        "\n",
        "# Match initial weights\n",
        "m_fused_focal.load_state_dict(m_ref_focal.state_dict())\n",
        "\n",
        "# 3. Optimizers\n",
        "opt_ref_focal   = torch.optim.Adam(m_ref_focal.parameters(),   lr=1e-3)\n",
        "opt_fused_focal = torch.optim.Adam(m_fused_focal.parameters(), lr=1e-3)\n",
        "\n",
        "# 4. Train with Focal Loss\n",
        "print(\"\\nðŸ”¥ Training Reference with Focal Loss for 10 epochs...\")\n",
        "df_ref_focal = train_epochs(\n",
        "    m_ref_focal,\n",
        "    opt_ref_focal,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    label=\"Reference_Focal\",\n",
        "    device=device,\n",
        "    epochs=10,\n",
        "    criterion=focal_criterion\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===== Overfit sanity test (should hit >95% train acc in ~5 epochs) =====\n",
        "import copy\n",
        "subset = torch.utils.data.Subset(train_ds, range(512))\n",
        "loader_small = torch.utils.data.DataLoader(subset, batch_size=64, shuffle=True)\n",
        "\n",
        "m_dbg = copy.deepcopy(m_ref).train()\n",
        "opt_dbg = torch.optim.Adam(m_dbg.parameters(), lr=3e-3)\n",
        "\n",
        "for e in range(1,6):\n",
        "    tr_loss, tr_acc = train_one_epoch(m_dbg, opt_dbg, loader_small, device)\n",
        "    print(f\"[overfit-512] e{e} loss={tr_loss:.3f} acc={tr_acc:.3f}\")\n",
        "# ========================================================================\n",
        "\n",
        "\n",
        "\n",
        "# ðŸ”‘ KEY FIX: Copy weights so both models start identically\n",
        "m_fused.load_state_dict(m_ref.state_dict())\n",
        "\n",
        "# Verify they match\n",
        "print(f\"âœ“ Weights match: conv={torch.allclose(m_ref.conv1.weight, m_fused.conv1.weight)}, \"\n",
        "      f\"v1={torch.allclose(m_ref.v1, m_fused.v1)}, \"\n",
        "      f\"b1={torch.allclose(m_ref.b1, m_fused.b1)}, \"\n",
        "      f\"fc_weight={torch.allclose(m_ref.head[1].weight, m_fused.head[1].weight)}\")\n",
        "\n",
        "opt_ref = torch.optim.Adam(m_ref.parameters(), lr=1e-3)\n",
        "opt_fused = torch.optim.Adam(m_fused.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"â± Training 1 epoch each (quick demo) ...\")\n",
        "t0 = time.time()\n",
        "ref_tr_loss, ref_tr_acc = train_one_epoch(m_ref, opt_ref, train_loader, device)\n",
        "t1 = time.time()\n",
        "fused_tr_loss, fused_tr_acc = train_one_epoch(m_fused, opt_fused, train_loader, device)\n",
        "t2 = time.time()\n",
        "\n",
        "ref_te_loss, ref_te_acc = evaluate(m_ref, test_loader)\n",
        "fused_te_loss, fused_te_acc = evaluate(m_fused, test_loader)\n",
        "\n",
        "timings = pd.DataFrame([\n",
        "    {\"model\":\"Reference\", \"train_sec\": t1-t0, \"train_loss\": ref_tr_loss, \"train_acc\": ref_tr_acc, \"test_loss\": ref_te_loss, \"test_acc\": ref_te_acc},\n",
        "    {\"model\":\"Fused\",      \"train_sec\": t2-t1, \"train_loss\": fused_tr_loss, \"train_acc\": fused_tr_acc, \"test_loss\": fused_te_loss, \"test_acc\": fused_te_acc},\n",
        "])\n",
        "\n",
        "display(timings)\n",
        "timings.to_csv(\"profiling/benchmark_results/mnist_evonorm_timings.csv\", index=False)\n",
        "print(\"âœ… Saved: profiling/benchmark_results/mnist_evonorm_timings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PoMMzUg0sQPb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoMMzUg0sQPb",
        "outputId": "665c4393-5bef-4fc9-8e22-18802dd19b3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WITH BIAS - Max diff: 9.54e-07\n",
            "WITH BIAS - Mean diff: 3.83e-08\n"
          ]
        }
      ],
      "source": [
        "# Test WITH bias (like training actually uses)\n",
        "torch.manual_seed(42)\n",
        "x = torch.randn(2, 32, 28, 28, device='cuda')\n",
        "v = torch.randn(32, device='cuda')\n",
        "bias = torch.randn(32, device='cuda')\n",
        "\n",
        "# Reference: manually add bias, then apply evonorm\n",
        "x_biased = x + bias.view(1, 32, 1, 1)\n",
        "ref = evonorm_b0_reference(x_biased, v, groups=32)\n",
        "\n",
        "# Fused: passes bias to epilogue\n",
        "fused = triton_conv_evonorm_epilogue(x, v, bias=bias, groups=32)\n",
        "\n",
        "print(f\"WITH BIAS - Max diff: {(ref - fused).abs().max().item():.2e}\")\n",
        "print(f\"WITH BIAS - Mean diff: {(ref - fused).abs().mean().item():.2e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sf-iSqCowJih",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf-iSqCowJih",
        "outputId": "87abc652-3388-4109-8848-459e7eb09724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forward match: True\n",
            "x grad match: True\n",
            "v grad match: True\n",
            "bias grad match: True\n",
            "\n",
            "x grad max diff: 0.00e+00\n",
            "v grad max diff: 0.00e+00\n",
            "bias grad max diff: 0.00e+00\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "x = torch.randn(2, 32, 28, 28, device='cuda', requires_grad=True)\n",
        "v = torch.randn(32, device='cuda', requires_grad=True)\n",
        "bias = torch.randn(32, device='cuda', requires_grad=True)\n",
        "\n",
        "# Reference path\n",
        "x_ref = x.clone().detach().requires_grad_(True)\n",
        "v_ref = v.clone().detach().requires_grad_(True)\n",
        "bias_ref_for_evonorm = bias.clone().detach().requires_grad_(True) # Need a bias tensor with grad for the reference evonorm path\n",
        "x_biased_ref = x_ref + bias_ref_for_evonorm.view(1, 32, 1, 1)\n",
        "out_ref = evonorm_b0_reference(x_biased_ref, v_ref, groups=32)\n",
        "loss_ref = out_ref.sum()\n",
        "loss_ref.backward()\n",
        "\n",
        "# Fused path\n",
        "x_fused = x.clone().detach().requires_grad_(True)\n",
        "v_fused = v.clone().detach().requires_grad_(True)\n",
        "# This line was incorrect; it directly called the Triton kernel without the autograd wrapper.\n",
        "# out_fused = triton_conv_evonorm_epilogue(x_fused, v_fused, bias=bias, groups=32)\n",
        "out_fused = evonorm_b0_triton_autograd(x_fused, v_fused, bias=bias, groups=32)\n",
        "loss_fused = out_fused.sum()\n",
        "loss_fused.backward()\n",
        "\n",
        "print(f\"Forward match: {torch.allclose(out_ref, out_fused, atol=1e-5)}\")\n",
        "print(f\"x grad match: {torch.allclose(x_ref.grad, x_fused.grad, atol=1e-3)}\")\n",
        "print(f\"v grad match: {torch.allclose(v_ref.grad, v_fused.grad, atol=1e-3)}\")\n",
        "# Corrected: Now also check bias grad match\n",
        "print(f\"bias grad match: {torch.allclose(bias_ref_for_evonorm.grad, bias.grad, atol=1e-3)}\")\n",
        "\n",
        "print(f\"\\nx grad max diff: {(x_ref.grad - x_fused.grad).abs().max().item():.2e}\")\n",
        "print(f\"v grad max diff: {(v_ref.grad - v_fused.grad).abs().max().item():.2e}\")\n",
        "print(f\"bias grad max diff: {(bias_ref_for_evonorm.grad - bias.grad).abs().max().item():.2e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3115bc5a",
      "metadata": {
        "id": "3115bc5a"
      },
      "source": [
        "## 7ï¸âƒ£ Microbenchmarks (elementwise/softmax/layernorm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb57a1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eb57a1e",
        "outputId": "48c69169-0b43-4320-95f7-93cc1a648023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote cuda_kernels.cu\n",
            "Compiled cuda_kernels.so\n",
            "âœ… Saved: profiling/benchmark_results/microbench_ops.csv\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('.')\n",
        "import importlib\n",
        "\n",
        "# Re-create triton_additional_kernels.py (from original notebook cell 3115bc5a)\n",
        "with open(\"triton_additional_kernels.py\", \"w\") as f:\n",
        "    f.write(r'''\n",
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers (vectorized, exp-only)\n",
        "# ----------------------------\n",
        "# sigmoid(z) = 1 / (1 + exp(-z))\n",
        "def _sigmoid(z):\n",
        "    return 1.0 / (1.0 + tl.exp(-z))\n",
        "\n",
        "# tanh(z) = 2*sigmoid(2z) - 1\n",
        "# Moved logic into kernels below as global functions cannot be called directly\n",
        "\n",
        "# ----------------------------\n",
        "# GELU (tanh approximation) kernel\n",
        "# ----------------------------\n",
        "@triton.jit\n",
        "def _gelu_tanh_kernel(x_ptr, y_ptr, n_elements,\n",
        "                      BLOCK_SIZE: tl.constexpr):\n",
        "    pid = tl.program_id(axis=0)\n",
        "    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offs < n_elements\n",
        "\n",
        "    x = tl.load(x_ptr + offs, mask=mask)\n",
        "    # GELU(tanh) = 0.5*x*(1 + tanh(âˆš(2/Ï€) * (x + 0.044715 x^3)))\n",
        "    k = 0.7978845608028654  # sqrt(2/pi)\n",
        "    x3 = x * x * x\n",
        "    t = k * (x + 0.044715 * x3)\n",
        "    # Inlined tanh(t) = 2*sigmoid(2t) - 1\n",
        "    tanh_t = 2.0 * (1.0 / (1.0 + tl.exp(-2.0 * t))) - 1.0\n",
        "    y = 0.5 * x * (1.0 + tanh_t)\n",
        "\n",
        "    tl.store(y_ptr + offs, y, mask=mask)\n",
        "\n",
        "def gelu_triton(x: torch.Tensor) -> torch.Tensor:\n",
        "    assert x.is_cuda and x.dtype == torch.float32\n",
        "    x_c = x.contiguous()\n",
        "    y = torch.empty_like(x_c)\n",
        "    n = x_c.numel()\n",
        "    BLOCK = 1024\n",
        "    grid = lambda META: (triton.cdiv(n, META[\"BLOCK_SIZE\"]),)\n",
        "    _gelu_tanh_kernel[grid](x_c, y, n, BLOCK_SIZE=BLOCK, num_warps=4, num_stages=2)\n",
        "    return y.view_as(x)\n",
        "\n",
        "# ----------------------------\n",
        "# Swish = x * sigmoid(x) kernel\n",
        "# ----------------------------\n",
        "@triton.jit\n",
        "def _swish_kernel(x_ptr, y_ptr, n_elements,\n",
        "                  BLOCK_SIZE: tl.constexpr):\n",
        "    pid = tl.program_id(axis=0)\n",
        "    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offs < n_elements\n",
        "\n",
        "    x = tl.load(x_ptr + offs, mask=mask)\n",
        "    y = x * (1.0 / (1.0 + tl.exp(-x)))  # uses inlined sigmoid\n",
        "    tl.store(y_ptr + offs, y, mask=mask)\n",
        "\n",
        "def swish_triton(x: torch.Tensor) -> torch.Tensor:\n",
        "    assert x.is_cuda and x.dtype == torch.float32\n",
        "    x_c = x.contiguous()\n",
        "    y = torch.empty_like(x_c)\n",
        "    n = x_c.numel()\n",
        "    BLOCK = 1024\n",
        "    grid = lambda META: (triton.cdiv(n, META[\"BLOCK_SIZE\"]),)\n",
        "    _swish_kernel[grid](x_c, y, n, BLOCK_SIZE=BLOCK, num_warps=4, num_stages=2)\n",
        "    return y.view_as(x)\n",
        "# print(\"âœ… Kernels loaded successfully\")\n",
        "\n",
        "@triton.jit\n",
        "def layernorm_gelu_fused_kernel(x_ptr, y_ptr, gamma_ptr, beta_ptr,\n",
        "                                n_rows, n_cols, stride_xr, stride_xc, stride_yr, stride_yc,\n",
        "                                eps: tl.constexpr, BLOCK_SIZE: tl.constexpr):\n",
        "    row = tl.program_id(0)\n",
        "    cols = tl.arange(0, BLOCK_SIZE)\n",
        "    mask = cols < n_cols\n",
        "    x_row = x_ptr + row * stride_xr + cols * stride_xc\n",
        "    y_row = y_ptr + row * stride_yr + cols * stride_yc\n",
        "    x = tl.load(x_row, mask=mask, other=0.0).to(tl.float32)\n",
        "    m = tl.sum(x, axis=0) / n_cols\n",
        "    xc = x - m\n",
        "    v = tl.sum(xc * xc, axis=0) / n_cols\n",
        "    inv = tl.rsqrt(v + eps)\n",
        "    gamma = tl.load(gamma_ptr + cols, mask=mask, other=1.0).to(tl.float32)\n",
        "    beta = tl.load(beta_ptr + cols, mask=mask, other=0.0).to(tl.float32)\n",
        "    normalized = (xc * inv) * gamma + beta\n",
        "    # ---- GELU part: tanh approximation, no tl.libdevice ----\n",
        "    x2 = normalized * normalized\n",
        "    x3 = x2 * normalized\n",
        "\n",
        "    # inner = sqrt(2/pi) * (x + 0.044715 x^3)\n",
        "    inner = 0.7978845608 * (normalized + 0.044715 * x3)\n",
        "\n",
        "    # tanh(inner) â‰ˆ (e^{2*inner} - 1) / (e^{2*inner} + 1)\n",
        "    two_inner = 2.0 * inner\n",
        "    e2 = tl.exp(two_inner)\n",
        "    tanh_inner = (e2 - 1.0) / (e2 + 1.0)\n",
        "\n",
        "    y = 0.5 * normalized * (1.0 + tanh_inner)\n",
        "\n",
        "    tl.store(y_row, y, mask=mask) # Changed row_start + offs to y_row\n",
        "\n",
        "def layernorm_gelu_fused_triton(x: torch.Tensor, gamma: torch.Tensor, beta: torch.Tensor, eps: float = 1e-5) -> torch.Tensor:\n",
        "    assert x.is_cuda and x.is_contiguous()\n",
        "    cols = x.shape[-1]\n",
        "    rows = x.numel() // cols\n",
        "    x2 = x.view(rows, cols).contiguous()\n",
        "    y2 = torch.empty_like(x2)\n",
        "    BLOCK = 1 << (cols - 1).bit_length()\n",
        "    BLOCK = min(BLOCK, 4096)\n",
        "    grid = (rows,)\n",
        "    layernorm_gelu_fused_kernel[grid](x2, y2, gamma, beta,\n",
        "                                      rows, cols,\n",
        "                                      x2.stride(0), x2.stride(1),\n",
        "                                      y2.stride(0), y2.stride(1),\n",
        "                                      eps=eps, BLOCK_SIZE=BLOCK)\n",
        "    return y2.view_as(x)\n",
        "\n",
        "@triton.jit\n",
        "def softmax_cross_entropy_kernel(logits_ptr, labels_ptr, loss_ptr,\n",
        "                                 n_rows, n_cols, stride_lr, stride_lc,\n",
        "                                 BLOCK_SIZE: tl.constexpr):\n",
        "    row_id = tl.program_id(axis=0)\n",
        "    if row_id >= n_rows: return\n",
        "    cols = tl.arange(0, BLOCK_SIZE)\n",
        "    mask = cols < n_cols\n",
        "    row_ptr = logits_ptr + row_id * stride_lr\n",
        "    logits = tl.load(row_ptr + cols * stride_lc, mask=mask, other=-float('inf'))\n",
        "    max_logit = tl.max(logits, axis=0)\n",
        "    exp_logits = tl.exp(logits - max_logit)\n",
        "    sum_exp = tl.sum(exp_logits, axis=0)\n",
        "    label = tl.load(labels_ptr + row_id)\n",
        "    label_logit = tl.load(row_ptr + label * stride_lc)\n",
        "    loss = -label_logit + max_logit + tl.log(sum_exp)\n",
        "    tl.store(loss_ptr + row_id, loss)\n",
        "\n",
        "def softmax_cross_entropy_triton(logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
        "    assert logits.is_cuda and logits.is_contiguous()\n",
        "    assert labels.is_cuda and labels.is_contiguous()\n",
        "    N, C = logits.shape\n",
        "    loss = torch.empty(N, device=logits.device, dtype=logits.dtype)\n",
        "    BLOCK = 4096 # Increased BLOCK size to support larger 'C' values from benchmarks\n",
        "    assert C <= BLOCK, f\"Classes {C} must be <= {BLOCK}\"\n",
        "    grid = (N,)\n",
        "    softmax_cross_entropy_kernel[grid](logits, labels, loss, N, C, logits.stride(0), logits.stride(1), BLOCK_SIZE=BLOCK)\n",
        "    return loss.mean()\n",
        "''')\n",
        "\n",
        "# Re-create jlr_colab_demo_fixed.py (from original notebook cell 3115bc5a)\n",
        "with open(\"jlr_colab_demo_fixed.py\", \"w\") as f:\n",
        "    f.write(r'''\n",
        "import torch, triton, triton.language as tl\n",
        "import torch.nn.functional as F\n",
        "\n",
        "@triton.jit\n",
        "def softmax_rowwise_kernel(x_ptr, y_ptr, n_rows, n_cols, sxr, sxc, syr, syc, BLOCK_SIZE: tl.constexpr):\n",
        "    row_id = tl.program_id(0)\n",
        "    cols = tl.arange(0, BLOCK_SIZE)\n",
        "    row_ptr_x = x_ptr + row_id * sxr\n",
        "    row_ptr_y = y_ptr + row_id * syr\n",
        "    mask = cols < n_cols\n",
        "    x = tl.load(row_ptr_x + cols * sxc, mask=mask, other=-float('inf'))\n",
        "    x = x - tl.max(x, axis=0)\n",
        "    expx = tl.exp(x)\n",
        "    out = expx / tl.sum(expx, axis=0)\n",
        "    tl.store(row_ptr_y + cols * syc, out, mask=mask)\n",
        "\n",
        "def softmax_triton_lastdim(x):\n",
        "    assert x.is_cuda and x.is_contiguous()\n",
        "    cols = x.shape[-1]; rows = x.numel() // cols\n",
        "    x2 = x.view(rows, cols).contiguous(); y2 = torch.empty_like(x2)\n",
        "    BLOCK = 4096 # Increased BLOCK size to support larger 'cols' values from benchmarks\n",
        "    assert cols <= BLOCK, f\"Cols ({cols}) exceeds BLOCK_SIZE ({BLOCK})\"\n",
        "    softmax_rowwise_kernel[(rows,)](x2, y2, rows, cols, x2.stride(0), x2.stride(1), y2.stride(0), y2.stride(1), BLOCK_SIZE=BLOCK)\n",
        "    return y2.view_as(x)\n",
        "\n",
        "@triton.jit\n",
        "def layernorm_fwd_kernel(x_ptr, y_ptr, gamma_ptr, beta_ptr, n_rows, n_cols, sxr, sxc, syr, syc, eps: tl.constexpr, BLOCK_SIZE: tl.constexpr):\n",
        "    row = tl.program_id(0)\n",
        "    cols = tl.arange(0, BLOCK_SIZE)\n",
        "    mask = cols < n_cols\n",
        "    x_row = x_ptr + row * sxr + cols * sxc\n",
        "    y_row = y_ptr + row * syr + cols * syc\n",
        "    x = tl.load(x_row, mask=mask, other=0.0).to(tl.float32)\n",
        "    m = tl.sum(x, axis=0) / n_cols\n",
        "    xc = x - m\n",
        "    v = tl.sum(xc * xc, axis=0) / n_cols\n",
        "    inv = tl.rsqrt(v + eps)\n",
        "    gamma = tl.load(gamma_ptr + cols, mask=mask, other=1.0).to(tl.float32)\n",
        "    beta = tl.load(beta_ptr + cols, mask=mask, other=0.0).to(tl.float32)\n",
        "    y = (xc * inv) * gamma + beta\n",
        "    tl.store(y_row, y, mask=mask)\n",
        "\n",
        "def layernorm_triton(x, gamma, beta, eps=1e-5):\n",
        "    assert x.is_cuda and x.is_contiguous()\n",
        "    cols = x.shape[-1]; rows = x.numel() // cols\n",
        "    x2 = x.view(rows, cols).contiguous(); y2 = torch.empty_like(x2)\n",
        "    BLOCK = 1 << (cols - 1).bit_length(); BLOCK = min(BLOCK, 4096)\n",
        "    layernorm_fwd_kernel[(rows,)](x2, y2, gamma, beta, rows, cols, x2.stride(0), x2.stride(1), y2.stride(0), y2.stride(1), eps=eps, BLOCK_SIZE=BLOCK)\n",
        "    return y2.view_as(x)\n",
        "\n",
        "def evonorm_b0_reference(x, v, groups=32, eps=1e-5):\n",
        "    N, C, H, W = x.shape; Cg = C // groups\n",
        "    xg = x.view(N, groups, Cg, H, W)\n",
        "    var = xg.var(dim=(2,3,4), unbiased=False, keepdim=True)\n",
        "    inv_std = torch.rsqrt(var + eps).expand(N, groups, Cg, H, W).reshape(N, C, H, W)\n",
        "    return x * torch.sigmoid(v.view(1, C, 1, 1) * x) * inv_std\n",
        "\n",
        "@triton.jit\n",
        "def evonorm_b0_fused_kernel(x_ptr, v_ptr, y_ptr, N, C, H, W, groups, eps: tl.constexpr, BLOCK: tl.constexpr):\n",
        "    pid = tl.program_id(0)\n",
        "    g = pid % groups; n = pid // groups\n",
        "    Cg = C // groups; HW = H * W; group_elems = Cg * HW\n",
        "    base = n * (C * HW) + g * (Cg * HW)\n",
        "    acc1 = tl.zeros([1], dtype=tl.float32); acc2 = tl.zeros([1], dtype=tl.float32)\n",
        "    offs = tl.arange(0, BLOCK)\n",
        "    for start in range(0, group_elems, BLOCK):\n",
        "        idx = base + start + offs; mask = (start + offs) < group_elems\n",
        "        x = tl.load(x_ptr + idx, mask=mask, other=0.0).to(tl.float32)\n",
        "        acc1 += tl.sum(x, axis=0); acc2 += tl.sum(x * x, axis=0)\n",
        "    ge = tl.full([1], group_elems, dtype=tl.float32)\n",
        "    mean = acc1 / ge; var = acc2 / ge - mean * mean; inv = 1.0 / tl.sqrt(var + eps)\n",
        "    for start in range(0, group_elems, BLOCK):\n",
        "        idx = base + start + offs; mask = (start + offs) < group_elems\n",
        "        x = tl.load(x_ptr + idx, mask=mask, other=0.0).to(tl.float32)\n",
        "        rel = start + offs; c_in_group = rel // HW; c_global = g * Cg + c_in_group\n",
        "        v = tl.load(v_ptr + c_global, mask=mask, other=0.0).to(tl.float32)\n",
        "        sig = 1.0 / (1.0 + tl.exp(-(v * x)))\n",
        "        y = x * sig * inv; tl.store(y_ptr + idx, y, mask=mask)\n",
        "\n",
        "def evonorm_b0_triton_fused(x, v, groups=32, eps=1e-5):\n",
        "    N, C, H, W = x.shape; x = x.contiguous(); y = torch.empty_like(x)\n",
        "    Cg = C // groups; BLOCK = min(1024, Cg * H * W) if (Cg * H * W) > 0 else 1024\n",
        "    evonorm_b0_fused_kernel[(N * groups,)](x.view(-1), v, y.view(-1), N, C, H, W, groups, eps=eps, BLOCK=BLOCK)\n",
        "    return y\n",
        "''')\n",
        "\n",
        "\n",
        "# --- CUDA Kernel Definition and Compilation ---\n",
        "# cuda_kernels.cu content (from original notebook cell f6f8f5c8 or e0c0519c)\n",
        "cuda_src = r\"\"\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <cuda_fp16.h>\n",
        "#include <cmath>\n",
        "#include <stdio.h>\n",
        "\n",
        "#define CUDA_CHECK(call) \\\n",
        "    do { \\\n",
        "        cudaError_t err = call; \\\n",
        "        if (err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"CUDA error in %s:%d: %s\\n\", __FILE__, __LINE__, \\\n",
        "                    cudaGetErrorString(err)); \\\n",
        "            exit(EXIT_FAILURE); \\\n",
        "        } \\\n",
        "    } while(0)\n",
        "\n",
        "// ============================================================================\n",
        "// Utility reduction helpers\n",
        "// ============================================================================\n",
        "template<int BLOCK_SIZE>\n",
        "__device__ float warp_reduce_sum(float val) {\n",
        "    for (int offset = 16; offset > 0; offset >>= 1)\n",
        "        val += __shfl_down_sync(0xffffffff, val, offset);\n",
        "    return val;\n",
        "}\n",
        "\n",
        "__device__ inline float warp_reduce_max(float v) {\n",
        "    for (int off = 16; off > 0; off >>= 1)\n",
        "        v = fmaxf(v, __shfl_down_sync(0xffffffff, v, off));\n",
        "    return v;\n",
        "}\n",
        "\n",
        "__device__ inline float block_allreduce_sum(float val, float* shared) {\n",
        "    val = warp_reduce_sum<32>(val);\n",
        "    int lane = threadIdx.x & 31;\n",
        "    int warp = threadIdx.x >> 5;\n",
        "    if (lane == 0) shared[warp] = val;\n",
        "    __syncthreads();\n",
        "    float out = 0.0;\n",
        "    if (warp == 0) {\n",
        "        out = (lane < (blockDim.x + 31)/32) ? shared[lane] : 0.0;\n",
        "        out = warp_reduce_sum<32>(out);\n",
        "        if (lane == 0) shared[0] = out;\n",
        "    }\n",
        "    __syncthreads();\n",
        "    return shared[0];\n",
        "}\n",
        "\n",
        "__device__ inline float block_allreduce_max(float val, float* shared) {\n",
        "    val = warp_reduce_max(val);\n",
        "    int lane = threadIdx.x & 31;\n",
        "    int warp = threadIdx.x >> 5;\n",
        "    if (lane == 0) shared[warp] = val;\n",
        "    __syncthreads();\n",
        "    float out = -INFINITY;\n",
        "    if (warp == 0) {\n",
        "        out = (lane < (blockDim.x + 31)/32) ? shared[lane] : -INFINITY;\n",
        "        out = warp_reduce_max(out);\n",
        "        if (lane == 0) shared[0] = out;\n",
        "    }\n",
        "    __syncthreads();\n",
        "    return shared[0];\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 1. ReLU\n",
        "// ============================================================================\n",
        "__global__ void relu_kernel(const float* x, float* y, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) y[i] = fmaxf(x[i], 0.0);\n",
        "}\n",
        "extern \"C\" void relu_cuda(const float* x, float* y, int n, cudaStream_t stream=0) {\n",
        "    int t = 256, b = (n + t - 1)/t;\n",
        "    relu_kernel<<<b,t,0,stream>>>(x,y,n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 2. Sigmoid\n",
        "// ============================================================================\n",
        "__global__ void sigmoid_kernel(const float* x, float* y, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) y[i] = 1.0 / (1.0 + expf(-x[i]));\n",
        "}\n",
        "extern \"C\" void sigmoid_cuda(const float* x, float* y, int n, cudaStream_t stream=0) {\n",
        "    int t = 256, b = (n + t - 1)/t;\n",
        "    sigmoid_kernel<<<b,t,0,stream>>>(x,y,n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 3. GELU (tanh approximation)\n",
        "// ============================================================================\n",
        "__global__ void gelu_kernel(const float* x, float* y, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        float v = x[i];\n",
        "        float x3 = v*v*v;\n",
        "        float inner = 0.7978845608 * (v + 0.044715 * x3);\n",
        "        y[i] = 0.5 * v * (1.0 + tanhf(inner));\n",
        "    }\n",
        "}\n",
        "extern \"C\" void gelu_cuda(const float* x, float* y, int n, cudaStream_t stream=0) {\n",
        "    int t = 256, b = (n + t - 1)/t;\n",
        "    gelu_kernel<<<b,t,0,stream>>>(x,y,n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 4. Swish\n",
        "// ============================================================================\n",
        "__global__ void swish_kernel(const float* x, float* y, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        float v = x[i];\n",
        "        float sig = 1.0 / (1.0 + expf(-v));\n",
        "        y[i] = v * sig;\n",
        "    }\n",
        "}\n",
        "extern \"C\" void swish_cuda(const float* x, float* y, int n, cudaStream_t stream=0) {\n",
        "    int t = 256, b = (n + t - 1)/t;\n",
        "    swish_kernel<<<b,t,0,stream>>>(x,y,n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 5. LayerNorm (broadcast-corrected)\n",
        "// ============================================================================\n",
        "template<int BLOCK>\n",
        "__global__ void layernorm_kernel(\n",
        "    const float* x, float* y,\n",
        "    const float* gamma, const float* beta,\n",
        "    int N, int D, float eps)\n",
        "{\n",
        "    int row = blockIdx.x;\n",
        "    if (row >= N) return;\n",
        "    const float* xrow = x + row*D;\n",
        "    float* yrow = y + row*D;\n",
        "\n",
        "    __shared__ float shared[32];\n",
        "    float sum = 0.0;\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) sum += xrow[i];\n",
        "    float total_sum = block_allreduce_sum(sum, shared);\n",
        "    float mean = total_sum / D;\n",
        "\n",
        "    float var_local = 0.0;\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
        "        float d = xrow[i] - mean;\n",
        "        var_local += d*d;\n",
        "    }\n",
        "    float total_var = block_allreduce_sum(var_local, shared);\n",
        "    float inv_std = rsqrtf(total_var / D + eps);\n",
        "\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
        "        float norm = (xrow[i] - mean) * inv_std;\n",
        "        yrow[i] = gamma[i]*norm + beta[i];\n",
        "    }\n",
        "}\n",
        "extern \"C\" void layernorm_cuda(\n",
        "    const float* x, float* y,\n",
        "    const float* gamma, const float* beta,\n",
        "    int N, int D, float eps, cudaStream_t stream=0)\n",
        "{\n",
        "    int t=256;\n",
        "    layernorm_kernel<256><<<N,t,0,stream>>>(x,y,gamma,beta,N,D,eps);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 6. Softmax (stable + broadcast fixed)\n",
        "// ============================================================================\n",
        "template<int BLOCK>\n",
        "__global__ void softmax_kernel(const float* x, float* y, int N, int D)\n",
        "{\n",
        "    int row = blockIdx.x;\n",
        "    if (row >= N) return;\n",
        "    const float* xr = x + row*D;\n",
        "    float* yr = y + row*D;\n",
        "    __shared__ float scratch[32];\n",
        "\n",
        "    float local_max=-INFINITY;\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x)\n",
        "        local_max=fmaxf(local_max,xr[i]);\n",
        "    float row_max=block_allreduce_max(local_max,scratch);\n",
        "\n",
        "    float local_sum=0.0;\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x){\n",
        "        float e=expf(xr[i]-row_max);\n",
        "        yr[i]=e;\n",
        "        local_sum+=e;\n",
        "    }\n",
        "    float row_sum=block_allreduce_sum(local_sum,scratch);\n",
        "\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x)\n",
        "        yr[i]/=row_sum;\n",
        "}\n",
        "extern \"C\" void softmax_cuda(const float* x, float* y, int N, int D, cudaStream_t stream=0){\n",
        "    int t=256;\n",
        "    softmax_kernel<256><<<N,t,0,stream>>>(x,y,N,D);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 7. EvoNorm-B0 (already correct)\n",
        "// ============================================================================\n",
        "__global__ void evonorm_b0_kernel(\n",
        "    const float* x,const float* v,float* y,\n",
        "    int N,int C,int H,int W,int groups,float eps)\n",
        "{\n",
        "    int n=blockIdx.x/groups;\n",
        "    int g=blockIdx.x%groups;\n",
        "    if(n>=N)return;\n",
        "    int Cg=C/groups,HW=H*W,group_size=Cg*HW;\n",
        "    int base=n*C*HW+g*Cg*HW;\n",
        "    __shared__ float s_mean,s_var;\n",
        "    float sum=0.0,sum_sq=0.0;\n",
        "    for(int i=threadIdx.x;i<group_size;i+=blockDim.x){\n",
        "        float val=x[base+i];\n",
        "        sum+=val; sum_sq+=val*val;\n",
        "    }\n",
        "    __shared__ float buf[256];\n",
        "    buf[threadIdx.x]=sum; __syncthreads();\n",
        "    for(int s=blockDim.x/2;s>0;s>>=1){\n",
        "        if(threadIdx.x<s)buf[threadIdx.x]+=buf[threadIdx.x+s];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if(threadIdx.x==0)s_mean=buf[0]/group_size;\n",
        "    __syncthreads();\n",
        "    buf[threadIdx.x]=sum_sq; __syncthreads();\n",
        "    for(int s=blockDim.x/2;s>0;s>>=1){\n",
        "        if(threadIdx.x<s)buf[threadIdx.x]+=buf[threadIdx.x+s];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if(threadIdx.x==0){\n",
        "        float mean_sq=buf[0]/group_size;\n",
        "        s_var=mean_sq-s_mean*s_mean;\n",
        "    }\n",
        "    __syncthreads();\n",
        "    float inv_std=rsqrtf(s_var+eps);\n",
        "    for(int i=threadIdx.x;i<group_size;i+=blockDim.x){\n",
        "        int global_idx=base+i;\n",
        "        int c_in_group=i/HW;\n",
        "        int c_global=g*Cg+c_in_group;\n",
        "        float val=x[global_idx];\n",
        "        float vval=v[c_global];\n",
        "        float sig=1.0/(1.0+expf(-vval*val));\n",
        "        y[global_idx]=val*sig*inv_std;\n",
        "    }\n",
        "}\n",
        "extern \"C\" void evonorm_b0_cuda(\n",
        "    const float* x, const float* v, float* y,\n",
        "    int N, int C, int H, int W, int groups, float eps, cudaStream_t stream=0)\n",
        "{\n",
        "    int t = 256;\n",
        "    int b = N * groups;\n",
        "    evonorm_b0_kernel<<<b, t, 0, stream>>>(x, v, y, N, C, H, W, groups, eps);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 8. Fused LayerNorm + GELU (broadcast fixed)\n",
        "// ============================================================================\n",
        "template<int BLOCK>\n",
        "__global__ void layernorm_gelu_fused_kernel(\n",
        "    const float* x,float* y,const float* gamma,const float* beta,\n",
        "    int N,int D,float eps)\n",
        "{\n",
        "    int row=blockIdx.x;\n",
        "    if(row>=N)return;\n",
        "    const float* xr=x+row*D;\n",
        "    float* yr=y+row*D;\n",
        "    __shared__ float scratch[32];\n",
        "\n",
        "    float sum=0.0;\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x) sum+=xr[i];\n",
        "    float total_sum=block_allreduce_sum(sum,scratch);\n",
        "    float mean=total_sum/D;\n",
        "\n",
        "    float var_local=0.0;\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x){\n",
        "        float d=xr[i]-mean;\n",
        "        var_local+=d*d;\n",
        "    }\n",
        "    float total_var=block_allreduce_sum(var_local,scratch);\n",
        "    float inv_std=rsqrtf(total_var/D+eps);\n",
        "\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x){\n",
        "        float norm=(xr[i]-mean)*inv_std;\n",
        "        float a=gamma[i]*norm+beta[i];\n",
        "        float a3=a*a*a;\n",
        "        float inner=0.7978845608*(a+0.044715*a3);\n",
        "        yr[i]=0.5*a*(1.0+tanhf(inner));\n",
        "    }\n",
        "}\n",
        "extern \"C\" void layernorm_gelu_fused_cuda(\n",
        "    const float* x,float* y,const float* gamma,const float* beta,\n",
        "    int N,int D,float eps,cudaStream_t stream=0)\n",
        "{\n",
        "    int t=256;\n",
        "    layernorm_gelu_fused_kernel<256><<<N,t,0,stream>>>(x,y,gamma,beta,N,D,eps);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\"\"\"\n",
        "with open(\"cuda_kernels.cu\", \"w\") as f:\n",
        "    f.write(cuda_src)\n",
        "print(\"Wrote cuda_kernels.cu\")\n",
        "\n",
        "# Compile cuda_kernels.so (from original notebook cell 7a65093d)\n",
        "!nvcc -O3 -std=c++14 -Xcompiler -fPIC --shared cuda_kernels.cu -o cuda_kernels.so -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90\n",
        "print(\"Compiled cuda_kernels.so\")\n",
        "\n",
        "# --- End CUDA Kernel Definition and Compilation ---\n",
        "\n",
        "import ctypes\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Before importing, reload modules to pick up changes\n",
        "# The modules will be re-imported from the updated files.\n",
        "# This ensures that the Python session uses the latest definitions.\n",
        "try:\n",
        "    # Only try to reload if the module was already imported\n",
        "    if 'jlr_colab_demo_fixed' in sys.modules:\n",
        "        importlib.reload(sys.modules['jlr_colab_demo_fixed'])\n",
        "    if 'triton_additional_kernels' in sys.modules:\n",
        "        importlib.reload(sys.modules['triton_additional_kernels'])\n",
        "except NameError:\n",
        "    pass # Modules might not be loaded yet in a fresh session\n",
        "\n",
        "# Ensure Triton functions are imported from the (potentially reloaded) modules\n",
        "from jlr_colab_demo_fixed import layernorm_triton, softmax_triton_lastdim\n",
        "from triton_additional_kernels import swish_triton, gelu_triton, layernorm_gelu_fused_triton\n",
        "\n",
        "rows = []\n",
        "sizes = [(1, 4096), (32, 4096), (128, 1024)]\n",
        "\n",
        "c_void_p, c_int, c_float = ctypes.c_void_p, ctypes.c_int, ctypes.c_float\n",
        "\n",
        "# Definition of dev_ptr must be outside try-except and before cuda function wrappers\n",
        "def dev_ptr(t: torch.Tensor):\n",
        "    assert t.is_cuda and t.dtype == torch.float32 and t.is_contiguous()\n",
        "    return c_void_p(t.data_ptr())\n",
        "\n",
        "\n",
        "def swish_torch(x):\n",
        "    return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "# Local wrappers for CUDA kernels to ensure they are callable in this cell\n",
        "try:\n",
        "    # Only try to load if not already loaded (e.g., from cell e0c0519c)\n",
        "    if 'lib' not in globals():\n",
        "        lib = ctypes.cdll.LoadLibrary(\"./cuda_kernels.so\")\n",
        "        print(\"âœ… Loaded CUDA library locally in microbenchmarks cell.\")\n",
        "\n",
        "    # Prototypes (ensure all are defined)\n",
        "    for fn_name in [\"relu_cuda\", \"sigmoid_cuda\", \"gelu_cuda\", \"swish_cuda\"]:\n",
        "        f = getattr(lib, fn_name)\n",
        "        f.argtypes = [c_void_p, c_void_p, c_int, c_void_p]\n",
        "        f.restype = None\n",
        "\n",
        "    lib.layernorm_cuda.argtypes = [c_void_p, c_void_p, c_void_p, c_void_p, c_int, c_int, c_float, c_void_p]\n",
        "    lib.layernorm_cuda.restype = None\n",
        "    lib.softmax_cuda.argtypes = [c_void_p, c_void_p, c_int, c_int, c_void_p]\n",
        "    lib.softmax_cuda.restype = None\n",
        "    # Note: evonorm_b0_cuda and layernorm_gelu_fused_cuda are not used in this specific benchmark, but keeping for completeness if needed later\n",
        "    # lib.evonorm_b0_cuda.argtypes = [c_void_p, c_void_p, c_void_p, c_int, c_int, c_int, c_int, c_int, c_float, c_void_p]\n",
        "    # lib.evonorm_b0_cuda.restype = None\n",
        "    # lib.layernorm_gelu_fused_cuda.argtypes = [c_void_p, c_void_p, c_void_p, c_void_p, c_int, c_int, c_float, c_void_p]\n",
        "    # lib.layernorm_gelu_fused_cuda.restype = None\n",
        "\n",
        "    # Define wrappers for CUDA kernels\n",
        "    def relu_cuda(x):\n",
        "        y = torch.empty_like(x)\n",
        "        lib.relu_cuda(dev_ptr(x), dev_ptr(y), x.numel(), c_void_p(0))\n",
        "        return y\n",
        "    def sigmoid_cuda(x):\n",
        "        y = torch.empty_like(x)\n",
        "        lib.sigmoid_cuda(dev_ptr(x), dev_ptr(y), x.numel(), c_void_p(0))\n",
        "        return y\n",
        "    def gelu_cuda(x):\n",
        "        y = torch.empty_like(x)\n",
        "        lib.gelu_cuda(dev_ptr(x), dev_ptr(y), x.numel(), c_void_p(0))\n",
        "        return y\n",
        "    def swish_cuda(x):\n",
        "        y = torch.empty_like(x)\n",
        "        lib.swish_cuda(dev_ptr(x), dev_ptr(y), x.numel(), c_void_p(0))\n",
        "        return y\n",
        "    def layernorm_cuda(x, g, b, eps=1e-5):\n",
        "        cols = x.shape[-1]; rows = x.numel() // cols\n",
        "        x_view = x.view(rows, cols).contiguous(); y_view = torch.empty_like(x_view)\n",
        "        lib.layernorm_cuda(dev_ptr(x_view), dev_ptr(y_view), dev_ptr(g), dev_ptr(b), rows, cols, c_float(eps), c_void_p(0))\n",
        "        return y_view.view_as(x)\n",
        "    def softmax_cuda(x):\n",
        "        cols = x.shape[-1]; rows = x.numel() // cols\n",
        "        x_view = x.view(rows, cols).contiguous(); y_view = torch.empty_like(x_view)\n",
        "        lib.softmax_cuda(dev_ptr(x_view), dev_ptr(y_view), rows, cols, c_void_p(0))\n",
        "        return y_view.view_as(x)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not load cuda_kernels.so or define wrappers locally: {e}\")\n",
        "    # Define dummy functions to prevent crashes if CUDA kernels are not available\n",
        "    def relu_cuda(x): raise NotImplementedError(\"CUDA kernel not loaded\")\n",
        "    def sigmoid_cuda(x): raise NotImplementedError(\"CUDA kernel not loaded\")\n",
        "    def swish_cuda(x): raise NotImplementedError(\"CUDA kernel not loaded\")\n",
        "    def layernorm_cuda(x,g,b,eps=1e-5): raise NotImplementedError(\"CUDA kernel not loaded\")\n",
        "    def softmax_cuda(x): raise NotImplementedError(\"CUDA kernel not loaded\")\n",
        "    def gelu_cuda(x): raise NotImplementedError(\"CUDA kernel not loaded\")\n",
        "\n",
        "\n",
        "for n, m in sizes:\n",
        "    x = torch.randn(n, m, device=device, dtype=torch.float32) # Ensure float32 for CUDA kernels\n",
        "\n",
        "    # --- Swish benchmarking ---\n",
        "    _, pt_swish_ms, pt_swish_mem = profile_time_and_memory(lambda: swish_torch(x), repeat=50)\n",
        "    _, cu_swish_ms, cu_swish_mem = profile_time_and_memory(lambda: swish_cuda(x), repeat=50)\n",
        "    _, tr_swish_ms, tr_swish_mem = profile_time_and_memory(lambda: swish_triton(x), repeat=50)\n",
        "\n",
        "    rows.append({\n",
        "        \"op\": \"swish\", \"n\": n, \"m\": m, \"backend\": \"torch\",\n",
        "        \"time_ms\": pt_swish_ms, \"peak_mem_mb\": pt_swish_mem,\n",
        "    })\n",
        "    rows.append({\n",
        "        \"op\": \"swish\", \"n\": n, \"m\": m, \"backend\": \"cuda\",\n",
        "        \"time_ms\": cu_swish_ms, \"peak_mem_mb\": cu_swish_mem,\n",
        "    })\n",
        "    rows.append({\n",
        "        \"op\": \"swish\", \"n\": n, \"m\": m, \"backend\": \"triton\",\n",
        "        \"time_ms\": tr_swish_ms, \"peak_mem_mb\": tr_swish_mem,\n",
        "    })\n",
        "\n",
        "    # --- LayerNorm benchmarking ---\n",
        "    g = torch.ones(m, device=device, dtype=torch.float32)\n",
        "    b = torch.zeros(m, device=device, dtype=torch.float32)\n",
        "\n",
        "    _, pt_ln_ms, pt_ln_mem = profile_time_and_memory(lambda: F.layer_norm(x, (m,), g, b), repeat=50)\n",
        "    _, cu_ln_ms, cu_ln_mem = profile_time_and_memory(lambda: layernorm_cuda(x, g, b), repeat=50)\n",
        "    _, tr_ln_ms, tr_ln_mem = profile_time_and_memory(lambda: layernorm_triton(x, g, b), repeat=50)\n",
        "\n",
        "    rows.append({\n",
        "        \"op\": \"layernorm\", \"n\": n, \"m\": m, \"backend\": \"torch\",\n",
        "        \"time_ms\": pt_ln_ms, \"peak_mem_mb\": pt_ln_mem,\n",
        "    })\n",
        "    rows.append({\n",
        "        \"op\": \"layernorm\", \"n\": n, \"m\": m, \"backend\": \"cuda\",\n",
        "        \"time_ms\": cu_ln_ms, \"peak_mem_mb\": cu_ln_mem,\n",
        "    })\n",
        "    rows.append({\n",
        "        \"op\": \"layernorm\", \"n\": n, \"m\": m, \"backend\": \"triton\",\n",
        "        \"time_ms\": tr_ln_ms, \"peak_mem_mb\": tr_ln_mem,\n",
        "    })\n",
        "\n",
        "    # --- Softmax benchmarking ---\n",
        "    _, pt_sm_ms, pt_sm_mem = profile_time_and_memory(lambda: F.softmax(x, dim=-1), repeat=50)\n",
        "    _, cu_sm_ms, cu_sm_mem = profile_time_and_memory(lambda: softmax_cuda(x), repeat=50)\n",
        "    _, tr_sm_ms, tr_sm_mem = profile_time_and_memory(lambda: softmax_triton_lastdim(x), repeat=50)\n",
        "\n",
        "    rows.append({\n",
        "        \"op\": \"softmax\", \"n\": n, \"m\": m, \"backend\": \"torch\",\n",
        "        \"time_ms\": pt_sm_ms, \"peak_mem_mb\": pt_sm_mem,\n",
        "    })\n",
        "    rows.append({\n",
        "        \"op\": \"softmax\", \"n\": n, \"m\": m, \"backend\": \"cuda\",\n",
        "        \"time_ms\": cu_sm_ms, \"peak_mem_mb\": cu_sm_mem,\n",
        "    })\n",
        "    rows.append({\n",
        "        \"op\": \"softmax\", \"n\": n, \"m\": m, \"backend\": \"triton\",\n",
        "        \"time_ms\": tr_sm_ms, \"peak_mem_mb\": tr_sm_mem,\n",
        "    })\n",
        "\n",
        "bench = pd.DataFrame(rows)\n",
        "os.makedirs(\"profiling/benchmark_results\", exist_ok=True)\n",
        "bench.to_csv(\"profiling/benchmark_results/microbench_ops.csv\", index=False)\n",
        "print(\"âœ… Saved: profiling/benchmark_results/microbench_ops.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B2laTiarHl_1",
      "metadata": {
        "id": "B2laTiarHl_1"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.profiler import profile, ProfilerActivity\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Replace your old profile_time_and_memory with this one ---\n",
        "def profile_time_and_memory(fn, *args, repeat: int = 50):\n",
        "    \"\"\"\n",
        "    Run fn(*args) 'repeat' times, return:\n",
        "      - last output\n",
        "      - avg time per run in ms\n",
        "      - peak memory (MB)\n",
        "    \"\"\"\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    out = None\n",
        "    for _ in range(repeat):\n",
        "        out = fn(*args)\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_ms = (time.perf_counter() - t0) * 1e3 / repeat\n",
        "\n",
        "    peak_mem_mb = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
        "    return out, elapsed_ms, peak_mem_mb\n",
        "\n",
        "\n",
        "def gpu_efficiency_proxy(fn, *args, iters: int = 20):\n",
        "    \"\"\"\n",
        "    Very rough 'GPU efficiency' proxy:\n",
        "      util% â‰ˆ (total CUDA kernel time / wall-clock active time) * 100\n",
        "    \"\"\"\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    with profile(activities=[ProfilerActivity.CUDA], record_shapes=False) as prof:\n",
        "        for _ in range(iters):\n",
        "            fn(*args)\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_s = time.perf_counter() - t0\n",
        "\n",
        "    # Sum CUDA kernel times from the profiler (microseconds â†’ ms)\n",
        "    cuda_ms = sum(e.cuda_time_total for e in prof.key_averages()) / 1e3\n",
        "    util_pct = (cuda_ms / (elapsed_s * 1e3)) * 100.0\n",
        "    return util_pct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SJq0sZrDHr1j",
      "metadata": {
        "id": "SJq0sZrDHr1j"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# Softmax sequence-length benchmark\n",
        "# ================================\n",
        "\n",
        "seq_lens = [256, 512, 1024]\n",
        "batch_sizes = [16, 32, 64]\n",
        "\n",
        "rows = []\n",
        "\n",
        "for B in batch_sizes:\n",
        "    for L in seq_lens:\n",
        "        x = torch.randn(B, L, device=device, dtype=torch.float32).contiguous()\n",
        "\n",
        "        # Torch softmax\n",
        "        _, t_torch, mem_torch = profile_time_and_memory(\n",
        "            lambda x: F.softmax(x, dim=-1), x, repeat=50\n",
        "        )\n",
        "        util_torch = gpu_efficiency_proxy(lambda x: F.softmax(x, dim=-1), x, iters=20)\n",
        "\n",
        "        # CUDA softmax\n",
        "        _, t_cuda, mem_cuda = profile_time_and_memory(\n",
        "            lambda x: softmax_cuda(x), x, repeat=50\n",
        "        )\n",
        "        util_cuda = gpu_efficiency_proxy(lambda x: softmax_cuda(x), x, iters=20)\n",
        "\n",
        "        # Triton softmax\n",
        "        _, t_triton, mem_triton = profile_time_and_memory(\n",
        "            lambda x: softmax_triton_lastdim(x), x, repeat=50\n",
        "        )\n",
        "        util_triton = gpu_efficiency_proxy(lambda x: softmax_triton_lastdim(x), x, iters=20)\n",
        "\n",
        "        tokens = B * L\n",
        "        rows += [\n",
        "            {\n",
        "                \"op\": \"softmax\",\n",
        "                \"backend\": \"torch\",\n",
        "                \"batch\": B,\n",
        "                \"seq_len\": L,\n",
        "                \"time_ms\": t_torch,\n",
        "                \"tokens_per_s\": tokens / (t_torch / 1e3),\n",
        "                \"peak_mem_mb\": mem_torch,\n",
        "                \"gpu_util_pct\": util_torch,\n",
        "            },\n",
        "            {\n",
        "                \"op\": \"softmax\",\n",
        "                \"backend\": \"cuda\",\n",
        "                \"batch\": B,\n",
        "                \"seq_len\": L,\n",
        "                \"time_ms\": t_cuda,\n",
        "                \"tokens_per_s\": tokens / (t_cuda / 1e3),\n",
        "                \"peak_mem_mb\": mem_cuda,\n",
        "                \"gpu_util_pct\": util_cuda,\n",
        "            },\n",
        "            {\n",
        "                \"op\": \"softmax\",\n",
        "                \"backend\": \"triton\",\n",
        "                \"batch\": B,\n",
        "                \"seq_len\": L,\n",
        "                \"time_ms\": t_triton,\n",
        "                \"tokens_per_s\": tokens / (t_triton / 1e3),\n",
        "                \"peak_mem_mb\": mem_triton,\n",
        "                \"gpu_util_pct\": util_triton,\n",
        "            },\n",
        "        ]\n",
        "\n",
        "df_seq = pd.DataFrame(rows)\n",
        "os.makedirs(\"profiling/benchmark_results\", exist_ok=True)\n",
        "df_seq.to_csv(\"profiling/benchmark_results/softmax_seq_bench.csv\", index=False)\n",
        "print(\"âœ… Saved: profiling/benchmark_results/softmax_seq_bench.csv\")\n",
        "df_seq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VfVuh8JOHxLy",
      "metadata": {
        "id": "VfVuh8JOHxLy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0KUjNyL3oM8Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0KUjNyL3oM8Y",
        "outputId": "5367cbfc-9e31-42d9-b8d4-0c333b16acc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ðŸš€ PERFORMANCE ANALYSIS\n",
            "============================================================\n",
            "\n",
            "ðŸ“Š SPEEDUP ANALYSIS (Triton vs PyTorch)\n",
            "----------------------------------------\n",
            "\n",
            "ðŸ“ˆ Benchmarks (Pivoted DataFrame):\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"print(\\\"\\\\n\\u2705 Saved pivoted benchmarks to profiling/benchmark_results/microbench_ops_pivoted\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"op\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"softmax\",\n          \"layernorm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52,\n        \"min\": 1,\n        \"max\": 128,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1373,\n        \"min\": 1024,\n        \"max\": 4096,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1024,\n          4096\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cuda_mem_mb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0569766823498283,\n        \"min\": 126.953125,\n        \"max\": 128.890625,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          126.953125,\n          128.890625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"torch_mem_mb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0570641534368674,\n        \"min\": 126.953125,\n        \"max\": 128.8916015625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          128.8916015625,\n          128.890625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"triton_mem_mb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0569766823498283,\n        \"min\": 126.953125,\n        \"max\": 128.890625,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          126.953125,\n          128.890625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cuda_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0028731345694043573,\n        \"min\": 0.029224959998828126,\n        \"max\": 0.0360746200021822,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0332094799978222,\n          0.029224959998828126\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"torch_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0065202566363477205,\n        \"min\": 0.014507599998978549,\n        \"max\": 0.029558160003944067,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.028179239998280536,\n          0.014507599998978549\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"triton_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.7156589793605543,\n        \"min\": 4.174072600008003,\n        \"max\": 13.55091860000357,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5.760186179995799,\n          5.706936080005107\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speedup\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0019752852037670564,\n        \"min\": 0.0013623401147195402,\n        \"max\": 0.0061863083063483796,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.004892071040367152,\n          0.0025420996127515005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_faster\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6ad58c6c-e130-4a90-81f4-09273ec5d74e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op</th>\n",
              "      <th>n</th>\n",
              "      <th>m</th>\n",
              "      <th>cuda_mem_mb</th>\n",
              "      <th>torch_mem_mb</th>\n",
              "      <th>triton_mem_mb</th>\n",
              "      <th>cuda_ms</th>\n",
              "      <th>torch_ms</th>\n",
              "      <th>triton_ms</th>\n",
              "      <th>speedup</th>\n",
              "      <th>is_faster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>layernorm</td>\n",
              "      <td>1</td>\n",
              "      <td>4096</td>\n",
              "      <td>126.953125</td>\n",
              "      <td>126.954102</td>\n",
              "      <td>126.953125</td>\n",
              "      <td>0.036075</td>\n",
              "      <td>0.029558</td>\n",
              "      <td>5.942384</td>\n",
              "      <td>0.004974</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>layernorm</td>\n",
              "      <td>32</td>\n",
              "      <td>4096</td>\n",
              "      <td>128.890625</td>\n",
              "      <td>128.891602</td>\n",
              "      <td>128.890625</td>\n",
              "      <td>0.033209</td>\n",
              "      <td>0.028179</td>\n",
              "      <td>5.760186</td>\n",
              "      <td>0.004892</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>layernorm</td>\n",
              "      <td>128</td>\n",
              "      <td>1024</td>\n",
              "      <td>128.867188</td>\n",
              "      <td>128.868164</td>\n",
              "      <td>128.867188</td>\n",
              "      <td>0.030607</td>\n",
              "      <td>0.025822</td>\n",
              "      <td>4.174073</td>\n",
              "      <td>0.006186</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>softmax</td>\n",
              "      <td>1</td>\n",
              "      <td>4096</td>\n",
              "      <td>126.953125</td>\n",
              "      <td>126.953125</td>\n",
              "      <td>126.953125</td>\n",
              "      <td>0.034930</td>\n",
              "      <td>0.018461</td>\n",
              "      <td>13.550919</td>\n",
              "      <td>0.001362</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>softmax</td>\n",
              "      <td>32</td>\n",
              "      <td>4096</td>\n",
              "      <td>128.890625</td>\n",
              "      <td>128.890625</td>\n",
              "      <td>128.890625</td>\n",
              "      <td>0.029225</td>\n",
              "      <td>0.014508</td>\n",
              "      <td>5.706936</td>\n",
              "      <td>0.002542</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ad58c6c-e130-4a90-81f4-09273ec5d74e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ad58c6c-e130-4a90-81f4-09273ec5d74e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ad58c6c-e130-4a90-81f4-09273ec5d74e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ef8be784-00b1-4b60-8677-779c0e591e1b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef8be784-00b1-4b60-8677-779c0e591e1b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ef8be784-00b1-4b60-8677-779c0e591e1b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          op    n     m  cuda_mem_mb  torch_mem_mb  triton_mem_mb   cuda_ms  \\\n",
              "0  layernorm    1  4096   126.953125    126.954102     126.953125  0.036075   \n",
              "1  layernorm   32  4096   128.890625    128.891602     128.890625  0.033209   \n",
              "2  layernorm  128  1024   128.867188    128.868164     128.867188  0.030607   \n",
              "3    softmax    1  4096   126.953125    126.953125     126.953125  0.034930   \n",
              "4    softmax   32  4096   128.890625    128.890625     128.890625  0.029225   \n",
              "\n",
              "   torch_ms  triton_ms   speedup  is_faster  \n",
              "0  0.029558   5.942384  0.004974      False  \n",
              "1  0.028179   5.760186  0.004892      False  \n",
              "2  0.025822   4.174073  0.006186      False  \n",
              "3  0.018461  13.550919  0.001362      False  \n",
              "4  0.014508   5.706936  0.002542      False  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average speedup (Triton vs PyTorch): 0.14x\n",
            "Triton faster than PyTorch in 0 out of 9 cases.\n",
            "\n",
            "Detailed Performance (ms):\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"print(\\\"\\\\n\\u2705 Saved pivoted benchmarks to profiling/benchmark_results/microbench_ops_pivoted\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"op\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"swish\",\n          \"softmax\",\n          \"layernorm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57,\n        \"min\": 1,\n        \"max\": 128,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          128,\n          32,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1536,\n        \"min\": 1024,\n        \"max\": 4096,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4096,\n          1024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"torch_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006461328660897264,\n        \"min\": 0.014507599998978549,\n        \"max\": 0.03245009999773174,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.014507599998978549,\n          0.029264200002216967\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cuda_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003702761549658756,\n        \"min\": 0.028531939997265,\n        \"max\": 0.04004008000265458,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.029224959998828126,\n          0.03097714000432461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"triton_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.499655719270423,\n        \"min\": 0.06081149999772606,\n        \"max\": 13.55091860000357,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          5.706936080005107,\n          0.0690165000014531\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speedup\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18474336699149538,\n        \"min\": 0.0013623401147195402,\n        \"max\": 0.4448300074926322,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.0025420996127515005,\n          0.424017445126902\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c6c8db89-a747-43e2-94e3-266bb38ca9b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op</th>\n",
              "      <th>n</th>\n",
              "      <th>m</th>\n",
              "      <th>torch_ms</th>\n",
              "      <th>cuda_ms</th>\n",
              "      <th>triton_ms</th>\n",
              "      <th>speedup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>swish</td>\n",
              "      <td>128</td>\n",
              "      <td>1024</td>\n",
              "      <td>0.027051</td>\n",
              "      <td>0.031148</td>\n",
              "      <td>0.060811</td>\n",
              "      <td>0.444830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>swish</td>\n",
              "      <td>32</td>\n",
              "      <td>4096</td>\n",
              "      <td>0.029264</td>\n",
              "      <td>0.030977</td>\n",
              "      <td>0.069017</td>\n",
              "      <td>0.424017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>softmax</td>\n",
              "      <td>128</td>\n",
              "      <td>1024</td>\n",
              "      <td>0.016464</td>\n",
              "      <td>0.028532</td>\n",
              "      <td>0.077682</td>\n",
              "      <td>0.211947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>swish</td>\n",
              "      <td>1</td>\n",
              "      <td>4096</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.040040</td>\n",
              "      <td>0.177519</td>\n",
              "      <td>0.182798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>layernorm</td>\n",
              "      <td>128</td>\n",
              "      <td>1024</td>\n",
              "      <td>0.025822</td>\n",
              "      <td>0.030607</td>\n",
              "      <td>4.174073</td>\n",
              "      <td>0.006186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>layernorm</td>\n",
              "      <td>1</td>\n",
              "      <td>4096</td>\n",
              "      <td>0.029558</td>\n",
              "      <td>0.036075</td>\n",
              "      <td>5.942384</td>\n",
              "      <td>0.004974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>layernorm</td>\n",
              "      <td>32</td>\n",
              "      <td>4096</td>\n",
              "      <td>0.028179</td>\n",
              "      <td>0.033209</td>\n",
              "      <td>5.760186</td>\n",
              "      <td>0.004892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>softmax</td>\n",
              "      <td>32</td>\n",
              "      <td>4096</td>\n",
              "      <td>0.014508</td>\n",
              "      <td>0.029225</td>\n",
              "      <td>5.706936</td>\n",
              "      <td>0.002542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>softmax</td>\n",
              "      <td>1</td>\n",
              "      <td>4096</td>\n",
              "      <td>0.018461</td>\n",
              "      <td>0.034930</td>\n",
              "      <td>13.550919</td>\n",
              "      <td>0.001362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6c8db89-a747-43e2-94e3-266bb38ca9b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6c8db89-a747-43e2-94e3-266bb38ca9b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6c8db89-a747-43e2-94e3-266bb38ca9b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-97b531ca-1b83-4201-a691-8218d1320e7a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97b531ca-1b83-4201-a691-8218d1320e7a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-97b531ca-1b83-4201-a691-8218d1320e7a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          op    n     m  torch_ms   cuda_ms  triton_ms   speedup\n",
              "8      swish  128  1024  0.027051  0.031148   0.060811  0.444830\n",
              "7      swish   32  4096  0.029264  0.030977   0.069017  0.424017\n",
              "5    softmax  128  1024  0.016464  0.028532   0.077682  0.211947\n",
              "6      swish    1  4096  0.032450  0.040040   0.177519  0.182798\n",
              "2  layernorm  128  1024  0.025822  0.030607   4.174073  0.006186\n",
              "0  layernorm    1  4096  0.029558  0.036075   5.942384  0.004974\n",
              "1  layernorm   32  4096  0.028179  0.033209   5.760186  0.004892\n",
              "4    softmax   32  4096  0.014508  0.029225   5.706936  0.002542\n",
              "3    softmax    1  4096  0.018461  0.034930  13.550919  0.001362"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory Usage (MB):\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"print(\\\"\\\\n\\u2705 Saved pivoted benchmarks to profiling/benchmark_results/microbench_ops_pivoted\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"op\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"softmax\",\n          \"layernorm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52,\n        \"min\": 1,\n        \"max\": 128,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1373,\n        \"min\": 1024,\n        \"max\": 4096,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1024,\n          4096\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"torch_mem_mb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0570641534368674,\n        \"min\": 126.953125,\n        \"max\": 128.8916015625,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          128.8916015625,\n          128.890625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cuda_mem_mb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0569766823498283,\n        \"min\": 126.953125,\n        \"max\": 128.890625,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          126.953125,\n          128.890625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"triton_mem_mb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0569766823498283,\n        \"min\": 126.953125,\n        \"max\": 128.890625,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          126.953125,\n          128.890625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-420d82e8-06c0-4b0b-a9e6-2e0d055a45e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op</th>\n",
              "      <th>n</th>\n",
              "      <th>m</th>\n",
              "      <th>torch_mem_mb</th>\n",
              "      <th>cuda_mem_mb</th>\n",
              "      <th>triton_mem_mb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>layernorm</td>\n",
              "      <td>1</td>\n",
              "      <td>4096</td>\n",
              "      <td>126.954102</td>\n",
              "      <td>126.953125</td>\n",
              "      <td>126.953125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>layernorm</td>\n",
              "      <td>32</td>\n",
              "      <td>4096</td>\n",
              "      <td>128.891602</td>\n",
              "      <td>128.890625</td>\n",
              "      <td>128.890625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>layernorm</td>\n",
              "      <td>128</td>\n",
              "      <td>1024</td>\n",
              "      <td>128.868164</td>\n",
              "      <td>128.867188</td>\n",
              "      <td>128.867188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>softmax</td>\n",
              "      <td>1</td>\n",
              "      <td>4096</td>\n",
              "      <td>126.953125</td>\n",
              "      <td>126.953125</td>\n",
              "      <td>126.953125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>softmax</td>\n",
              "      <td>32</td>\n",
              "      <td>4096</td>\n",
              "      <td>128.890625</td>\n",
              "      <td>128.890625</td>\n",
              "      <td>128.890625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-420d82e8-06c0-4b0b-a9e6-2e0d055a45e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-420d82e8-06c0-4b0b-a9e6-2e0d055a45e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-420d82e8-06c0-4b0b-a9e6-2e0d055a45e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6966a0d8-77a2-46a6-8f4b-85cc2e684d1a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6966a0d8-77a2-46a6-8f4b-85cc2e684d1a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6966a0d8-77a2-46a6-8f4b-85cc2e684d1a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          op    n     m  torch_mem_mb  cuda_mem_mb  triton_mem_mb\n",
              "0  layernorm    1  4096    126.954102   126.953125     126.953125\n",
              "1  layernorm   32  4096    128.891602   128.890625     128.890625\n",
              "2  layernorm  128  1024    128.868164   128.867188     128.867188\n",
              "3    softmax    1  4096    126.953125   126.953125     126.953125\n",
              "4    softmax   32  4096    128.890625   128.890625     128.890625"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Saved pivoted benchmarks to profiling/benchmark_results/microbench_ops_pivoted.csv\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸš€ PERFORMANCE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create a pivoted DataFrame for easier analysis\n",
        "bench_pivot = bench.pivot_table(\n",
        "    index=['op', 'n', 'm'],\n",
        "    columns='backend',\n",
        "    values=['time_ms', 'peak_mem_mb']\n",
        ").reset_index()\n",
        "\n",
        "# Flatten the multi-level columns\n",
        "bench_pivot.columns = ['_'.join(col).strip() if col[1] else col[0] for col in bench_pivot.columns.values]\n",
        "\n",
        "# Rename columns to match expected names for 'torch_ms', 'triton_ms', etc.\n",
        "bench_pivot = bench_pivot.rename(columns={\n",
        "    'time_ms_torch': 'torch_ms',\n",
        "    'time_ms_cuda': 'cuda_ms',\n",
        "    'time_ms_triton': 'triton_ms',\n",
        "    'peak_mem_mb_torch': 'torch_mem_mb',\n",
        "    'peak_mem_mb_cuda': 'cuda_mem_mb',\n",
        "    'peak_mem_mb_triton': 'triton_mem_mb'\n",
        "})\n",
        "\n",
        "# 1. Speedup Analysis\n",
        "print(\"\\nðŸ“Š SPEEDUP ANALYSIS (Triton vs PyTorch)\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Calculate speedups\n",
        "bench_pivot['speedup'] = bench_pivot['torch_ms'] / bench_pivot['triton_ms']\n",
        "bench_pivot['is_faster'] = bench_pivot['speedup'] > 1.0\n",
        "\n",
        "# Summary statistics\n",
        "avg_speedup = bench_pivot['speedup'].mean()\n",
        "# ... (rest of the performance analysis code)\n",
        "\n",
        "# Display the pivoted DataFrame for debugging/review\n",
        "print(\"\\nðŸ“ˆ Benchmarks (Pivoted DataFrame):\")\n",
        "display(bench_pivot.head())\n",
        "\n",
        "print(f\"\\nAverage speedup (Triton vs PyTorch): {avg_speedup:.2f}x\")\n",
        "print(f\"Triton faster than PyTorch in {bench_pivot['is_faster'].sum()} out of {len(bench_pivot)} cases.\")\n",
        "\n",
        "# 2. Detailed Performance Comparison\n",
        "print(\"\\nDetailed Performance (ms):\")\n",
        "display(bench_pivot[['op', 'n', 'm', 'torch_ms', 'cuda_ms', 'triton_ms', 'speedup']].sort_values(by='speedup', ascending=False).head(10))\n",
        "\n",
        "# 3. Memory Usage Analysis\n",
        "print(\"\\nMemory Usage (MB):\")\n",
        "display(bench_pivot[['op', 'n', 'm', 'torch_mem_mb', 'cuda_mem_mb', 'triton_mem_mb']].head())\n",
        "\n",
        "# Optionally, you can save this pivoted dataframe as well\n",
        "bench_pivot.to_csv(\"profiling/benchmark_results/microbench_ops_pivoted.csv\", index=False)\n",
        "print(\"\\nâœ… Saved pivoted benchmarks to profiling/benchmark_results/microbench_ops_pivoted.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fd0b089",
      "metadata": {
        "id": "5fd0b089"
      },
      "source": [
        "## 0ï¸âƒ£ GPU Check for CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KBI9ueNAG1_f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBI9ueNAG1_f",
        "outputId": "6d36fa51-4e51-47e1-e95a-efccfc97fbe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available (torch): True\n",
            "Thu Nov 20 20:37:01 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0             31W /   70W |     944MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, sys, subprocess, torch\n",
        "print(\"CUDA available (torch):\", torch.cuda.is_available())\n",
        "!nvidia-smi || true\n",
        "!nvcc --version || true"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6f8f5c8",
      "metadata": {
        "id": "f6f8f5c8"
      },
      "source": [
        "## 1ï¸âƒ£ Write `cuda_kernels.cu`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rpocAVg-i20E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpocAVg-i20E",
        "outputId": "3b60c67c-ecc4-4703-9e40-a5f026d32051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote cuda_kernels.cu\n"
          ]
        }
      ],
      "source": [
        "# cuda_kernels.cu\n",
        "# Fixed CUDA kernels for JLR Triton vs CUDA demo\n",
        "# Compile: nvcc -O3 -std=c++14 -Xcompiler -fPIC --shared cuda_kernels.cu -o cuda_kernels.so\n",
        "\n",
        "cuda_src = r\"\"\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <cuda_fp16.h>\n",
        "#include <cmath>\n",
        "#include <stdio.h>\n",
        "\n",
        "#define CUDA_CHECK(call) \\\n",
        "    do { \\\n",
        "        cudaError_t err = call; \\\n",
        "        if (err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"CUDA error in %s:%d: %s\\n\", __FILE__, __LINE__, \\\n",
        "                    cudaGetErrorString(err)); \\\n",
        "            exit(EXIT_FAILURE); \\\n",
        "        } \\\n",
        "    } while(0)\n",
        "\n",
        "// ============================================================================\n",
        "// Utility reduction helpers\n",
        "// ============================================================================\n",
        "template<int BLOCK_SIZE>\n",
        "__device__ float warp_reduce_sum(float val) {\n",
        "    for (int offset = 16; offset > 0; offset >>= 1)\n",
        "        val += __shfl_down_sync(0xffffffff, val, offset);\n",
        "    return val;\n",
        "}\n",
        "\n",
        "__device__ inline float warp_reduce_max(float v) {\n",
        "    for (int off = 16; off > 0; off >>= 1)\n",
        "        v = fmaxf(v, __shfl_down_sync(0xffffffff, v, off));\n",
        "    return v;\n",
        "}\n",
        "\n",
        "__device__ inline float block_allreduce_sum(float val, float* shared) {\n",
        "    val = warp_reduce_sum<32>(val);\n",
        "    int lane = threadIdx.x & 31;\n",
        "    int warp = threadIdx.x >> 5;\n",
        "    if (lane == 0) shared[warp] = val;\n",
        "    __syncthreads();\n",
        "    float out = 0.0;\n",
        "    if (warp == 0) {\n",
        "        out = (lane < (blockDim.x + 31)/32) ? shared[lane] : 0.0;\n",
        "        out = warp_reduce_sum<32>(out);\n",
        "        if (lane == 0) shared[0] = out;\n",
        "    }\n",
        "    __syncthreads();\n",
        "    return shared[0];\n",
        "}\n",
        "\n",
        "__device__ inline float block_allreduce_max(float val, float* shared) {\n",
        "    val = warp_reduce_max(val);\n",
        "    int lane = threadIdx.x & 31;\n",
        "    int warp = threadIdx.x >> 5;\n",
        "    if (lane == 0) shared[warp] = val;\n",
        "    __syncthreads();\n",
        "    float out = -INFINITY;\n",
        "    if (warp == 0) {\n",
        "        out = (lane < (blockDim.x + 31)/32) ? shared[lane] : -INFINITY;\n",
        "        out = warp_reduce_max(out);\n",
        "        if (lane == 0) shared[0] = out;\n",
        "    }\n",
        "    __syncthreads();\n",
        "    return shared[0];\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 1. ReLU\n",
        "// ============================================================================\n",
        "__global__ void relu_kernel(const float* x, float* y, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) y[i] = fmaxf(x[i], 0.0);\n",
        "}\n",
        "extern \"C\" void relu_cuda(const float* x, float* y, int n, cudaStream_t stream=0) {\n",
        "    int t = 256, b = (n + t - 1)/t;\n",
        "    relu_kernel<<<b,t,0,stream>>>(x,y,n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 2. Sigmoid\n",
        "// ============================================================================\n",
        "__global__ void sigmoid_kernel(const float* x, float* y, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) y[i] = 1.0 / (1.0 + expf(-x[i]));\n",
        "}\n",
        "extern \"C\" void sigmoid_cuda(const float* x, float* y, int n, cudaStream_t stream=0) {\n",
        "    int t = 256, b = (n + t - 1)/t;\n",
        "    sigmoid_kernel<<<b,t,0,stream>>>(x,y,n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 3. GELU (tanh approximation)\n",
        "// ============================================================================\n",
        "__global__ void gelu_kernel(const float* x, float* y, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        float v = x[i];\n",
        "        float x3 = v*v*v;\n",
        "        float inner = 0.7978845608 * (v + 0.044715 * x3);\n",
        "        y[i] = 0.5 * v * (1.0 + tanhf(inner));\n",
        "    }\n",
        "}\n",
        "extern \"C\" void gelu_cuda(const float* x, float* y, int n, cudaStream_t stream=0) {\n",
        "    int t = 256, b = (n + t - 1)/t;\n",
        "    gelu_kernel<<<b,t,0,stream>>>(x,y,n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 4. Swish\n",
        "// ============================================================================\n",
        "__global__ void swish_kernel(const float* x, float* y, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        float v = x[i];\n",
        "        float sig = 1.0 / (1.0 + expf(-v));\n",
        "        y[i] = v * sig;\n",
        "    }\n",
        "}\n",
        "extern \"C\" void swish_cuda(const float* x, float* y, int n, cudaStream_t stream=0) {\n",
        "    int t = 256, b = (n + t - 1)/t;\n",
        "    swish_kernel<<<b,t,0,stream>>>(x,y,n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 5. LayerNorm (broadcast-corrected)\n",
        "// ============================================================================\n",
        "template<int BLOCK>\n",
        "__global__ void layernorm_kernel(\n",
        "    const float* x, float* y,\n",
        "    const float* gamma, const float* beta,\n",
        "    int N, int D, float eps)\n",
        "{\n",
        "    int row = blockIdx.x;\n",
        "    if (row >= N) return;\n",
        "    const float* xrow = x + row*D;\n",
        "    float* yrow = y + row*D;\n",
        "\n",
        "    __shared__ float shared[32];\n",
        "    float sum = 0.0;\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) sum += xrow[i];\n",
        "    float total_sum = block_allreduce_sum(sum, shared);\n",
        "    float mean = total_sum / D;\n",
        "\n",
        "    float var_local = 0.0;\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
        "        float d = xrow[i] - mean;\n",
        "        var_local += d*d;\n",
        "    }\n",
        "    float total_var = block_allreduce_sum(var_local, shared);\n",
        "    float inv_std = rsqrtf(total_var / D + eps);\n",
        "\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
        "        float norm = (xrow[i] - mean) * inv_std;\n",
        "        yrow[i] = gamma[i]*norm + beta[i];\n",
        "    }\n",
        "}\n",
        "extern \"C\" void layernorm_cuda(\n",
        "    const float* x, float* y,\n",
        "    const float* gamma, const float* beta,\n",
        "    int N, int D, float eps, cudaStream_t stream=0)\n",
        "{\n",
        "    int t=256;\n",
        "    layernorm_kernel<256><<<N,t,0,stream>>>(x,y,gamma,beta,N,D,eps);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 6. Softmax (stable + broadcast fixed)\n",
        "// ============================================================================\n",
        "template<int BLOCK>\n",
        "__global__ void softmax_kernel(const float* x, float* y, int N, int D)\n",
        "{\n",
        "    int row = blockIdx.x;\n",
        "    if (row >= N) return;\n",
        "    const float* xr = x + row*D;\n",
        "    float* yr = y + row*D;\n",
        "    __shared__ float scratch[32];\n",
        "\n",
        "    float local_max=-INFINITY;\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x)\n",
        "        local_max=fmaxf(local_max,xr[i]);\n",
        "    float row_max=block_allreduce_max(local_max,scratch);\n",
        "\n",
        "    float local_sum=0.0;\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x){\n",
        "        float e=expf(xr[i]-row_max);\n",
        "        yr[i]=e;\n",
        "        local_sum+=e;\n",
        "    }\n",
        "    float row_sum=block_allreduce_sum(local_sum,scratch);\n",
        "\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x)\n",
        "        yr[i]/=row_sum;\n",
        "}\n",
        "extern \"C\" void softmax_cuda(const float* x, float* y, int N, int D, cudaStream_t stream=0){\n",
        "    int t=256;\n",
        "    softmax_kernel<256><<<N,t,0,stream>>>(x,y,N,D);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 7. EvoNorm-B0 (already correct)\n",
        "// ============================================================================\n",
        "__global__ void evonorm_b0_kernel(\n",
        "    const float* x,const float* v,float* y,\n",
        "    int N,int C,int H,int W,int groups,float eps)\n",
        "{\n",
        "    int n=blockIdx.x/groups;\n",
        "    int g=blockIdx.x%groups;\n",
        "    if(n>=N)return;\n",
        "    int Cg=C/groups,HW=H*W,group_size=Cg*HW;\n",
        "    int base=n*C*HW+g*Cg*HW;\n",
        "    __shared__ float s_mean,s_var;\n",
        "    float sum=0.0,sum_sq=0.0;\n",
        "    for(int i=threadIdx.x;i<group_size;i+=blockDim.x){\n",
        "        float val=x[base+i];\n",
        "        sum+=val; sum_sq+=val*val;\n",
        "    }\n",
        "    __shared__ float buf[256];\n",
        "    buf[threadIdx.x]=sum; __syncthreads();\n",
        "    for(int s=blockDim.x/2;s>0;s>>=1){\n",
        "        if(threadIdx.x<s)buf[threadIdx.x]+=buf[threadIdx.x+s];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if(threadIdx.x==0)s_mean=buf[0]/group_size;\n",
        "    __syncthreads();\n",
        "    buf[threadIdx.x]=sum_sq; __syncthreads();\n",
        "    for(int s=blockDim.x/2;s>0;s>>=1){\n",
        "        if(threadIdx.x<s)buf[threadIdx.x]+=buf[threadIdx.x+s];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if(threadIdx.x==0){\n",
        "        float mean_sq=buf[0]/group_size;\n",
        "        s_var=mean_sq-s_mean*s_mean;\n",
        "    }\n",
        "    __syncthreads();\n",
        "    float inv_std=rsqrtf(s_var+eps);\n",
        "    for(int i=threadIdx.x;i<group_size;i+=blockDim.x){\n",
        "        int global_idx=base+i;\n",
        "        int c_in_group=i/HW;\n",
        "        int c_global=g*Cg+c_in_group;\n",
        "        float val=x[global_idx];\n",
        "        float vval=v[c_global];\n",
        "        float sig=1.0/(1.0+expf(-vval*val));\n",
        "        y[global_idx]=val*sig*inv_std;\n",
        "    }\n",
        "}\n",
        "extern \"C\" void evonorm_b0_cuda(\n",
        "    const float* x,const float* v,float* y,\n",
        "    int N,int C,int H,int W,int groups,float eps,cudaStream_t stream=0)\n",
        "{\n",
        "    int t=256,b=N*groups;\n",
        "    evonorm_b0_kernel<<<b,t,0,stream>>>(x,v,y,N,C,H,W,groups,eps);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 8. Fused LayerNorm + GELU (broadcast fixed)\n",
        "// ============================================================================\n",
        "template<int BLOCK>\n",
        "__global__ void layernorm_gelu_fused_kernel(\n",
        "    const float* x,float* y,const float* gamma,const float* beta,\n",
        "    int N,int D,float eps)\n",
        "{\n",
        "    int row=blockIdx.x;\n",
        "    if(row>=N)return;\n",
        "    const float* xr=x+row*D;\n",
        "    float* yr=y+row*D;\n",
        "    __shared__ float scratch[32];\n",
        "\n",
        "    float sum=0.0;\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x) sum+=xr[i];\n",
        "    float total_sum=block_allreduce_sum(sum,scratch);\n",
        "    float mean=total_sum/D;\n",
        "\n",
        "    float var_local=0.0;\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x){\n",
        "        float d=xr[i]-mean;\n",
        "        var_local+=d*d;\n",
        "    }\n",
        "    float total_var=block_allreduce_sum(var_local,scratch);\n",
        "    float inv_std=rsqrtf(total_var/D+eps);\n",
        "\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x){\n",
        "        float norm=(xr[i]-mean)*inv_std;\n",
        "        float a=gamma[i]*norm+beta[i];\n",
        "        float a3=a*a*a;\n",
        "        float inner=0.7978845608*(a+0.044715*a3);\n",
        "        yr[i]=0.5*a*(1.0+tanhf(inner));\n",
        "    }\n",
        "}\n",
        "extern \"C\" void layernorm_gelu_fused_cuda(\n",
        "    const float* x,float* y,const float* gamma,const float* beta,\n",
        "    int N,int D,float eps,cudaStream_t stream=0)\n",
        "{\n",
        "    int t=256;\n",
        "    layernorm_gelu_fused_kernel<256><<<N,t,0,stream>>>(x,y,gamma,beta,N,D,eps);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\"\"\"\n",
        "with open(\"cuda_kernels.cu\", \"w\") as f:\n",
        "    f.write(cuda_src)\n",
        "print(\"Wrote cuda_kernels.cu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a65093d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a65093d",
        "outputId": "dba18fdc-da6c-43db-fe71-d2d51cc7891f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rwxr-xr-x 1 root root 1.2M Nov 20 20:37 cuda_kernels.so\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Build a fat binary for several common archs\n",
        "!nvcc -O3 -std=c++14 -Xcompiler -fPIC --shared cuda_kernels.cu -o cuda_kernels.so -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90\n",
        "\n",
        "!ls -lh cuda_kernels.so\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6c57637",
      "metadata": {
        "id": "f6c57637"
      },
      "source": [
        "## 3ï¸âƒ£ Load `.so` and test vs PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0c0519c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0c0519c",
        "outputId": "7702c8a8-53d8-445c-bdfd-1b9bf050b95d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "âœ… ReLU               max|diff|=0.000e+00\n",
            "âœ… Sigmoid            max|diff|=0.000e+00\n",
            "âŒ GELU approx        max|diff|=4.735e-04\n",
            "âœ… Swish              max|diff|=0.000e+00\n",
            "âœ… LayerNorm          max|diff|=0.000e+00\n",
            "âœ… Softmax            max|diff|=0.000e+00\n",
            "âœ… EvoNorm-B0         max|diff|=0.000e+00\n",
            "âœ… LN+GELU fused      max|diff|=0.000e+00\n",
            "\n",
            "âœ… Done.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import ctypes, torch, numpy as np, pandas as pd, time, os\n",
        "\n",
        "# Ensure cuda_kernels.cu is written before compilation\n",
        "cuda_src = r\"\"\"\n",
        "#include <cuda_runtime.h>\n",
        "#include <cuda_fp16.h>\n",
        "#include <cmath>\n",
        "#include <stdio.h>\n",
        "\n",
        "#define CUDA_CHECK(call) \\\n",
        "    do { \\\n",
        "        cudaError_t err = call; \\\n",
        "        if (err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"CUDA error in %s:%d: %s\\n\", __FILE__, __LINE__, \\\n",
        "                    cudaGetErrorString(err)); \\\n",
        "            exit(EXIT_FAILURE); \\\n",
        "        } \\\n",
        "    } while(0)\n",
        "\n",
        "// ============================================================================\n",
        "// Utility reduction helpers\n",
        "// ============================================================================\n",
        "template<int BLOCK_SIZE>\n",
        "__device__ float warp_reduce_sum(float val) {\n",
        "    for (int offset = 16; offset > 0; offset >>= 1)\n",
        "        val += __shfl_down_sync(0xffffffff, val, offset);\n",
        "    return val;\n",
        "}\n",
        "\n",
        "__device__ inline float warp_reduce_max(float v) {\n",
        "    for (int off = 16; off > 0; off >>= 1)\n",
        "        v = fmaxf(v, __shfl_down_sync(0xffffffff, v, off));\n",
        "    return v;\n",
        "}\n",
        "\n",
        "__device__ inline float block_allreduce_sum(float val, float* shared) {\n",
        "    val = warp_reduce_sum<32>(val);\n",
        "    int lane = threadIdx.x & 31;\n",
        "    int warp = threadIdx.x >> 5;\n",
        "    if (lane == 0) shared[warp] = val;\n",
        "    __syncthreads();\n",
        "    float out = 0.0;\n",
        "    if (warp == 0) {\n",
        "        out = (lane < (blockDim.x + 31)/32) ? shared[lane] : 0.0;\n",
        "        out = warp_reduce_sum<32>(out);\n",
        "        if (lane == 0) shared[0] = out;\n",
        "    }\n",
        "    __syncthreads();\n",
        "    return shared[0];\n",
        "}\n",
        "\n",
        "__device__ inline float block_allreduce_max(float val, float* shared) {\n",
        "    val = warp_reduce_max(val);\n",
        "    int lane = threadIdx.x & 31;\n",
        "    int warp = threadIdx.x >> 5;\n",
        "    if (lane == 0) shared[warp] = val;\n",
        "    __syncthreads();\n",
        "    float out = -INFINITY;\n",
        "    if (warp == 0) {\n",
        "        out = (lane < (blockDim.x + 31)/32) ? shared[lane] : -INFINITY;\n",
        "        out = warp_reduce_max(out);\n",
        "        if (lane == 0) shared[0] = out;\n",
        "    }\n",
        "    __syncthreads();\n",
        "    return shared[0];\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 1. ReLU\n",
        "// ============================================================================\n",
        "__global__ void relu_kernel(const float* x, float* y, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) y[i] = fmaxf(x[i], 0.0);\n",
        "}\n",
        "extern \"C\" void relu_cuda(const float* x, float* y, int n, cudaStream_t stream=0) {\n",
        "    int t = 256, b = (n + t - 1)/t;\n",
        "    relu_kernel<<<b,t,0,stream>>>(x,y,n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 2. Sigmoid\n",
        "// ============================================================================\n",
        "__global__ void sigmoid_kernel(const float* x, float* y, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) y[i] = 1.0 / (1.0 + expf(-x[i]));\n",
        "}\n",
        "extern \"C\" void sigmoid_cuda(const float* x, float* y, int n, cudaStream_t stream=0) {\n",
        "    int t = 256, b = (n + t - 1)/t;\n",
        "    sigmoid_kernel<<<b,t,0,stream>>>(x,y,n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 3. GELU (tanh approximation)\n",
        "// ============================================================================\n",
        "__global__ void gelu_kernel(const float* x, float* y, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        float v = x[i];\n",
        "        float x3 = v*v*v;\n",
        "        float inner = 0.7978845608 * (v + 0.044715 * x3);\n",
        "        y[i] = 0.5 * v * (1.0 + tanhf(inner));\n",
        "    }\n",
        "}\n",
        "extern \"C\" void gelu_cuda(const float* x, float* y, int n, cudaStream_t stream=0) {\n",
        "    int t = 256, b = (n + t - 1)/t;\n",
        "    gelu_kernel<<<b,t,0,stream>>>(x,y,n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 4. Swish\n",
        "// ============================================================================\n",
        "__global__ void swish_kernel(const float* x, float* y, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        float v = x[i];\n",
        "        float sig = 1.0 / (1.0 + expf(-v));\n",
        "        y[i] = v * sig;\n",
        "    }\n",
        "}\n",
        "extern \"C\" void swish_cuda(const float* x, float* y, int n, cudaStream_t stream=0) {\n",
        "    int t = 256, b = (n + t - 1)/t;\n",
        "    swish_kernel<<<b,t,0,stream>>>(x,y,n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 5. LayerNorm (broadcast-corrected)\n",
        "// ============================================================================\n",
        "template<int BLOCK>\n",
        "__global__ void layernorm_kernel(\n",
        "    const float* x, float* y,\n",
        "    const float* gamma, const float* beta,\n",
        "    int N, int D, float eps)\n",
        "{\n",
        "    int row = blockIdx.x;\n",
        "    if (row >= N) return;\n",
        "    const float* xrow = x + row*D;\n",
        "    float* yrow = y + row*D;\n",
        "\n",
        "    __shared__ float shared[32];\n",
        "    float sum = 0.0;\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) sum += xrow[i];\n",
        "    float total_sum = block_allreduce_sum(sum, shared);\n",
        "    float mean = total_sum / D;\n",
        "\n",
        "    float var_local = 0.0;\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
        "        float d = xrow[i] - mean;\n",
        "        var_local += d*d;\n",
        "    }\n",
        "    float total_var = block_allreduce_sum(var_local, shared);\n",
        "    float inv_std = rsqrtf(total_var / D + eps);\n",
        "\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
        "        float norm = (xrow[i] - mean) * inv_std;\n",
        "        yrow[i] = gamma[i]*norm + beta[i];\n",
        "    }\n",
        "}\n",
        "extern \"C\" void layernorm_cuda(\n",
        "    const float* x, float* y,\n",
        "    const float* gamma, const float* beta,\n",
        "    int N, int D, float eps, cudaStream_t stream=0)\n",
        "{\n",
        "    int t=256;\n",
        "    layernorm_kernel<256><<<N,t,0,stream>>>(x,y,gamma,beta,N,D,eps);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 6. Softmax (stable + broadcast fixed)\n",
        "// ============================================================================\n",
        "template<int BLOCK>\n",
        "__global__ void softmax_kernel(const float* x, float* y, int N, int D)\n",
        "{\n",
        "    int row = blockIdx.x;\n",
        "    if (row >= N) return;\n",
        "    const float* xr = x + row*D;\n",
        "    float* yr = y + row*D;\n",
        "    __shared__ float scratch[32];\n",
        "\n",
        "    float local_max=-INFINITY;\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x)\n",
        "        local_max=fmaxf(local_max,xr[i]);\n",
        "    float row_max=block_allreduce_max(local_max,scratch);\n",
        "\n",
        "    float local_sum=0.0;\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x){\n",
        "        float e=expf(xr[i]-row_max);\n",
        "        yr[i]=e;\n",
        "        local_sum+=e;\n",
        "    }\n",
        "    float row_sum=block_allreduce_sum(local_sum,scratch);\n",
        "\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x)\n",
        "        yr[i]/=row_sum;\n",
        "}\n",
        "extern \"C\" void softmax_cuda(const float* x, float* y, int N, int D, cudaStream_t stream=0){\n",
        "    int t=256;\n",
        "    softmax_kernel<256><<<N,t,0,stream>>>(x,y,N,D);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 7. EvoNorm-B0 (already correct)\n",
        "// ============================================================================\n",
        "__global__ void evonorm_b0_kernel(\n",
        "    const float* x,const float* v,float* y,\n",
        "    int N,int C,int H,int W,int groups,float eps)\n",
        "{\n",
        "    int n=blockIdx.x/groups;\n",
        "    int g=blockIdx.x%groups;\n",
        "    if(n>=N)return;\n",
        "    int Cg=C/groups,HW=H*W,group_size=Cg*HW;\n",
        "    int base=n*C*HW+g*Cg*HW;\n",
        "    __shared__ float s_mean,s_var;\n",
        "    float sum=0.0,sum_sq=0.0;\n",
        "    for(int i=threadIdx.x;i<group_size;i+=blockDim.x){\n",
        "        float val=x[base+i];\n",
        "        sum+=val; sum_sq+=val*val;\n",
        "    }\n",
        "    __shared__ float buf[256];\n",
        "    buf[threadIdx.x]=sum; __syncthreads();\n",
        "    for(int s=blockDim.x/2;s>0;s>>=1){\n",
        "        if(threadIdx.x<s)buf[threadIdx.x]+=buf[threadIdx.x+s];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if(threadIdx.x==0)s_mean=buf[0]/group_size;\n",
        "    __syncthreads();\n",
        "    buf[threadIdx.x]=sum_sq; __syncthreads();\n",
        "    for(int s=blockDim.x/2;s>0;s>>=1){\n",
        "        if(threadIdx.x<s)buf[threadIdx.x]+=buf[threadIdx.x+s];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if(threadIdx.x==0){\n",
        "        float mean_sq=buf[0]/group_size;\n",
        "        s_var=mean_sq-s_mean*s_mean;\n",
        "    }\n",
        "    __syncthreads();\n",
        "    float inv_std=rsqrtf(s_var+eps);\n",
        "    for(int i=threadIdx.x;i<group_size;i+=blockDim.x){\n",
        "        int global_idx=base+i;\n",
        "        int c_in_group=i/HW;\n",
        "        int c_global=g*Cg+c_in_group;\n",
        "        float val=x[global_idx];\n",
        "        float vval=v[c_global];\n",
        "        float sig=1.0/(1.0+expf(-vval*val));\n",
        "        y[global_idx]=val*sig*inv_std;\n",
        "    }\n",
        "}\n",
        "extern \"C\" void evonorm_b0_cuda(\n",
        "    const float* x,const float* v,float* y,\n",
        "    int N,int C,int H,int W,int groups,float eps,cudaStream_t stream=0)\n",
        "{\n",
        "    int t=256,b=N*groups;\n",
        "    evonorm_b0_kernel<<<b,t,0,stream>>>(x,v,y,N,C,H,W,groups,eps);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "// ============================================================================\n",
        "// 8. Fused LayerNorm + GELU (broadcast fixed)\n",
        "// ============================================================================\n",
        "template<int BLOCK>\n",
        "__global__ void layernorm_gelu_fused_kernel(\n",
        "    const float* x,float* y,const float* gamma,const float* beta,\n",
        "    int N,int D,float eps)\n",
        "{\n",
        "    int row=blockIdx.x;\n",
        "    if(row>=N)return;\n",
        "    const float* xr=x+row*D;\n",
        "    float* yr=y+row*D;\n",
        "    __shared__ float scratch[32];\n",
        "\n",
        "    float sum=0.0;\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x) sum+=xr[i];\n",
        "    float total_sum=block_allreduce_sum(sum,scratch);\n",
        "    float mean=total_sum/D;\n",
        "\n",
        "    float var_local=0.0;\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x){\n",
        "        float d=xr[i]-mean;\n",
        "        var_local+=d*d;\n",
        "    }\n",
        "    float total_var=block_allreduce_sum(var_local,scratch);\n",
        "    float inv_std=rsqrtf(total_var/D+eps);\n",
        "\n",
        "    for(int i=threadIdx.x;i<D;i+=blockDim.x){\n",
        "        float norm=(xr[i]-mean)*inv_std;\n",
        "        float a=gamma[i]*norm+beta[i];\n",
        "        float a3=a*a*a;\n",
        "        float inner=0.7978845608*(a+0.044715*a3);\n",
        "        yr[i]=0.5*a*(1.0+tanhf(inner));\n",
        "    }\n",
        "}\n",
        "extern \"C\" void layernorm_gelu_fused_cuda(\n",
        "    const float* x,float* y,const float* gamma,const float* beta,\n",
        "    int N,int D,float eps,cudaStream_t stream=0)\n",
        "{\n",
        "    int t=256;\n",
        "    layernorm_gelu_fused_kernel<256><<<N,t,0,stream>>>(x,y,gamma,beta,N,D,eps);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\"\"\"\n",
        "with open(\"cuda_kernels.cu\", \"w\") as f:\n",
        "    f.write(cuda_src)\n",
        "\n",
        "# Compile the CUDA kernels\n",
        "!nvcc -O3 -std=c++14 -Xcompiler -fPIC --shared cuda_kernels.cu -o cuda_kernels.so -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90\n",
        "\n",
        "lib = ctypes.cdll.LoadLibrary(\"./cuda_kernels.so\")\n",
        "c_void_p, c_int, c_float = ctypes.c_void_p, ctypes.c_int, ctypes.c_float\n",
        "\n",
        "def dev_ptr(t: torch.Tensor):\n",
        "    assert t.is_cuda and t.dtype == torch.float32 and t.is_contiguous()\n",
        "    return c_void_p(t.data_ptr())\n",
        "\n",
        "# Prototypes\n",
        "for fn in [\"relu_cuda\", \"sigmoid_cuda\", \"gelu_cuda\", \"swish_cuda\"]:\n",
        "    f = getattr(lib, fn)\n",
        "    f.argtypes = [c_void_p, c_void_p, c_int, c_void_p]\n",
        "    f.restype = None\n",
        "\n",
        "lib.layernorm_cuda.argtypes = [c_void_p, c_void_p, c_void_p, c_void_p, c_int, c_int, c_float, c_void_p]\n",
        "lib.layernorm_cuda.restype = None\n",
        "lib.softmax_cuda.argtypes = [c_void_p, c_void_p, c_int, c_int, c_void_p]\n",
        "lib.softmax_cuda.restype = None\n",
        "lib.evonorm_b0_cuda.argtypes = [c_void_p, c_void_p, c_void_p, c_int, c_int, c_int, c_int, c_int, c_float, c_void_p]\n",
        "lib.evonorm_b0_cuda.restype = None\n",
        "lib.layernorm_gelu_fused_cuda.argtypes = [c_void_p, c_void_p, c_void_p, c_void_p, c_int, c_int, c_float, c_void_p]\n",
        "lib.layernorm_gelu_fused_cuda.restype = None\n",
        "\n",
        "def check(name, got, ref, rtol=1e-4, atol=1e-5):\n",
        "    \"\"\"Test if custom kernel matches PyTorch\"\"\"\n",
        "    ok = torch.allclose(got, ref, rtol=rtol, atol=atol)\n",
        "    max_diff = (got-ref).abs().max().item() if not ok else 0.0 # Only calculate if not ok for efficiency\n",
        "    print(f\"{'âœ…' if ok else 'âŒ'} {name:18s} max|diff|={max_diff:.3e}\")\n",
        "    return ok\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# 1D\n",
        "n = 1_000_000\n",
        "x = torch.randn(n, device=device).float().contiguous()\n",
        "y = torch.empty_like(x)\n",
        "\n",
        "lib.relu_cuda(dev_ptr(x), dev_ptr(y), n, c_void_p(0)); check(\"ReLU\", y, torch.relu(x))\n",
        "lib.sigmoid_cuda(dev_ptr(x), dev_ptr(y), n, c_void_p(0)); check(\"Sigmoid\", y, torch.sigmoid(x))\n",
        "lib.gelu_cuda(dev_ptr(x), dev_ptr(y), n, c_void_p(0)); check(\"GELU approx\", y, torch.nn.functional.gelu(x), rtol=1e-3, atol=1e-4)\n",
        "lib.swish_cuda(dev_ptr(x), dev_ptr(y), n, c_void_p(0)); check(\"Swish\", y, x*torch.sigmoid(x))\n",
        "\n",
        "# LayerNorm\n",
        "N, D = 128, 1024\n",
        "x2 = torch.randn(N, D, device=device).float().contiguous()\n",
        "y2 = torch.empty_like(x2)\n",
        "g = torch.ones(D, device=device).float().contiguous()\n",
        "b = torch.zeros(D, device=device).float().contiguous()\n",
        "lib.layernorm_cuda(dev_ptr(x2), dev_ptr(y2), dev_ptr(g), dev_ptr(b), N, D, c_float(1e-5), c_void_p(0))\n",
        "check(\"LayerNorm\", y2, torch.nn.functional.layer_norm(x2, (D,), g, b, 1e-5), atol=2e-5)\n",
        "\n",
        "# Softmax\n",
        "N, D = 128, 512\n",
        "xs = torch.randn(N, D, device=device).float().contiguous()\n",
        "ys = torch.empty_like(xs)\n",
        "lib.softmax_cuda(dev_ptr(xs), dev_ptr(ys), N, D, c_void_p(0))\n",
        "check(\"Softmax\", ys, torch.nn.functional.softmax(xs, dim=-1))\n",
        "\n",
        "# EvoNorm-B0\n",
        "N, C, H, W = 2, 32, 16, 16\n",
        "xe = torch.randn(N, C, H, W, device=device).float().contiguous()\n",
        "ve = torch.randn(C, device=device).float().contiguous()\n",
        "ye = torch.empty_like(xe)\n",
        "groups = 32\n",
        "lib.evonorm_b0_cuda(dev_ptr(xe), dev_ptr(ve), dev_ptr(ye), N, C, H, W, groups, c_float(1e-5), c_void_p(0))\n",
        "\n",
        "xg = xe.reshape(N, groups, C//groups, H, W)\n",
        "var = xg.var(dim=(2,3,4), unbiased=False, keepdim=True)\n",
        "inv = torch.rsqrt(var + 1e-5).expand_as(xg).reshape_as(xe)\n",
        "ref = xe * torch.sigmoid(ve.view(1,C,1,1) * xe) * inv\n",
        "check(\"EvoNorm-B0\", ye, ref, rtol=1e-3, atol=1e-4)\n",
        "\n",
        "# Fused LN+GELU\n",
        "N, D = 64, 2048\n",
        "xf = torch.randn(N, D, device=device).float().contiguous()\n",
        "yf = torch.empty_like(xf)\n",
        "g = torch.ones(D, device=device).float().contiguous()\n",
        "b = torch.zeros(D, device=device).float().contiguous()\n",
        "\n",
        "lib.layernorm_gelu_fused_cuda(\n",
        "    dev_ptr(xf), dev_ptr(yf), dev_ptr(g), dev_ptr(b),\n",
        "    N, D, c_float(1e-5), c_void_p(0)\n",
        ")\n",
        "\n",
        "ref_ln = F.layer_norm(xf, (D,), g, b, eps=1e-5)\n",
        "ref_fused = F.gelu(ref_ln, approximate=\"tanh\")\n",
        "\n",
        "check(\"LN+GELU fused\", yf, ref_fused, rtol=5e-3, atol=5e-4)\n",
        "\n",
        "\n",
        "print(\"\\nâœ… Done.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa809e3a",
      "metadata": {
        "id": "fa809e3a"
      },
      "source": [
        "## 4ï¸âƒ£ Quick timings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f2939f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "2f2939f8",
        "outputId": "ee75f8ca-1bae-4c6e-8454-48a6419c229b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"op\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Sigmoid\",\n          \"Swish\",\n          \"ReLU\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.36489762098149253,\n        \"min\": 0.1416921615600586,\n        \"max\": 0.9722153345743815,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7906595865885416,\n          0.7904370625813802,\n          0.1416921615600586\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e284f8c2-3690-41f4-b124-0c9e28b64697\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>op</th>\n",
              "      <th>ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ReLU</td>\n",
              "      <td>0.141692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sigmoid</td>\n",
              "      <td>0.790660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GELU</td>\n",
              "      <td>0.972215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Swish</td>\n",
              "      <td>0.790437</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e284f8c2-3690-41f4-b124-0c9e28b64697')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e284f8c2-3690-41f4-b124-0c9e28b64697 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e284f8c2-3690-41f4-b124-0c9e28b64697');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-84912b12-5dd9-45b0-89f4-3e94ebf72470\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84912b12-5dd9-45b0-89f4-3e94ebf72470')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-84912b12-5dd9-45b0-89f4-3e94ebf72470 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        op        ms\n",
              "0     ReLU  0.141692\n",
              "1  Sigmoid  0.790660\n",
              "2     GELU  0.972215\n",
              "3    Swish  0.790437"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import time, pandas as pd\n",
        "\n",
        "def time_kernel(call, iters=30, warmup=10):\n",
        "    torch.cuda.synchronize()\n",
        "    for _ in range(warmup): call()\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.time()\n",
        "    for _ in range(iters): call()\n",
        "    torch.cuda.synchronize()\n",
        "    return (time.time()-t0)*1000/iters\n",
        "\n",
        "n = 4_000_000\n",
        "x = torch.randn(n, device=device).float().contiguous()\n",
        "y = torch.empty_like(x)\n",
        "\n",
        "rows = []\n",
        "rows.append({\"op\":\"ReLU\", \"ms\": time_kernel(lambda: lib.relu_cuda(dev_ptr(x), dev_ptr(y), n, c_void_p(0)))})\n",
        "rows.append({\"op\":\"Sigmoid\", \"ms\": time_kernel(lambda: lib.sigmoid_cuda(dev_ptr(x), dev_ptr(y), n, c_void_p(0)))})\n",
        "rows.append({\"op\":\"GELU\", \"ms\": time_kernel(lambda: lib.gelu_cuda(dev_ptr(x), dev_ptr(y), n, c_void_p(0)))})\n",
        "rows.append({\"op\":\"Swish\", \"ms\": time_kernel(lambda: lib.swish_cuda(dev_ptr(x), dev_ptr(y), n, c_void_p(0)))})\n",
        "import pandas as pd\n",
        "pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YsiL3WK_OQ3x",
      "metadata": {
        "id": "YsiL3WK_OQ3x"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "081f5408",
      "metadata": {
        "id": "081f5408"
      },
      "source": [
        "#  Additional Triton Kernels for JLR Hackathon\n",
        "Includes **GELU**, **Swish**, **LayerNorm+GELU**, **LayerNorm+Swish**, and **Softmax+CrossEntropy** kernels.\n",
        "\n",
        "Each kernel is verified against PyTorch reference implementations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52ef353d",
      "metadata": {
        "id": "52ef353d"
      },
      "source": [
        "## 0ï¸âƒ£ GPU Setup & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7a0fa26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7a0fa26",
        "outputId": "ca24249f-e6ac-465c-d393-667038aa7267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… CUDA available: True\n",
            "Thu Nov 20 20:59:48 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P0             30W /   70W |     948MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch, triton, triton.language as tl\n",
        "print(\"âœ… CUDA available:\", torch.cuda.is_available())\n",
        "!nvidia-smi || true\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9c5e0c1",
      "metadata": {
        "id": "d9c5e0c1"
      },
      "source": [
        "## 1ï¸âƒ£ Triton Kernels Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9Zf3IgpZ2n00",
      "metadata": {
        "id": "9Zf3IgpZ2n00"
      },
      "outputs": [],
      "source": [
        "# Complete Triton Kernels for GELU, Swish, and Fused Layersimport torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers (vectorized, exp-only)\n",
        "# ----------------------------\n",
        "# sigmoid(z) = 1 / (1 + exp(-z))\n",
        "def _sigmoid(z):\n",
        "    return 1.0 / (1.0 + tl.exp(-z))\n",
        "\n",
        "# tanh(z) = 2*sigmoid(2z) - 1\n",
        "# Moved logic into kernels below as global functions cannot be called directly\n",
        "\n",
        "# ----------------------------\n",
        "# GELU (tanh approximation) kernel\n",
        "# ----------------------------\n",
        "@triton.jit\n",
        "def _gelu_tanh_kernel(x_ptr, y_ptr, n_elements,\n",
        "                      BLOCK_SIZE: tl.constexpr):\n",
        "    pid = tl.program_id(axis=0)\n",
        "    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offs < n_elements\n",
        "\n",
        "    x = tl.load(x_ptr + offs, mask=mask)\n",
        "    # GELU(tanh) = 0.5*x*(1 + tanh(âˆš(2/Ï€) * (x + 0.044715 x^3)))\n",
        "    k = 0.7978845608028654  # sqrt(2/pi)\n",
        "    x3 = x * x * x\n",
        "    t = k * (x + 0.044715 * x3)\n",
        "    # Inlined tanh(t) = 2*sigmoid(2t) - 1\n",
        "    tanh_t = 2.0 * (1.0 / (1.0 + tl.exp(-2.0 * t))) - 1.0\n",
        "    y = 0.5 * x * (1.0 + tanh_t)\n",
        "\n",
        "    tl.store(y_ptr + offs, y, mask=mask)\n",
        "\n",
        "def gelu_triton(x: torch.Tensor) -> torch.Tensor:\n",
        "    assert x.is_cuda and x.dtype == torch.float32\n",
        "    x_c = x.contiguous()\n",
        "    y = torch.empty_like(x_c)\n",
        "    n = x_c.numel()\n",
        "    BLOCK = 1024\n",
        "    grid = lambda META: (triton.cdiv(n, META[\"BLOCK_SIZE\"]),)\n",
        "    _gelu_tanh_kernel[grid](x_c, y, n, BLOCK_SIZE=BLOCK, num_warps=4, num_stages=2)\n",
        "    return y.view_as(x)\n",
        "\n",
        "# ----------------------------\n",
        "# Swish = x * sigmoid(x) kernel\n",
        "# ----------------------------\n",
        "@triton.jit\n",
        "def _swish_kernel(x_ptr, y_ptr, n_elements,\n",
        "                  BLOCK_SIZE: tl.constexpr):\n",
        "    pid = tl.program_id(axis=0)\n",
        "    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offs < n_elements\n",
        "\n",
        "    x = tl.load(x_ptr + offs, mask=mask)\n",
        "    y = x * (1.0 / (1.0 + tl.exp(-x)))  # uses inlined sigmoid\n",
        "    tl.store(y_ptr + offs, y, mask=mask)\n",
        "\n",
        "def swish_triton(x: torch.Tensor) -> torch.Tensor:\n",
        "    assert x.is_cuda and x.dtype == torch.float32\n",
        "    x_c = x.contiguous()\n",
        "    y = torch.empty_like(x_c)\n",
        "    n = x_c.numel()\n",
        "    BLOCK = 1024\n",
        "    grid = lambda META: (triton.cdiv(n, META[\"BLOCK_SIZE\"]),)\n",
        "    _swish_kernel[grid](x_c, y, n, BLOCK_SIZE=BLOCK, num_warps=4, num_stages=2)\n",
        "    return y.view_as(x)\n",
        "    print(\"âœ… Kernels loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "swXy1eGq2FUJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swXy1eGq2FUJ",
        "outputId": "1241d67a-1449-4eca-85e0-479841823a43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Autograd wrappers: gelu_triton_autograd, swish_triton_autograd\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.autograd import Function\n",
        "\n",
        "# Keep using your existing Triton forwards: gelu_triton(x), swish_triton(x)\n",
        "\n",
        "_k = 0.7978845608028654  # sqrt(2/pi)\n",
        "\n",
        "class _GELUTrtFn(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        y = gelu_triton(x)\n",
        "        ctx.save_for_backward(x)\n",
        "        return y\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_out):\n",
        "        (x,) = ctx.saved_tensors\n",
        "        x2 = x * x\n",
        "        x3 = x2 * x\n",
        "        t  = _k * (x + 0.044715 * x3)\n",
        "        tanh_t = torch.tanh(t)\n",
        "        dt_dx  = _k * (1.0 + 3.0 * 0.044715 * x2)\n",
        "        dgelu_dx = 0.5 * (1.0 + tanh_t) + 0.5 * x * (1.0 - tanh_t * tanh_t) * dt_dx\n",
        "        return grad_out * dgelu_dx\n",
        "\n",
        "def gelu_triton_autograd(x: torch.Tensor) -> torch.Tensor:\n",
        "    return _GELUTrtFn.apply(x)\n",
        "\n",
        "class _SwishTrtFn(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        y = swish_triton(x)\n",
        "        ctx.save_for_backward(x)\n",
        "        return y\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_out):\n",
        "        (x,) = ctx.saved_tensors\n",
        "        s = torch.sigmoid(x)\n",
        "        d_dx = s + x * s * (1.0 - s)\n",
        "        return grad_out * d_dx\n",
        "\n",
        "def swish_triton_autograd(x: torch.Tensor) -> torch.Tensor:\n",
        "    return _SwishTrtFn.apply(x)\n",
        "\n",
        "print(\"âœ… Autograd wrappers: gelu_triton_autograd, swish_triton_autograd\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d867585",
      "metadata": {
        "id": "5d867585"
      },
      "source": [
        "## 2ï¸âƒ£ Run Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac48ef1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac48ef1b",
        "outputId": "4dca3eaa-f360-416c-95ee-9ebf3e7a2b61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GELU max diff: 4.77e-07\n",
            "Swish max diff: 4.77e-07\n"
          ]
        }
      ],
      "source": [
        "def test_gelu():\n",
        "    x = torch.randn(1024, 512, device='cuda', dtype=torch.float32)\n",
        "    y_torch = torch.nn.functional.gelu(x, approximate='tanh')\n",
        "    y_triton = gelu_triton(x)\n",
        "    diff = (y_torch - y_triton).abs().max().item()\n",
        "    print(f\"GELU max diff: {diff:.2e}\")\n",
        "\n",
        "def test_swish():\n",
        "    x = torch.randn(1024, 512, device='cuda', dtype=torch.float32)\n",
        "    y_torch = x * torch.sigmoid(x)\n",
        "    y_triton = swish_triton(x)\n",
        "    diff = (y_torch - y_triton).abs().max().item()\n",
        "    print(f\"Swish max diff: {diff:.2e}\")\n",
        "\n",
        "test_gelu()\n",
        "test_swish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VBIIpCu6PlqQ",
      "metadata": {
        "id": "VBIIpCu6PlqQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "03301244",
      "metadata": {
        "id": "03301244"
      },
      "source": [
        "# ðŸ§ª Comprehensive CUDA vs Triton Comparison\n",
        "\n",
        "End-to-end notebook to build CUDA kernels, load Triton kernels, and benchmark CUDA vs Triton vs PyTorch.\n",
        "**Sections**: GPU check â†’ build `.so` â†’ write Triton/Python helpers â†’ run correctness & performance suite â†’ plots & CSV reports.\n",
        "\n",
        "> **Note**: Use a Colab GPU runtime (Runtime â†’ Change runtime type â†’ GPU)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e75bcbb2",
      "metadata": {
        "id": "e75bcbb2"
      },
      "source": [
        "## 0ï¸âƒ£ GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b233301",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b233301",
        "outputId": "e0b879e0-74bc-4d2c-b40d-6e4b66a695e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available (torch): True\n",
            "Thu Nov 20 20:59:58 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0             30W /   70W |     948MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch, os, sys\n",
        "print(\"CUDA available (torch):\", torch.cuda.is_available())\n",
        "!nvidia-smi || true\n",
        "!nvcc --version || true\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e9bab9",
      "metadata": {
        "id": "08e9bab9"
      },
      "source": [
        "## 1ï¸âƒ£ Write & Compile `cuda_kernels.cu`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87817bc3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87817bc3",
        "outputId": "cd7079c0-9d2d-4be7-a7d5-c8cc1dcef876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote cuda_kernels.cu (bytes): 10120\n",
            "-rwxr-xr-x 1 root root 1.2M Nov 20 21:00 cuda_kernels.so\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cuda_src = r'''// cuda_kernels.cu\n",
        "// CUDA implementations for JLR Hackathon Project\n",
        "// Compile: nvcc -O3 -arch=sm_75 -o cuda_kernels.so --shared -Xcompiler -fPIC cuda_kernels.cu\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <cuda_fp16.h>\n",
        "#include <cmath>\n",
        "#include <stdio.h>\n",
        "\n",
        "#define CUDA_CHECK(call) \\\n",
        "    do { \\\n",
        "        cudaError_t err = call; \\\n",
        "        if (err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"CUDA error in %s:%d: %s\\\\n\", __FILE__, __LINE__, \\\n",
        "                    cudaGetErrorString(err)); \\\n",
        "            exit(EXIT_FAILURE); \\\n",
        "        } \\\n",
        "    } while(0)\n",
        "\n",
        "__global__ void relu_kernel(const float* x, float* y, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) y[idx] = fmaxf(x[idx], 0.0f);\n",
        "}\n",
        "extern \"C\" void relu_cuda(const float* x, float* y, int n, cudaStream_t stream = 0) {\n",
        "    int threads = 256, blocks = (n + threads - 1) / threads;\n",
        "    relu_kernel<<<blocks, threads, 0, stream>>>(x, y, n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "__global__ void sigmoid_kernel(const float* x, float* y, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) y[idx] = 1.0f / (1.0f + expf(-x[idx]));\n",
        "}\n",
        "extern \"C\" void sigmoid_cuda(const float* x, float* y, int n, cudaStream_t stream = 0) {\n",
        "    int threads = 256, blocks = (n + threads - 1) / threads;\n",
        "    sigmoid_kernel<<<blocks, threads, 0, stream>>>(x, y, n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "__global__ void gelu_kernel(const float* x, float* y, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        float val = x[idx];\n",
        "        float x3 = val * val * val;\n",
        "        float inner = 0.7978845608f * (val + 0.044715f * x3);\n",
        "        y[idx] = 0.5f * val * (1.0f + tanhf(inner));\n",
        "    }\n",
        "}\n",
        "extern \"C\" void gelu_cuda(const float* x, float* y, int n, cudaStream_t stream = 0) {\n",
        "    int threads = 256, blocks = (n + threads - 1) / threads;\n",
        "    gelu_kernel<<<blocks, threads, 0, stream>>>(x, y, n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "__global__ void swish_kernel(const float* x, float* y, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        float val = x[idx];\n",
        "        float sig = 1.0f / (1.0f + expf(-val));\n",
        "        y[idx] = val * sig;\n",
        "    }\n",
        "}\n",
        "extern \"C\" void swish_cuda(const float* x, float* y, int n, cudaStream_t stream = 0) {\n",
        "    int threads = 256, blocks = (n + threads - 1) / threads;\n",
        "    swish_kernel<<<blocks, threads, 0, stream>>>(x, y, n);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "template<int BLOCK_SIZE>\n",
        "__device__ float warp_reduce_sum(float val) {\n",
        "    for (int offset = 16; offset > 0; offset /= 2) {\n",
        "        val += __shfl_down_sync(0xffffffff, val, offset);\n",
        "    }\n",
        "    return val;\n",
        "}\n",
        "\n",
        "template<int BLOCK_SIZE>\n",
        "__global__ void layernorm_kernel(const float* x, float* y, const float* gamma, const float* beta,\n",
        "                                 int N, int D, float eps) {\n",
        "    int row = blockIdx.x;\n",
        "    if (row >= N) return;\n",
        "    const float* x_row = x + row * D;\n",
        "    float* y_row = y + row * D;\n",
        "    float sum = 0.0f;\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) sum += x_row[i];\n",
        "    __shared__ float shared_sum[32];\n",
        "    sum = warp_reduce_sum<BLOCK_SIZE>(sum);\n",
        "    if (threadIdx.x % 32 == 0) shared_sum[threadIdx.x / 32] = sum;\n",
        "    __syncthreads();\n",
        "    if (threadIdx.x < 32) {\n",
        "        sum = (threadIdx.x < (blockDim.x + 31) / 32) ? shared_sum[threadIdx.x] : 0.0f;\n",
        "        sum = warp_reduce_sum<32>(sum);\n",
        "    }\n",
        "    __syncthreads();\n",
        "    float mean = sum / D;\n",
        "    float var_sum = 0.0f;\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
        "        float diff = x_row[i] - mean;\n",
        "        var_sum += diff * diff;\n",
        "    }\n",
        "    var_sum = warp_reduce_sum<BLOCK_SIZE>(var_sum);\n",
        "    if (threadIdx.x % 32 == 0) shared_sum[threadIdx.x / 32] = var_sum;\n",
        "    __syncthreads();\n",
        "    if (threadIdx.x < 32) {\n",
        "        var_sum = (threadIdx.x < (blockDim.x + 31) / 32) ? shared_sum[threadIdx.x] : 0.0f;\n",
        "        var_sum = warp_reduce_sum<32>(var_sum);\n",
        "    }\n",
        "    __syncthreads();\n",
        "    float variance = var_sum / D;\n",
        "    float inv_std = rsqrtf(variance + eps);\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
        "        float normalized = (x_row[i] - mean) * inv_std;\n",
        "        y_row[i] = gamma[i] * normalized + beta[i];\n",
        "    }\n",
        "}\n",
        "extern \"C\" void layernorm_cuda(const float* x, float* y, const float* gamma, const float* beta,\n",
        "                               int N, int D, float eps, cudaStream_t stream = 0) {\n",
        "    int threads = 256, blocks = N;\n",
        "    layernorm_kernel<256><<<blocks, threads, 0, stream>>>(x, y, gamma, beta, N, D, eps);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "template<int BLOCK_SIZE>\n",
        "__global__ void softmax_kernel(const float* x, float* y, int N, int D) {\n",
        "    int row = blockIdx.x;\n",
        "    if (row >= N) return;\n",
        "    const float* x_row = x + row * D;\n",
        "    float* y_row = y + row * D;\n",
        "    float max_val = -INFINITY;\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x)\n",
        "        max_val = fmaxf(max_val, x_row[i]);\n",
        "    max_val = warp_reduce_sum<BLOCK_SIZE>(max_val);\n",
        "    __shared__ float shared_max[32];\n",
        "    if (threadIdx.x % 32 == 0) shared_max[threadIdx.x / 32] = max_val;\n",
        "    __syncthreads();\n",
        "    if (threadIdx.x < 32) {\n",
        "        max_val = (threadIdx.x < (blockDim.x + 31) / 32) ? shared_max[threadIdx.x] : -INFINITY;\n",
        "        for (int offset = 16; offset > 0; offset /= 2)\n",
        "            max_val = fmaxf(max_val, __shfl_down_sync(0xffffffff, max_val, offset));\n",
        "    }\n",
        "    __syncthreads();\n",
        "    float sum = 0.0f;\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
        "        float e = expf(x_row[i] - max_val);\n",
        "        y_row[i] = e;\n",
        "        sum += e;\n",
        "    }\n",
        "    sum = warp_reduce_sum<BLOCK_SIZE>(sum);\n",
        "    __shared__ float shared_sum[32];\n",
        "    if (threadIdx.x % 32 == 0) shared_sum[threadIdx.x / 32] = sum;\n",
        "    __syncthreads();\n",
        "    if (threadIdx.x < 32) {\n",
        "        sum = (threadIdx.x < (blockDim.x + 31) / 32) ? shared_sum[threadIdx.x] : 0.0f;\n",
        "        sum = warp_reduce_sum<32>(sum);\n",
        "    }\n",
        "    __syncthreads();\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) y_row[i] /= sum;\n",
        "}\n",
        "extern \"C\" void softmax_cuda(const float* x, float* y, int N, int D, cudaStream_t stream = 0) {\n",
        "    int threads = 256, blocks = N;\n",
        "    softmax_kernel<256><<<blocks, threads, 0, stream>>>(x, y, N, D);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "__global__ void evonorm_b0_kernel(const float* x, const float* v, float* y,\n",
        "                                  int N, int C, int H, int W, int groups, float eps) {\n",
        "    int n = blockIdx.x / groups;\n",
        "    int g = blockIdx.x % groups;\n",
        "    if (n >= N) return;\n",
        "    int Cg = C / groups, HW = H * W, group_size = Cg * HW;\n",
        "    int base = n * C * HW + g * Cg * HW;\n",
        "    __shared__ float s_mean, s_var;\n",
        "    float local_sum = 0.0f, local_sum_sq = 0.0f;\n",
        "    __shared__ float shared_data[256];\n",
        "    for (int i = threadIdx.x; i < group_size; i += blockDim.x) {\n",
        "        float val = x[base + i];\n",
        "        local_sum += val; local_sum_sq += val * val;\n",
        "    }\n",
        "    shared_data[threadIdx.x] = local_sum; __syncthreads();\n",
        "    for (int s = blockDim.x/2; s>0; s>>=1) { if (threadIdx.x < s) shared_data[threadIdx.x] += shared_data[threadIdx.x+s]; __syncthreads(); }\n",
        "    if (threadIdx.x == 0) s_mean = shared_data[0] / group_size; __syncthreads();\n",
        "    shared_data[threadIdx.x] = local_sum_sq; __syncthreads();\n",
        "    for (int s = blockDim.x/2; s>0; s>>=1) { if (threadIdx.x < s) shared_data[threadIdx.x] += shared_data[threadIdx.x+s]; __syncthreads(); }\n",
        "    if (threadIdx.x == 0) { float mean_sq = shared_data[0] / group_size; s_var = mean_sq - s_mean * s_mean; }\n",
        "    __syncthreads();\n",
        "    float inv_std = rsqrtf(s_var + eps);\n",
        "    for (int i = threadIdx.x; i < group_size; i += blockDim.x) {\n",
        "        int global_idx = base + i;\n",
        "        int c_in_group = i / HW;\n",
        "        int c_global = g * Cg + c_in_group;\n",
        "        float val = x[global_idx];\n",
        "        float v_val = v[c_global];\n",
        "        float sig = 1.0f / (1.0f + expf(-v_val * val));\n",
        "        y[global_idx] = val * sig * inv_std;\n",
        "    }\n",
        "}\n",
        "extern \"C\" void evonorm_b0_cuda(const float* x, const float* v, float* y,\n",
        "                                int N, int C, int H, int W, int groups, float eps, cudaStream_t stream = 0) {\n",
        "    int threads = 256, blocks = N * groups;\n",
        "    evonorm_b0_kernel<<<blocks, threads, 0, stream>>>(x, v, y, N, C, H, W, groups, eps);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "\n",
        "template<int BLOCK_SIZE>\n",
        "__global__ void layernorm_gelu_fused_kernel(const float* x, float* y, const float* gamma, const float* beta,\n",
        "                                            int N, int D, float eps) {\n",
        "    int row = blockIdx.x; if (row >= N) return;\n",
        "    const float* x_row = x + row * D; float* y_row = y + row * D;\n",
        "    float sum = 0.0f; for (int i = threadIdx.x; i < D; i += blockDim.x) sum += x_row[i];\n",
        "    __shared__ float shared_stats[32];\n",
        "    sum = warp_reduce_sum<BLOCK_SIZE>(sum);\n",
        "    if (threadIdx.x % 32 == 0) shared_stats[threadIdx.x/32] = sum;\n",
        "    __syncthreads();\n",
        "    if (threadIdx.x < 32) { sum = (threadIdx.x < (blockDim.x+31)/32) ? shared_stats[threadIdx.x] : 0.0f; sum = warp_reduce_sum<32>(sum); }\n",
        "    __syncthreads();\n",
        "    float mean = sum / D;\n",
        "    float var_sum = 0.0f; for (int i = threadIdx.x; i < D; i += blockDim.x) { float d = x_row[i]-mean; var_sum += d*d; }\n",
        "    var_sum = warp_reduce_sum<BLOCK_SIZE>(var_sum);\n",
        "    if (threadIdx.x % 32 == 0) shared_stats[threadIdx.x/32] = var_sum;\n",
        "    __syncthreads();\n",
        "    if (threadIdx.x < 32) { var_sum = (threadIdx.x < (blockDim.x+31)/32) ? shared_stats[threadIdx.x] : 0.0f; var_sum = warp_reduce_sum<32>(var_sum); }\n",
        "    __syncthreads();\n",
        "    float inv_std = rsqrtf(var_sum / D + eps);\n",
        "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
        "        float norm = (x_row[i]-mean) * inv_std;\n",
        "        float affine = gamma[i]*norm + beta[i];\n",
        "        float x3 = affine * affine * affine;\n",
        "        float inner = 0.7978845608f * (affine + 0.044715f * x3);\n",
        "        y_row[i] = 0.5f * affine * (1.0f + tanhf(inner));\n",
        "    }\n",
        "}\n",
        "extern \"C\" void layernorm_gelu_fused_cuda(const float* x, float* y, const float* gamma, const float* beta,\n",
        "                                          int N, int D, float eps, cudaStream_t stream = 0) {\n",
        "    int threads = 256, blocks = N;\n",
        "    layernorm_gelu_fused_kernel<256><<<blocks, threads, 0, stream>>>(x, y, gamma, beta, N, D, eps);\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "}\n",
        "'''\n",
        "with open(\"cuda_kernels.cu\", \"w\") as f:\n",
        "    f.write(cuda_src)\n",
        "print(\"Wrote cuda_kernels.cu (bytes):\", len(cuda_src))\n",
        "\n",
        "# Compile (fatbin across common SMs)\n",
        "!nvcc -O3 -std=c++14 -Xcompiler -fPIC --shared cuda_kernels.cu -o cuda_kernels.so \\\n",
        "-gencode arch=compute_70,code=sm_70 \\\n",
        "-gencode arch=compute_75,code=sm_75 \\\n",
        "-gencode arch=compute_80,code=sm_80 \\\n",
        "-gencode arch=compute_86,code=sm_86 \\\n",
        "-gencode arch=compute_90,code=sm_90\n",
        "!ls -lh cuda_kernels.so\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb5545a3",
      "metadata": {
        "id": "bb5545a3"
      },
      "source": [
        "## 2ï¸âƒ£ Write `triton_additional_kernels.py` (your Triton kernels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "803570b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "803570b4",
        "outputId": "c8ace975-2d80-4f41-a7c1-d711e28d941f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote triton_additional_kernels.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "with open(\"triton_additional_kernels.py\", \"w\") as f:\n",
        "    f.write(r'''\n",
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "@triton.jit\n",
        "def gelu_kernel(x_ptr, y_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n",
        "    pid = tl.program_id(axis=0)\n",
        "    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offs < n_elements\n",
        "\n",
        "    x = tl.load(x_ptr + offs, mask=mask, other=0.0)\n",
        "\n",
        "    # GELU tanh-based approximation, but with our own tanh (no tl.libdevice)\n",
        "    # inner = 0.7978845608 * (x + 0.044715 * x^3)\n",
        "    x2 = x * x\n",
        "    x3 = x2 * x\n",
        "    inner = 0.7978845608 * (x + 0.044715 * x3)\n",
        "\n",
        "    # tanh(inner) â‰ˆ (e^{2*inner} - 1) / (e^{2*inner} + 1)\n",
        "    two_inner = 2.0 * inner\n",
        "    e2 = tl.exp(two_inner)\n",
        "    tanh_inner = (e2 - 1.0) / (e2 + 1.0)\n",
        "\n",
        "    y = 0.5 * x * (1.0 + tanh_inner)\n",
        "\n",
        "    tl.store(y_ptr + offs, y, mask=mask)\n",
        "\n",
        "\n",
        "def gelu_triton(x: torch.Tensor):\n",
        "    assert x.is_cuda\n",
        "    x_flat = x.contiguous().view(-1)\n",
        "    n_elements = x_flat.numel()\n",
        "\n",
        "    y_flat = torch.empty_like(x_flat)\n",
        "\n",
        "    BLOCK_SIZE = 1024\n",
        "    grid = (triton.cdiv(n_elements, BLOCK_SIZE),)\n",
        "\n",
        "    gelu_kernel[grid](\n",
        "        x_flat, y_flat,\n",
        "        n_elements,\n",
        "        BLOCK_SIZE=BLOCK_SIZE,\n",
        "    )\n",
        "    return y_flat.view_as(x)\n",
        "\n",
        "@triton.jit\n",
        "def swish_kernel(x_ptr, y_ptr, n_elements, BLOCK_SIZE: tl.constexpr):\n",
        "    pid = tl.program_id(axis=0)\n",
        "    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offs < n_elements\n",
        "    x = tl.load(x_ptr + offs, mask=mask, other=0.0)\n",
        "    y = x * (1.0 / (1.0 + tl.exp(-x)))\n",
        "    tl.store(y_ptr + offs, y, mask=mask)\n",
        "\n",
        "def swish_triton(x: torch.Tensor) -> torch.Tensor:\n",
        "    assert x.is_cuda and x.is_contiguous()\n",
        "    y = torch.empty_like(x)\n",
        "    n = x.numel()\n",
        "    BLOCK = 1024\n",
        "    grid = lambda meta: (triton.cdiv(n, meta['BLOCK_SIZE']),)\n",
        "    swish_kernel[grid](x, y, n, BLOCK_SIZE=BLOCK)\n",
        "    return y\n",
        "\n",
        "@triton.jit\n",
        "def layernorm_gelu_fused_kernel(x_ptr, y_ptr, gamma_ptr, beta_ptr,\n",
        "                                n_rows, n_cols, stride_xr, stride_xc, stride_yr, stride_yc,\n",
        "                                eps: tl.constexpr, BLOCK_SIZE: tl.constexpr):\n",
        "    row = tl.program_id(0)\n",
        "    cols = tl.arange(0, BLOCK_SIZE)\n",
        "    mask = cols < n_cols\n",
        "    x_row = x_ptr + row * stride_xr + cols * stride_xc\n",
        "    y_row = y_ptr + row * stride_yr + cols * stride_yc\n",
        "    x = tl.load(x_row, mask=mask, other=0.0).to(tl.float32)\n",
        "    m = tl.sum(x, axis=0) / n_cols\n",
        "    xc = x - m\n",
        "    v = tl.sum(xc * xc, axis=0) / n_cols\n",
        "    inv = tl.rsqrt(v + eps)\n",
        "    gamma = tl.load(gamma_ptr + cols, mask=mask, other=1.0).to(tl.float32)\n",
        "    beta = tl.load(beta_ptr + cols, mask=mask, other=0.0).to(tl.float32)\n",
        "    normalized = (xc * inv) * gamma + beta\n",
        "    # ---- GELU part: tanh approximation, no tl.libdevice ----\n",
        "    x2 = normalized * normalized\n",
        "    x3 = x2 * normalized\n",
        "\n",
        "    # inner = sqrt(2/pi) * (x + 0.044715 x^3)\n",
        "    inner = 0.7978845608 * (normalized + 0.044715 * x3)\n",
        "\n",
        "    # tanh(inner) â‰ˆ (e^{2*inner} - 1) / (e^{2*inner} + 1)\n",
        "    two_inner = 2.0 * inner\n",
        "    e2 = tl.exp(two_inner)\n",
        "    tanh_inner = (e2 - 1.0) / (e2 + 1.0)\n",
        "\n",
        "    y = 0.5 * normalized * (1.0 + tanh_inner)\n",
        "\n",
        "    tl.store(y_ptr + row_start + offs, y, mask=mask)\n",
        "\n",
        "def layernorm_gelu_fused_triton(x: torch.Tensor, gamma: torch.Tensor, beta: torch.Tensor, eps: float = 1e-5) -> torch.Tensor:\n",
        "    assert x.is_cuda and x.is_contiguous()\n",
        "    cols = x.shape[-1]\n",
        "    rows = x.numel() // cols\n",
        "    x2 = x.view(rows, cols).contiguous()\n",
        "    y2 = torch.empty_like(x2)\n",
        "    BLOCK = 1 << (cols - 1).bit_length()\n",
        "    BLOCK = min(BLOCK, 4096)\n",
        "    grid = (rows,)\n",
        "    layernorm_gelu_fused_kernel[grid](x2, y2, gamma, beta,\n",
        "                                      rows, cols,\n",
        "                                      x2.stride(0), x2.stride(1),\n",
        "                                      y2.stride(0), y2.stride(1),\n",
        "                                      eps=eps, BLOCK_SIZE=BLOCK)\n",
        "    return y2.view_as(x)\n",
        "\n",
        "@triton.jit\n",
        "def softmax_cross_entropy_kernel(logits_ptr, labels_ptr, loss_ptr,\n",
        "                                 n_rows, n_cols, stride_lr, stride_lc,\n",
        "                                 BLOCK_SIZE: tl.constexpr):\n",
        "    row_id = tl.program_id(axis=0)\n",
        "    if row_id >= n_rows: return\n",
        "    cols = tl.arange(0, BLOCK_SIZE)\n",
        "    mask = cols < n_cols\n",
        "    row_ptr = logits_ptr + row_id * stride_lr\n",
        "    logits = tl.load(row_ptr + cols * stride_lc, mask=mask, other=-float('inf'))\n",
        "    max_logit = tl.max(logits, axis=0)\n",
        "    exp_logits = tl.exp(logits - max_logit)\n",
        "    sum_exp = tl.sum(exp_logits, axis=0)\n",
        "    label = tl.load(labels_ptr + row_id)\n",
        "    label_logit = tl.load(row_ptr + label * stride_lc)\n",
        "    loss = -label_logit + max_logit + tl.log(sum_exp)\n",
        "    tl.store(loss_ptr + row_id, loss)\n",
        "\n",
        "def softmax_cross_entropy_triton(logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
        "    assert logits.is_cuda and logits.is_contiguous()\n",
        "    assert labels.is_cuda and labels.is_contiguous()\n",
        "    N, C = logits.shape\n",
        "    loss = torch.empty(N, device=logits.device, dtype=logits.dtype)\n",
        "    BLOCK = 1024\n",
        "    assert C <= BLOCK, f\"Classes {C} must be <= {BLOCK}\"\n",
        "    grid = (N,)\n",
        "    softmax_cross_entropy_kernel[grid](logits, labels, loss, N, C, logits.stride(0), logits.stride(1), BLOCK_SIZE=BLOCK)\n",
        "    return loss.mean()\n",
        "''')\n",
        "print(\"Wrote triton_additional_kernels.py\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0XZe-JM7C5iC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XZe-JM7C5iC",
        "outputId": "76363f6b-1915-44b1-904a-a200d29570ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max abs diff: 9.5367431640625e-07\n"
          ]
        }
      ],
      "source": [
        "#Quick sanity check vs PyTorch\n",
        "B, D = 32, 1024\n",
        "x = torch.randn(B, D, device=device, dtype=torch.float32)\n",
        "gamma = torch.randn(D, device=device, dtype=torch.float32)\n",
        "beta  = torch.randn(D, device=device, dtype=torch.float32)\n",
        "\n",
        "y_ref = F.gelu(F.layer_norm(x, (D,), gamma, beta, eps=1e-5), approximate=\"tanh\")\n",
        "y_triton = layernorm_gelu_fused_triton(x, gamma, beta)\n",
        "\n",
        "print(\"max abs diff:\", (y_ref - y_triton).abs().max().item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5495777",
      "metadata": {
        "id": "e5495777"
      },
      "source": [
        "## 3ï¸âƒ£ Write `jlr_colab_demo_fixed.py` (Triton refs used by the benchmark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a7e46e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a7e46e1",
        "outputId": "df1171dd-7bdc-45e3-d94e-f7ee80873744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote jlr_colab_demo_fixed.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "with open(\"jlr_colab_demo_fixed.py\", \"w\") as f:\n",
        "    f.write(r'''\n",
        "import torch, triton, triton.language as tl\n",
        "import torch.nn.functional as F\n",
        "\n",
        "@triton.jit\n",
        "def softmax_rowwise_kernel(x_ptr, y_ptr, n_rows, n_cols, sxr, sxc, syr, syc, BLOCK_SIZE: tl.constexpr):\n",
        "    row_id = tl.program_id(0)\n",
        "    cols = tl.arange(0, BLOCK_SIZE)\n",
        "    row_ptr_x = x_ptr + row_id * sxr\n",
        "    row_ptr_y = y_ptr + row_id * syr\n",
        "    mask = cols < n_cols\n",
        "    x = tl.load(row_ptr_x + cols * sxc, mask=mask, other=-float('inf'))\n",
        "    x = x - tl.max(x, axis=0)\n",
        "    expx = tl.exp(x)\n",
        "    out = expx / tl.sum(expx, axis=0)\n",
        "    tl.store(row_ptr_y + cols * syc, out, mask=mask)\n",
        "\n",
        "def softmax_triton_lastdim(x):\n",
        "    assert x.is_cuda and x.is_contiguous()\n",
        "    cols = x.shape[-1]; rows = x.numel() // cols\n",
        "    x2 = x.view(rows, cols).contiguous(); y2 = torch.empty_like(x2)\n",
        "    BLOCK = 1024; assert cols <= BLOCK\n",
        "    softmax_rowwise_kernel[(rows,)](x2, y2, rows, cols, x2.stride(0), x2.stride(1), y2.stride(0), y2.stride(1), BLOCK_SIZE=BLOCK)\n",
        "    return y2.view_as(x)\n",
        "\n",
        "@triton.jit\n",
        "def layernorm_fwd_kernel(x_ptr, y_ptr, gamma_ptr, beta_ptr, n_rows, n_cols, sxr, sxc, syr, syc, eps: tl.constexpr, BLOCK_SIZE: tl.constexpr):\n",
        "    row = tl.program_id(0)\n",
        "    cols = tl.arange(0, BLOCK_SIZE)\n",
        "    mask = cols < n_cols\n",
        "    x_row = x_ptr + row * sxr + cols * sxc\n",
        "    y_row = y_ptr + row * syr + cols * syc\n",
        "    x = tl.load(x_row, mask=mask, other=0.0).to(tl.float32)\n",
        "    m = tl.sum(x, axis=0) / n_cols\n",
        "    xc = x - m\n",
        "    v = tl.sum(xc * xc, axis=0) / n_cols\n",
        "    inv = tl.rsqrt(v + eps)\n",
        "    gamma = tl.load(gamma_ptr + cols, mask=mask, other=1.0).to(tl.float32)\n",
        "    beta = tl.load(beta_ptr + cols, mask=mask, other=0.0).to(tl.float32)\n",
        "    y = (xc * inv) * gamma + beta\n",
        "    tl.store(y_row, y, mask=mask)\n",
        "\n",
        "def layernorm_triton(x, gamma, beta, eps=1e-5):\n",
        "    assert x.is_cuda and x.is_contiguous()\n",
        "    cols = x.shape[-1]; rows = x.numel() // cols\n",
        "    x2 = x.view(rows, cols).contiguous(); y2 = torch.empty_like(x2)\n",
        "    BLOCK = 1 << (cols - 1).bit_length(); BLOCK = min(BLOCK, 4096)\n",
        "    layernorm_fwd_kernel[(rows,)](x2, y2, gamma, beta, rows, cols, x2.stride(0), x2.stride(1), y2.stride(0), y2.stride(1), eps=eps, BLOCK_SIZE=BLOCK)\n",
        "    return y2.view_as(x)\n",
        "\n",
        "def evonorm_b0_reference(x, v, groups=32, eps=1e-5):\n",
        "    N, C, H, W = x.shape; Cg = C // groups\n",
        "    xg = x.view(N, groups, Cg, H, W)\n",
        "    var = xg.var(dim=(2,3,4), unbiased=False, keepdim=True)\n",
        "    inv_std = torch.rsqrt(var + eps).expand(N, groups, Cg, H, W).reshape(N, C, H, W)\n",
        "    return x * torch.sigmoid(v.view(1, C, 1, 1) * x) * inv_std\n",
        "\n",
        "@triton.jit\n",
        "def evonorm_b0_fused_kernel(x_ptr, v_ptr, y_ptr, N, C, H, W, groups, eps: tl.constexpr, BLOCK: tl.constexpr):\n",
        "    pid = tl.program_id(0)\n",
        "    g = pid % groups; n = pid // groups\n",
        "    Cg = C // groups; HW = H * W; group_elems = Cg * HW\n",
        "    base = n * (C * HW) + g * (Cg * HW)\n",
        "    acc1 = tl.zeros([1], dtype=tl.float32); acc2 = tl.zeros([1], dtype=tl.float32)\n",
        "    offs = tl.arange(0, BLOCK)\n",
        "    for start in range(0, group_elems, BLOCK):\n",
        "        idx = base + start + offs; mask = (start + offs) < group_elems\n",
        "        x = tl.load(x_ptr + idx, mask=mask, other=0.0).to(tl.float32)\n",
        "        acc1 += tl.sum(x, axis=0); acc2 += tl.sum(x * x, axis=0)\n",
        "    ge = tl.full([1], group_elems, dtype=tl.float32)\n",
        "    mean = acc1 / ge; var = acc2 / ge - mean * mean; inv = 1.0 / tl.sqrt(var + eps)\n",
        "    for start in range(0, group_elems, BLOCK):\n",
        "        idx = base + start + offs; mask = (start + offs) < group_elems\n",
        "        x = tl.load(x_ptr + idx, mask=mask, other=0.0).to(tl.float32)\n",
        "        rel = start + offs; c_in_group = rel // HW; c_global = g * Cg + c_in_group\n",
        "        v = tl.load(v_ptr + c_global, mask=mask, other=0.0).to(tl.float32)\n",
        "        sig = 1.0 / (1.0 + tl.exp(-(v * x)))\n",
        "        y = x * sig * inv; tl.store(y_ptr + idx, y, mask=mask)\n",
        "\n",
        "def evonorm_b0_triton_fused(x, v, groups=32, eps=1e-5):\n",
        "    N, C, H, W = x.shape; x = x.contiguous(); y = torch.empty_like(x)\n",
        "    Cg = C // groups; BLOCK = min(1024, Cg * H * W) if (Cg * H * W) > 0 else 1024\n",
        "    evonorm_b0_fused_kernel[(N * groups,)](x.view(-1), v, y.view(-1), N, C, H, W, groups, eps=eps, BLOCK=BLOCK)\n",
        "    return y\n",
        "''')\n",
        "print(\"Wrote jlr_colab_demo_fixed.py\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JWqe6PlL99u8",
      "metadata": {
        "id": "JWqe6PlL99u8"
      },
      "outputs": [],
      "source": [
        "# === Override softmax_triton_lastdim to support larger last-dim (e.g., 4096) ===\n",
        "from jlr_colab_demo_fixed import softmax_rowwise_kernel  # kernel is still in that module\n",
        "\n",
        "def softmax_triton_lastdim(x):\n",
        "    assert x.is_cuda and x.is_contiguous()\n",
        "    cols = x.shape[-1]\n",
        "    rows = x.numel() // cols\n",
        "\n",
        "    x2 = x.view(rows, cols).contiguous()\n",
        "    y2 = torch.empty_like(x2)\n",
        "\n",
        "    # Use power-of-two BLOCK, capped at 4096 (like LayerNorm)\n",
        "    BLOCK = 1 << (cols - 1).bit_length()\n",
        "    BLOCK = min(BLOCK, 4096)\n",
        "\n",
        "    softmax_rowwise_kernel[(rows,)](\n",
        "        x2, y2,\n",
        "        rows, cols,\n",
        "        x2.stride(0), x2.stride(1),\n",
        "        y2.stride(0), y2.stride(1),\n",
        "        BLOCK_SIZE=BLOCK\n",
        "    )\n",
        "    return y2.view_as(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "035373a2",
      "metadata": {
        "id": "035373a2"
      },
      "source": [
        "## 4ï¸âƒ£ Comparison Utilities (CUDA loader, timers, benchmarks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3510639",
      "metadata": {
        "id": "d3510639"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os, time, numpy as np, pandas as pd, torch, torch.nn.functional as F\n",
        "from ctypes import CDLL, c_void_p, c_int, c_float\n",
        "from typing import Callable, Dict, Tuple\n",
        "\n",
        "from triton_additional_kernels import (\n",
        "    gelu_triton, swish_triton, layernorm_gelu_fused_triton, softmax_cross_entropy_triton\n",
        ")\n",
        "from jlr_colab_demo_fixed import layernorm_triton, softmax_triton_lastdim, evonorm_b0_reference, evonorm_b0_triton_fused\n",
        "\n",
        "os.makedirs('reports/cuda_vs_triton', exist_ok=True)\n",
        "os.makedirs('profiling/comparison_results', exist_ok=True)\n",
        "\n",
        "class CUDAKernels:\n",
        "    def __init__(self, lib_path='./cuda_kernels.so'):\n",
        "        try:\n",
        "            self.lib = CDLL(lib_path)\n",
        "            self._setup()\n",
        "            print(f\"âœ… Loaded CUDA library: {lib_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to load CUDA library: {e}\")\n",
        "            self.lib = None\n",
        "\n",
        "    def _setup(self):\n",
        "        self.lib.relu_cuda.argtypes = [c_void_p, c_void_p, c_int, c_void_p]\n",
        "        self.lib.sigmoid_cuda.argtypes = [c_void_p, c_void_p, c_int, c_void_p]\n",
        "        self.lib.gelu_cuda.argtypes = [c_void_p, c_void_p, c_int, c_void_p]\n",
        "        self.lib.swish_cuda.argtypes = [c_void_p, c_void_p, c_int, c_void_p]\n",
        "        self.lib.layernorm_cuda.argtypes = [c_void_p, c_void_p, c_void_p, c_void_p, c_int, c_int, c_float, c_void_p]\n",
        "        self.lib.softmax_cuda.argtypes = [c_void_p, c_void_p, c_int, c_int, c_void_p]\n",
        "        self.lib.evonorm_b0_cuda.argtypes = [c_void_p, c_void_p, c_void_p, c_int, c_int, c_int, c_int, c_int, c_float, c_void_p]\n",
        "        self.lib.layernorm_gelu_fused_cuda.argtypes = [c_void_p, c_void_p, c_void_p, c_void_p, c_int, c_int, c_float, c_void_p]\n",
        "\n",
        "    def _devptr(self, t: torch.Tensor):\n",
        "        assert t.is_cuda and t.is_contiguous() and t.dtype==torch.float32\n",
        "        return c_void_p(t.data_ptr())\n",
        "\n",
        "    def relu(self, x):\n",
        "        y = torch.empty_like(x); self.lib.relu_cuda(self._devptr(x), self._devptr(y), x.numel(), c_void_p(0)); return y\n",
        "    def sigmoid(self, x):\n",
        "        y = torch.empty_like(x); self.lib.sigmoid_cuda(self._devptr(x), self._devptr(y), x.numel(), c_void_p(0)); return y\n",
        "    def gelu(self, x):\n",
        "        y = torch.empty_like(x); self.lib.gelu_cuda(self._devptr(x), self._devptr(y), x.numel(), c_void_p(0)); return y\n",
        "    def swish(self, x):\n",
        "        y = torch.empty_like(x); self.lib.swish_cuda(self._devptr(x), self._devptr(y), x.numel(), c_void_p(0)); return y\n",
        "\n",
        "    def layernorm(self, x, gamma, beta, eps=1e-5):\n",
        "        cols = x.shape[-1]; rows = x.numel() // cols\n",
        "        x2 = x.view(rows, cols).contiguous(); y2 = torch.empty_like(x2)\n",
        "        self.lib.layernorm_cuda(self._devptr(x2), self._devptr(y2), self._devptr(gamma), self._devptr(beta), rows, cols, c_float(eps), c_void_p(0))\n",
        "        return y2.view_as(x)\n",
        "\n",
        "    def softmax(self, x):\n",
        "        cols = x.shape[-1]; rows = x.numel() // cols\n",
        "        x2 = x.view(rows, cols).contiguous(); y2 = torch.empty_like(x2)\n",
        "        self.lib.softmax_cuda(self._devptr(x2), self._devptr(y2), rows, cols, c_void_p(0))\n",
        "        return y2.view_as(x)\n",
        "\n",
        "    def evonorm_b0(self, x, v, groups=32, eps=1e-5):\n",
        "        N, C, H, W = x.shape; y = torch.empty_like(x)\n",
        "        self.lib.evonorm_b0_cuda(self._devptr(x), self._devptr(v), self._devptr(y), N, C, H, W, groups, c_float(eps), c_void_p(0))\n",
        "        return y\n",
        "\n",
        "    def layernorm_gelu_fused(self, x, g, b, eps=1e-5):\n",
        "        cols = x.shape[-1]; rows = x.numel() // cols\n",
        "        x2 = x.view(rows, cols).contiguous(); y2 = torch.empty_like(x2)\n",
        "        self.lib.layernorm_gelu_fused_cuda(self._devptr(x2), self._devptr(y2), self._devptr(g), self._devptr(b), rows, cols, c_float(eps), c_void_p(0))\n",
        "        return y2.view_as(x)\n",
        "def time_function(fn: Callable, warmup: int = 20, iters: int = 100):\n",
        "    \"\"\"\n",
        "    Run fn() `iters` times and measure:\n",
        "      - mean time in ms\n",
        "      - stddev in ms\n",
        "      - peak GPU memory in MB\n",
        "    \"\"\"\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Warmup\n",
        "        for _ in range(warmup):\n",
        "            fn()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "        # Timed runs\n",
        "        times = []\n",
        "        for _ in range(iters):\n",
        "            s = torch.cuda.Event(True)\n",
        "            e = torch.cuda.Event(True)\n",
        "            s.record()\n",
        "            fn()\n",
        "            e.record()\n",
        "            torch.cuda.synchronize()\n",
        "            times.append(s.elapsed_time(e))\n",
        "\n",
        "    mean_ms = float(np.mean(times))\n",
        "    std_ms = float(np.std(times))\n",
        "    peak_mem_mb = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
        "\n",
        "    return mean_ms, std_ms, peak_mem_mb\n",
        "\n",
        "\n",
        "def benchmark_operation(name, cuda_fn, triton_fn, torch_fn, x, *args, warmup=20, iters=100):\n",
        "    \"\"\"\n",
        "    Benchmarks one operation across:\n",
        "      - PyTorch (reference)\n",
        "      - CUDA (custom kernels)\n",
        "      - Triton\n",
        "\n",
        "    Returns a dict with:\n",
        "      - time (ms), std, speedup vs PyTorch\n",
        "      - peak_mem_mb for each backend\n",
        "    \"\"\"\n",
        "    print(f\"ðŸ”¬ {name} | shape={x.shape}\")\n",
        "    res = {\n",
        "        'operation': name,\n",
        "        'input_shape': str(x.shape),\n",
        "    }\n",
        "\n",
        "    # ----- PyTorch baseline -----\n",
        "    t_ms, t_std, t_mem = time_function(\n",
        "        (lambda: torch_fn(x, *args)) if args else (lambda: torch_fn(x)),\n",
        "        warmup,\n",
        "        iters,\n",
        "    )\n",
        "    res['pytorch_ms'] = t_ms\n",
        "    res['pytorch_std'] = t_std\n",
        "    res['pytorch_mem_mb'] = t_mem\n",
        "\n",
        "    # ----- CUDA backend -----\n",
        "    try:\n",
        "        c_ms, c_std, c_mem = time_function(\n",
        "            (lambda: cuda_fn(x, *args)) if args else (lambda: cuda_fn(x)),\n",
        "            warmup,\n",
        "            iters,\n",
        "        )\n",
        "        res['cuda_ms'] = c_ms\n",
        "        res['cuda_std'] = c_std\n",
        "        res['cuda_mem_mb'] = c_mem\n",
        "        res['cuda_speedup'] = t_ms / c_ms\n",
        "    except Exception as e:\n",
        "        print(\"   CUDA failed:\", e)\n",
        "        res['cuda_ms'] = float('nan')\n",
        "        res['cuda_std'] = float('nan')\n",
        "        res['cuda_mem_mb'] = float('nan')\n",
        "        res['cuda_speedup'] = float('nan')\n",
        "\n",
        "    # ----- Triton backend -----\n",
        "    try:\n",
        "        tr_ms, tr_std, tr_mem = time_function(\n",
        "            (lambda: triton_fn(x, *args)) if args else (lambda: triton_fn(x)),\n",
        "            warmup,\n",
        "            iters,\n",
        "        )\n",
        "        res['triton_ms'] = tr_ms\n",
        "        res['triton_std'] = tr_std\n",
        "        res['triton_mem_mb'] = tr_mem\n",
        "        res['triton_speedup'] = t_ms / tr_ms\n",
        "    except Exception as e:\n",
        "        print(\"   Triton failed:\", e)\n",
        "        res['triton_ms'] = float('nan')\n",
        "        res['triton_std'] = float('nan')\n",
        "        res['triton_mem_mb'] = float('nan')\n",
        "        res['triton_speedup'] = float('nan')\n",
        "\n",
        "    print(\n",
        "        f\"   PyTorch {t_ms:.3f} ms (mem {t_mem:.1f} MB) | \"\n",
        "        f\"CUDA {res['cuda_ms']:.3f} ms (mem {res['cuda_mem_mb']:.1f} MB) | \"\n",
        "        f\"Triton {res['triton_ms']:.3f} ms (mem {res['triton_mem_mb']:.1f} MB)\"\n",
        "    )\n",
        "    return res\n",
        "\n",
        "\n",
        "def run_full_benchmark_suite(cuda_kernels: CUDAKernels):\n",
        "    device = torch.device('cuda'); results = []\n",
        "    print(\"\\n=== ELEMENT-WISE ===\")\n",
        "    for shape in [(1024,1024),(2048,2048),(4096,4096)]:\n",
        "        x = torch.randn(shape, device=device).float().contiguous()\n",
        "        results.append(benchmark_operation(f\"ReLU_{shape[0]}x{shape[1]}\", cuda_kernels.relu, lambda x:F.relu(x), lambda x:F.relu(x), x))\n",
        "        results.append(benchmark_operation(f\"Sigmoid_{shape[0]}x{shape[1]}\", cuda_kernels.sigmoid, lambda x:torch.sigmoid(x), lambda x:torch.sigmoid(x), x))\n",
        "        results.append(benchmark_operation(f\"GELU_{shape[0]}x{shape[1]}\", cuda_kernels.gelu, gelu_triton, lambda x:F.gelu(x, approximate='tanh'), x))\n",
        "        results.append(benchmark_operation(f\"Swish_{shape[0]}x{shape[1]}\", cuda_kernels.swish, swish_triton, lambda x:x*torch.sigmoid(x), x))\n",
        "\n",
        "    print(\"\\n=== NORMALIZATION ===\")\n",
        "    for batch in [32,64,128]:\n",
        "        for dim in [256,512,1024]:\n",
        "            x = torch.randn(batch, dim, device=device).float().contiguous()\n",
        "            g = torch.ones(dim, device=device).float().contiguous()\n",
        "            b = torch.zeros(dim, device=device).float().contiguous()\n",
        "            results.append(benchmark_operation(f\"LayerNorm_B{batch}_D{dim}\",\n",
        "                                               lambda x,g,b: cuda_kernels.layernorm(x,g,b),\n",
        "                                               lambda x,g,b: layernorm_triton(x,g,b),\n",
        "                                               lambda x,g,b: F.layer_norm(x,(dim,),g,b), x, g, b))\n",
        "\n",
        "    print(\"\\n=== SOFTMAX ===\")\n",
        "    for batch in [16,64,128]:\n",
        "        for dim in [128,512,1024]:\n",
        "            x = torch.randn(batch, dim, device=device).float().contiguous()\n",
        "            results.append(benchmark_operation(f\"Softmax_B{batch}_D{dim}\", cuda_kernels.softmax, softmax_triton_lastdim, lambda x:F.softmax(x, dim=-1), x))\n",
        "\n",
        "    print(\"\\n=== FUSED ===\")\n",
        "    for batch in [32,64,128]:\n",
        "        for dim in [256,512]:\n",
        "            x = torch.randn(batch, dim, device=device).float().contiguous()\n",
        "            g = torch.ones(dim, device=device).float().contiguous()\n",
        "            b = torch.zeros(dim, device=device).float().contiguous()\n",
        "            results.append(benchmark_operation(f\"LN+GELU_Fused_B{batch}_D{dim}\",\n",
        "                                               lambda x,g,b: cuda_kernels.layernorm_gelu_fused(x,g,b),\n",
        "                                               lambda x,g,b: layernorm_gelu_fused_triton(x,g,b),\n",
        "                                               lambda x,g,b: F.gelu(F.layer_norm(x,(dim,),g,b), approximate='tanh'),\n",
        "                                               x,g,b))\n",
        "\n",
        "    print(\"\\n=== EVONORM-B0 ===\")\n",
        "    for batch in [16,32,64]:\n",
        "        for C in [32,64]:\n",
        "            for HW in [(28,28),(14,14)]:\n",
        "                x = torch.randn(batch, C, HW[0], HW[1], device=device).float().contiguous()\n",
        "                v = torch.randn(C, device=device).float().contiguous()\n",
        "                results.append(benchmark_operation(f\"EvoNorm_B{batch}_C{C}_HW{HW[0]}\",\n",
        "                                                   lambda x,v: cuda_kernels.evonorm_b0(x,v,groups=32),\n",
        "                                                   lambda x,v: evonorm_b0_triton_fused(x,v,groups=32),\n",
        "                                                   lambda x,v: evonorm_b0_reference(x,v,groups=32),\n",
        "                                                   x, v))\n",
        "    return pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8afa895d",
      "metadata": {
        "id": "8afa895d"
      },
      "source": [
        "## 5ï¸âƒ£ Run the full comparison and save reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86f1f08e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86f1f08e",
        "outputId": "2c2a79d0-dc6e-47ad-929d-36ee65cc27d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded CUDA library: ./cuda_kernels.so\n",
            "\n",
            "=== ELEMENT-WISE ===\n",
            "ðŸ”¬ ReLU_1024x1024 | shape=torch.Size([1024, 1024])\n",
            "   PyTorch 0.051 ms (mem 159.3 MB) | CUDA 0.053 ms (mem 159.3 MB) | Triton 0.050 ms (mem 159.3 MB)\n",
            "ðŸ”¬ Sigmoid_1024x1024 | shape=torch.Size([1024, 1024])\n",
            "   PyTorch 0.048 ms (mem 159.3 MB) | CUDA 0.225 ms (mem 159.3 MB) | Triton 0.048 ms (mem 159.3 MB)\n",
            "ðŸ”¬ GELU_1024x1024 | shape=torch.Size([1024, 1024])\n",
            "   PyTorch 0.048 ms (mem 159.3 MB) | CUDA 0.266 ms (mem 159.3 MB) | Triton 0.079 ms (mem 159.3 MB)\n",
            "ðŸ”¬ Swish_1024x1024 | shape=torch.Size([1024, 1024])\n",
            "   PyTorch 0.102 ms (mem 163.3 MB) | CUDA 0.225 ms (mem 159.3 MB) | Triton 0.084 ms (mem 159.3 MB)\n",
            "ðŸ”¬ ReLU_2048x2048 | shape=torch.Size([2048, 2048])\n",
            "   PyTorch 0.153 ms (mem 182.8 MB) | CUDA 0.158 ms (mem 182.8 MB) | Triton 0.155 ms (mem 182.8 MB)\n",
            "ðŸ”¬ Sigmoid_2048x2048 | shape=torch.Size([2048, 2048])\n",
            "   PyTorch 0.153 ms (mem 182.8 MB) | CUDA 0.815 ms (mem 182.8 MB) | Triton 0.154 ms (mem 182.8 MB)\n",
            "ðŸ”¬ GELU_2048x2048 | shape=torch.Size([2048, 2048])\n",
            "   PyTorch 0.155 ms (mem 182.8 MB) | CUDA 0.453 ms (mem 182.8 MB) | Triton 0.187 ms (mem 182.8 MB)\n",
            "ðŸ”¬ Swish_2048x2048 | shape=torch.Size([2048, 2048])\n",
            "   PyTorch 0.368 ms (mem 198.8 MB) | CUDA 0.369 ms (mem 182.8 MB) | Triton 0.223 ms (mem 182.8 MB)\n",
            "ðŸ”¬ ReLU_4096x4096 | shape=torch.Size([4096, 4096])\n",
            "   PyTorch 0.601 ms (mem 278.8 MB) | CUDA 0.562 ms (mem 278.8 MB) | Triton 0.597 ms (mem 278.8 MB)\n",
            "ðŸ”¬ Sigmoid_4096x4096 | shape=torch.Size([4096, 4096])\n",
            "   PyTorch 0.590 ms (mem 278.8 MB) | CUDA 1.341 ms (mem 278.8 MB) | Triton 0.591 ms (mem 278.8 MB)\n",
            "ðŸ”¬ GELU_4096x4096 | shape=torch.Size([4096, 4096])\n",
            "   PyTorch 0.588 ms (mem 278.8 MB) | CUDA 1.591 ms (mem 278.8 MB) | Triton 0.621 ms (mem 278.8 MB)\n",
            "ðŸ”¬ Swish_4096x4096 | shape=torch.Size([4096, 4096])\n",
            "   PyTorch 1.425 ms (mem 342.8 MB) | CUDA 1.336 ms (mem 278.8 MB) | Triton 0.624 ms (mem 278.8 MB)\n",
            "\n",
            "=== NORMALIZATION ===\n",
            "ðŸ”¬ LayerNorm_B32_D256 | shape=torch.Size([32, 256])\n",
            "   PyTorch 0.034 ms (mem 150.9 MB) | CUDA 0.042 ms (mem 150.9 MB) | Triton 0.087 ms (mem 150.9 MB)\n",
            "ðŸ”¬ LayerNorm_B32_D512 | shape=torch.Size([32, 512])\n",
            "   PyTorch 0.035 ms (mem 151.0 MB) | CUDA 0.039 ms (mem 151.0 MB) | Triton 0.088 ms (mem 151.0 MB)\n",
            "ðŸ”¬ LayerNorm_B32_D1024 | shape=torch.Size([32, 1024])\n",
            "   PyTorch 0.032 ms (mem 151.1 MB) | CUDA 0.039 ms (mem 151.1 MB) | Triton 0.081 ms (mem 151.1 MB)\n",
            "ðŸ”¬ LayerNorm_B64_D256 | shape=torch.Size([64, 256])\n",
            "   PyTorch 0.032 ms (mem 151.0 MB) | CUDA 0.039 ms (mem 151.0 MB) | Triton 0.081 ms (mem 151.0 MB)\n",
            "ðŸ”¬ LayerNorm_B64_D512 | shape=torch.Size([64, 512])\n",
            "   PyTorch 0.033 ms (mem 151.1 MB) | CUDA 0.040 ms (mem 151.1 MB) | Triton 0.082 ms (mem 151.1 MB)\n",
            "ðŸ”¬ LayerNorm_B64_D1024 | shape=torch.Size([64, 1024])\n",
            "   PyTorch 0.033 ms (mem 151.3 MB) | CUDA 0.039 ms (mem 151.3 MB) | Triton 0.086 ms (mem 151.3 MB)\n",
            "ðŸ”¬ LayerNorm_B128_D256 | shape=torch.Size([128, 256])\n",
            "   PyTorch 0.034 ms (mem 151.1 MB) | CUDA 0.039 ms (mem 151.1 MB) | Triton 0.082 ms (mem 151.1 MB)\n",
            "ðŸ”¬ LayerNorm_B128_D512 | shape=torch.Size([128, 512])\n",
            "   PyTorch 0.033 ms (mem 151.3 MB) | CUDA 0.039 ms (mem 151.3 MB) | Triton 0.081 ms (mem 151.3 MB)\n",
            "ðŸ”¬ LayerNorm_B128_D1024 | shape=torch.Size([128, 1024])\n",
            "   PyTorch 0.032 ms (mem 151.8 MB) | CUDA 0.038 ms (mem 151.8 MB) | Triton 0.146 ms (mem 151.8 MB)\n",
            "\n",
            "=== SOFTMAX ===\n",
            "ðŸ”¬ Softmax_B16_D128 | shape=torch.Size([16, 128])\n",
            "   PyTorch 0.054 ms (mem 150.9 MB) | CUDA 0.051 ms (mem 150.9 MB) | Triton 0.095 ms (mem 150.9 MB)\n",
            "ðŸ”¬ Softmax_B16_D512 | shape=torch.Size([16, 512])\n",
            "   PyTorch 0.023 ms (mem 150.9 MB) | CUDA 0.036 ms (mem 150.9 MB) | Triton 0.068 ms (mem 150.9 MB)\n",
            "ðŸ”¬ Softmax_B16_D1024 | shape=torch.Size([16, 1024])\n",
            "   PyTorch 0.024 ms (mem 151.0 MB) | CUDA 0.036 ms (mem 151.0 MB) | Triton 0.070 ms (mem 151.0 MB)\n",
            "ðŸ”¬ Softmax_B64_D128 | shape=torch.Size([64, 128])\n",
            "   PyTorch 0.022 ms (mem 150.9 MB) | CUDA 0.036 ms (mem 150.9 MB) | Triton 0.070 ms (mem 150.9 MB)\n",
            "ðŸ”¬ Softmax_B64_D512 | shape=torch.Size([64, 512])\n",
            "   PyTorch 0.025 ms (mem 151.1 MB) | CUDA 0.037 ms (mem 151.1 MB) | Triton 0.071 ms (mem 151.1 MB)\n",
            "ðŸ”¬ Softmax_B64_D1024 | shape=torch.Size([64, 1024])\n",
            "   PyTorch 0.022 ms (mem 151.3 MB) | CUDA 0.036 ms (mem 151.3 MB) | Triton 0.071 ms (mem 151.3 MB)\n",
            "ðŸ”¬ Softmax_B128_D128 | shape=torch.Size([128, 128])\n",
            "   PyTorch 0.023 ms (mem 151.0 MB) | CUDA 0.035 ms (mem 151.0 MB) | Triton 0.074 ms (mem 151.0 MB)\n",
            "ðŸ”¬ Softmax_B128_D512 | shape=torch.Size([128, 512])\n",
            "   PyTorch 0.022 ms (mem 151.3 MB) | CUDA 0.037 ms (mem 151.3 MB) | Triton 0.071 ms (mem 151.3 MB)\n",
            "ðŸ”¬ Softmax_B128_D1024 | shape=torch.Size([128, 1024])\n",
            "   PyTorch 0.023 ms (mem 151.8 MB) | CUDA 0.036 ms (mem 151.8 MB) | Triton 0.073 ms (mem 151.8 MB)\n",
            "\n",
            "=== FUSED ===\n",
            "ðŸ”¬ LN+GELU_Fused_B32_D256 | shape=torch.Size([32, 256])\n",
            "   PyTorch 0.048 ms (mem 150.9 MB) | CUDA 0.051 ms (mem 150.9 MB) | Triton 0.089 ms (mem 150.9 MB)\n",
            "ðŸ”¬ LN+GELU_Fused_B32_D512 | shape=torch.Size([32, 512])\n",
            "   PyTorch 0.046 ms (mem 151.0 MB) | CUDA 0.041 ms (mem 151.0 MB) | Triton 0.091 ms (mem 151.0 MB)\n",
            "ðŸ”¬ LN+GELU_Fused_B64_D256 | shape=torch.Size([64, 256])\n",
            "   PyTorch 0.051 ms (mem 151.0 MB) | CUDA 0.043 ms (mem 151.0 MB) | Triton 0.085 ms (mem 151.0 MB)\n",
            "ðŸ”¬ LN+GELU_Fused_B64_D512 | shape=torch.Size([64, 512])\n",
            "   PyTorch 0.045 ms (mem 151.2 MB) | CUDA 0.047 ms (mem 151.1 MB) | Triton 0.083 ms (mem 151.1 MB)\n",
            "ðŸ”¬ LN+GELU_Fused_B128_D256 | shape=torch.Size([128, 256])\n",
            "   PyTorch 0.045 ms (mem 151.2 MB) | CUDA 0.039 ms (mem 151.1 MB) | Triton 0.082 ms (mem 151.1 MB)\n",
            "ðŸ”¬ LN+GELU_Fused_B128_D512 | shape=torch.Size([128, 512])\n",
            "   PyTorch 0.044 ms (mem 151.6 MB) | CUDA 0.039 ms (mem 151.3 MB) | Triton 0.081 ms (mem 151.3 MB)\n",
            "\n",
            "=== EVONORM-B0 ===\n",
            "ðŸ”¬ EvoNorm_B16_C32_HW28 | shape=torch.Size([16, 32, 28, 28])\n",
            "   Triton failed: at 7:11:\n",
            "def evonorm_b0_fused_kernel(x_ptr, v_ptr, y_ptr, N, C, H, W, groups, eps: tl.constexpr, BLOCK: tl.constexpr):\n",
            "    pid = tl.program_id(0)\n",
            "    g = pid % groups; n = pid // groups\n",
            "    Cg = C // groups; HW = H * W; group_elems = Cg * HW\n",
            "    base = n * (C * HW) + g * (Cg * HW)\n",
            "    acc1 = tl.zeros([1], dtype=tl.float32); acc2 = tl.zeros([1], dtype=tl.float32)\n",
            "    offs = tl.arange(0, BLOCK)\n",
            "           ^\n",
            "   PyTorch 0.133 ms (mem 156.1 MB) | CUDA 0.056 ms (mem 154.3 MB) | Triton nan ms (mem nan MB)\n",
            "ðŸ”¬ EvoNorm_B16_C32_HW14 | shape=torch.Size([16, 32, 14, 14])\n",
            "   Triton failed: at 7:11:\n",
            "def evonorm_b0_fused_kernel(x_ptr, v_ptr, y_ptr, N, C, H, W, groups, eps: tl.constexpr, BLOCK: tl.constexpr):\n",
            "    pid = tl.program_id(0)\n",
            "    g = pid % groups; n = pid // groups\n",
            "    Cg = C // groups; HW = H * W; group_elems = Cg * HW\n",
            "    base = n * (C * HW) + g * (Cg * HW)\n",
            "    acc1 = tl.zeros([1], dtype=tl.float32); acc2 = tl.zeros([1], dtype=tl.float32)\n",
            "    offs = tl.arange(0, BLOCK)\n",
            "           ^\n",
            "   PyTorch 0.134 ms (mem 152.0 MB) | CUDA 0.034 ms (mem 151.6 MB) | Triton nan ms (mem nan MB)\n",
            "ðŸ”¬ EvoNorm_B16_C64_HW28 | shape=torch.Size([16, 64, 28, 28])\n",
            "   PyTorch 0.241 ms (mem 164.5 MB) | CUDA 0.091 ms (mem 158.4 MB) | Triton 0.091 ms (mem 158.4 MB)\n",
            "ðŸ”¬ EvoNorm_B16_C64_HW14 | shape=torch.Size([16, 64, 14, 14])\n",
            "   Triton failed: at 7:11:\n",
            "def evonorm_b0_fused_kernel(x_ptr, v_ptr, y_ptr, N, C, H, W, groups, eps: tl.constexpr, BLOCK: tl.constexpr):\n",
            "    pid = tl.program_id(0)\n",
            "    g = pid % groups; n = pid // groups\n",
            "    Cg = C // groups; HW = H * W; group_elems = Cg * HW\n",
            "    base = n * (C * HW) + g * (Cg * HW)\n",
            "    acc1 = tl.zeros([1], dtype=tl.float32); acc2 = tl.zeros([1], dtype=tl.float32)\n",
            "    offs = tl.arange(0, BLOCK)\n",
            "           ^\n",
            "   PyTorch 0.156 ms (mem 153.9 MB) | CUDA 0.042 ms (mem 152.4 MB) | Triton nan ms (mem nan MB)\n",
            "ðŸ”¬ EvoNorm_B32_C32_HW28 | shape=torch.Size([32, 32, 28, 28])\n",
            "   Triton failed: at 7:11:\n",
            "def evonorm_b0_fused_kernel(x_ptr, v_ptr, y_ptr, N, C, H, W, groups, eps: tl.constexpr, BLOCK: tl.constexpr):\n",
            "    pid = tl.program_id(0)\n",
            "    g = pid % groups; n = pid // groups\n",
            "    Cg = C // groups; HW = H * W; group_elems = Cg * HW\n",
            "    base = n * (C * HW) + g * (Cg * HW)\n",
            "    acc1 = tl.zeros([1], dtype=tl.float32); acc2 = tl.zeros([1], dtype=tl.float32)\n",
            "    offs = tl.arange(0, BLOCK)\n",
            "           ^\n",
            "   PyTorch 0.255 ms (mem 161.5 MB) | CUDA 0.093 ms (mem 158.4 MB) | Triton nan ms (mem nan MB)\n",
            "ðŸ”¬ EvoNorm_B32_C32_HW14 | shape=torch.Size([32, 32, 14, 14])\n",
            "   Triton failed: at 7:11:\n",
            "def evonorm_b0_fused_kernel(x_ptr, v_ptr, y_ptr, N, C, H, W, groups, eps: tl.constexpr, BLOCK: tl.constexpr):\n",
            "    pid = tl.program_id(0)\n",
            "    g = pid % groups; n = pid // groups\n",
            "    Cg = C // groups; HW = H * W; group_elems = Cg * HW\n",
            "    base = n * (C * HW) + g * (Cg * HW)\n",
            "    acc1 = tl.zeros([1], dtype=tl.float32); acc2 = tl.zeros([1], dtype=tl.float32)\n",
            "    offs = tl.arange(0, BLOCK)\n",
            "           ^\n",
            "   PyTorch 0.134 ms (mem 153.1 MB) | CUDA 0.046 ms (mem 152.4 MB) | Triton nan ms (mem nan MB)\n",
            "ðŸ”¬ EvoNorm_B32_C64_HW28 | shape=torch.Size([32, 64, 28, 28])\n",
            "   PyTorch 0.392 ms (mem 175.3 MB) | CUDA 0.163 ms (mem 163.1 MB) | Triton 0.123 ms (mem 163.1 MB)\n",
            "ðŸ”¬ EvoNorm_B32_C64_HW14 | shape=torch.Size([32, 64, 14, 14])\n",
            "   Triton failed: at 7:11:\n",
            "def evonorm_b0_fused_kernel(x_ptr, v_ptr, y_ptr, N, C, H, W, groups, eps: tl.constexpr, BLOCK: tl.constexpr):\n",
            "    pid = tl.program_id(0)\n",
            "    g = pid % groups; n = pid // groups\n",
            "    Cg = C // groups; HW = H * W; group_elems = Cg * HW\n",
            "    base = n * (C * HW) + g * (Cg * HW)\n",
            "    acc1 = tl.zeros([1], dtype=tl.float32); acc2 = tl.zeros([1], dtype=tl.float32)\n",
            "    offs = tl.arange(0, BLOCK)\n",
            "           ^\n",
            "   PyTorch 0.153 ms (mem 157.8 MB) | CUDA 0.062 ms (mem 154.3 MB) | Triton nan ms (mem nan MB)\n",
            "ðŸ”¬ EvoNorm_B64_C32_HW28 | shape=torch.Size([64, 32, 28, 28])\n",
            "   Triton failed: at 7:11:\n",
            "def evonorm_b0_fused_kernel(x_ptr, v_ptr, y_ptr, N, C, H, W, groups, eps: tl.constexpr, BLOCK: tl.constexpr):\n",
            "    pid = tl.program_id(0)\n",
            "    g = pid % groups; n = pid // groups\n",
            "    Cg = C // groups; HW = H * W; group_elems = Cg * HW\n",
            "    base = n * (C * HW) + g * (Cg * HW)\n",
            "    acc1 = tl.zeros([1], dtype=tl.float32); acc2 = tl.zeros([1], dtype=tl.float32)\n",
            "    offs = tl.arange(0, BLOCK)\n",
            "           ^\n",
            "   PyTorch 0.341 ms (mem 169.2 MB) | CUDA 0.174 ms (mem 163.1 MB) | Triton nan ms (mem nan MB)\n",
            "ðŸ”¬ EvoNorm_B64_C32_HW14 | shape=torch.Size([64, 32, 14, 14])\n",
            "   Triton failed: at 7:11:\n",
            "def evonorm_b0_fused_kernel(x_ptr, v_ptr, y_ptr, N, C, H, W, groups, eps: tl.constexpr, BLOCK: tl.constexpr):\n",
            "    pid = tl.program_id(0)\n",
            "    g = pid % groups; n = pid // groups\n",
            "    Cg = C // groups; HW = H * W; group_elems = Cg * HW\n",
            "    base = n * (C * HW) + g * (Cg * HW)\n",
            "    acc1 = tl.zeros([1], dtype=tl.float32); acc2 = tl.zeros([1], dtype=tl.float32)\n",
            "    offs = tl.arange(0, BLOCK)\n",
            "           ^\n",
            "   PyTorch 0.147 ms (mem 156.1 MB) | CUDA 0.073 ms (mem 154.3 MB) | Triton nan ms (mem nan MB)\n",
            "ðŸ”¬ EvoNorm_B64_C64_HW28 | shape=torch.Size([64, 64, 28, 28])\n",
            "   PyTorch 0.722 ms (mem 199.8 MB) | CUDA 0.300 ms (mem 175.3 MB) | Triton 0.225 ms (mem 175.3 MB)\n",
            "ðŸ”¬ EvoNorm_B64_C64_HW14 | shape=torch.Size([64, 64, 14, 14])\n",
            "   Triton failed: at 7:11:\n",
            "def evonorm_b0_fused_kernel(x_ptr, v_ptr, y_ptr, N, C, H, W, groups, eps: tl.constexpr, BLOCK: tl.constexpr):\n",
            "    pid = tl.program_id(0)\n",
            "    g = pid % groups; n = pid // groups\n",
            "    Cg = C // groups; HW = H * W; group_elems = Cg * HW\n",
            "    base = n * (C * HW) + g * (Cg * HW)\n",
            "    acc1 = tl.zeros([1], dtype=tl.float32); acc2 = tl.zeros([1], dtype=tl.float32)\n",
            "    offs = tl.arange(0, BLOCK)\n",
            "           ^\n",
            "   PyTorch 0.331 ms (mem 164.5 MB) | CUDA 0.124 ms (mem 158.4 MB) | Triton nan ms (mem nan MB)\n",
            "\n",
            "Saving CSV to reports/cuda_vs_triton/full_comparison.csv\n",
            "           operation               input_shape  pytorch_ms  pytorch_std  \\\n",
            "0     ReLU_1024x1024  torch.Size([1024, 1024])    0.051126     0.003449   \n",
            "1  Sigmoid_1024x1024  torch.Size([1024, 1024])    0.048349     0.002697   \n",
            "2     GELU_1024x1024  torch.Size([1024, 1024])    0.047845     0.002437   \n",
            "3    Swish_1024x1024  torch.Size([1024, 1024])    0.102477     0.002376   \n",
            "4     ReLU_2048x2048  torch.Size([2048, 2048])    0.153413     0.002371   \n",
            "5  Sigmoid_2048x2048  torch.Size([2048, 2048])    0.152881     0.002517   \n",
            "6     GELU_2048x2048  torch.Size([2048, 2048])    0.155360     0.003570   \n",
            "7    Swish_2048x2048  torch.Size([2048, 2048])    0.367900     0.004356   \n",
            "8     ReLU_4096x4096  torch.Size([4096, 4096])    0.601404     0.018581   \n",
            "9  Sigmoid_4096x4096  torch.Size([4096, 4096])    0.590132     0.004603   \n",
            "\n",
            "   pytorch_mem_mb   cuda_ms  cuda_std  cuda_mem_mb  cuda_speedup  triton_ms  \\\n",
            "0      159.262695  0.053160  0.002598   159.262695      0.961728   0.049521   \n",
            "1      159.262695  0.225028  0.003711   159.262695      0.214857   0.047989   \n",
            "2      159.262695  0.265537  0.006879   159.262695      0.180181   0.079393   \n",
            "3      163.262695  0.224604  0.010020   159.262695      0.456257   0.084143   \n",
            "4      182.833984  0.157955  0.003991   182.833984      0.971245   0.154529   \n",
            "5      182.833984  0.815149  0.014170   182.833984      0.187550   0.153675   \n",
            "6      182.833984  0.453180  0.003654   182.833984      0.342823   0.186972   \n",
            "7      198.833984  0.368501  0.004597   182.833984      0.998371   0.223236   \n",
            "8      278.833984  0.562369  0.008557   278.833984      1.069412   0.597419   \n",
            "9      278.833984  1.340677  0.022755   278.833984      0.440175   0.590903   \n",
            "\n",
            "   triton_std  triton_mem_mb  triton_speedup  \n",
            "0    0.003387     159.262695        1.032400  \n",
            "1    0.002193     159.262695        1.007488  \n",
            "2    0.009165     159.262695        0.602630  \n",
            "3    0.016875     159.262695        1.217900  \n",
            "4    0.006687     182.833984        0.992779  \n",
            "5    0.002913     182.833984        0.994838  \n",
            "6    0.011052     182.833984        0.830926  \n",
            "7    0.058756     182.833984        1.648037  \n",
            "8    0.009339     278.833984        1.006670  \n",
            "9    0.006807     278.833984        0.998695  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "cuda_kernels = CUDAKernels('./cuda_kernels.so')\n",
        "if cuda_kernels.lib is None:\n",
        "    raise SystemExit(\"CUDA library missing. Compile step above must succeed.\")\n",
        "\n",
        "df_results = run_full_benchmark_suite(cuda_kernels)\n",
        "print(\"\\nSaving CSV to reports/cuda_vs_triton/full_comparison.csv\")\n",
        "os.makedirs('reports/cuda_vs_triton', exist_ok=True)\n",
        "df_results.to_csv('reports/cuda_vs_triton/full_comparison.csv', index=False)\n",
        "\n",
        "# Quick preview\n",
        "print(df_results.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d00278e",
      "metadata": {
        "id": "5d00278e"
      },
      "source": [
        "## 6ï¸âƒ£ Quick visual (scatter of CUDA vs Triton times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40ce06b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "40ce06b5",
        "outputId": "cbc3e05a-32a1-4806-9c55-24b36937717e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved plot to reports/cuda_vs_triton/cuda_vs_triton_scatter.png\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "valid = df_results.dropna(subset=['cuda_ms','triton_ms'])\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(valid['cuda_ms'], valid['triton_ms'])\n",
        "m = max(valid['cuda_ms'].max(), valid['triton_ms'].max())\n",
        "plt.plot([0,m],[0,m],'--')\n",
        "plt.xlabel('CUDA Time (ms)'); plt.ylabel('Triton Time (ms)')\n",
        "plt.title('CUDA vs Triton Execution Time')\n",
        "plt.savefig('reports/cuda_vs_triton/cuda_vs_triton_scatter.png', dpi=150, bbox_inches='tight')\n",
        "print(\"Saved plot to reports/cuda_vs_triton/cuda_vs_triton_scatter.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5qQD-4Bwl0r-",
      "metadata": {
        "id": "5qQD-4Bwl0r-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bf3713f2",
      "metadata": {
        "id": "bf3713f2"
      },
      "source": [
        "## Report Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b43f0669",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "b43f0669",
        "outputId": "b1c2f4ba-5f1b-47d7-c4dd-68a349d54030"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"gpu\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Tesla T4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cuda_available\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sections\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-731e31c8-bec8-4fba-a41c-7d7a79c308cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gpu</th>\n",
              "      <th>cuda_available</th>\n",
              "      <th>sections</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tesla T4</td>\n",
              "      <td>True</td>\n",
              "      <td>[GPU check, Installs, Kernels, LayerNorm, Veri...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-731e31c8-bec8-4fba-a41c-7d7a79c308cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-731e31c8-bec8-4fba-a41c-7d7a79c308cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-731e31c8-bec8-4fba-a41c-7d7a79c308cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_7079fc0b-73e4-4dff-aa5b-3e838ca8fbb7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7079fc0b-73e4-4dff-aa5b-3e838ca8fbb7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        gpu  cuda_available                                           sections\n",
              "0  Tesla T4            True  [GPU check, Installs, Kernels, LayerNorm, Veri..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: reports/demo_pack/summary.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "summary = {\n",
        "    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\",\n",
        "    \"cuda_available\": bool(torch.cuda.is_available()),\n",
        "    \"sections\": [\n",
        "        \"GPU check\", \"Installs\", \"Kernels\", \"LayerNorm\", \"Verification\",\n",
        "        \"EvoNorm-B0 fused\", \"Conv+EvoNorm epilogue\", \"CNN training\", \"Benchmarks\"\n",
        "    ]\n",
        "}\n",
        "df = pd.DataFrame([summary])\n",
        "display(df)\n",
        "os.makedirs('reports/demo_pack', exist_ok=True) # Ensure directory exists\n",
        "df.to_csv(\"reports/demo_pack/summary.csv\", index=False)\n",
        "print(\"âœ… Saved: reports/demo_pack/summary.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gwFL3nMXzWJw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwFL3nMXzWJw",
        "outputId": "a2c31354-8435-4d33-ae96-210d0fd49779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Benchmarking seq_len = 256 ...\n",
            "\n",
            "Benchmarking seq_len = 512 ...\n",
            "\n",
            "Benchmarking seq_len = 1024 ...\n",
            "\n",
            "===== Final Sequence Length Results =====\n",
            "   batch  seq_len  d_model  pytorch_ms\n",
            "0     32      256      512    0.289186\n",
            "1     32      512      512    1.539207\n",
            "2     32     1024      512    1.116900\n",
            "Saved â†’ profiling/benchmark_results/softmax_seq_lengths.csv\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# ðŸ“Œ Sequence-Length Benchmarks\n",
        "# Goal 2: Compare perf across seq_len = 256, 512, 1024\n",
        "# ================================\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "def benchmark_softmax_seq_lengths(device=\"cuda\"):\n",
        "    results = []\n",
        "    batch_size = 32\n",
        "    d_model = 512\n",
        "    seq_lengths = [256, 512, 1024]\n",
        "\n",
        "    for L in seq_lengths:\n",
        "        print(f\"\\nBenchmarking seq_len = {L} ...\")\n",
        "        x = torch.randn(batch_size, L, d_model, device=device)\n",
        "\n",
        "        # Reshape to [N, D] for row-wise softmax\n",
        "        x_2d = x.view(-1, d_model)\n",
        "\n",
        "        # --- PyTorch softmax ---\n",
        "        torch.cuda.synchronize()\n",
        "        t0 = time.perf_counter()\n",
        "        y_torch = torch.softmax(x_2d, dim=-1)\n",
        "        torch.cuda.synchronize()\n",
        "        torch_ms = (time.perf_counter() - t0) * 1e3\n",
        "\n",
        "        # --- Triton softmax (if you have softmax_triton) ---\n",
        "        # torch.cuda.synchronize()\n",
        "        # t0 = time.perf_counter()\n",
        "        # y_triton = softmax_triton(x_2d)\n",
        "        # torch.cuda.synchronize()\n",
        "        # triton_ms = (time.perf_counter() - t0) * 1e3\n",
        "\n",
        "        # max_diff = (y_torch - y_triton).abs().max().item()\n",
        "\n",
        "        results.append({\n",
        "            \"batch\": batch_size,\n",
        "            \"seq_len\": L,\n",
        "            \"d_model\": d_model,\n",
        "            \"pytorch_ms\": torch_ms,\n",
        "            # \"triton_ms\": triton_ms,\n",
        "            # \"speedup\": torch_ms / triton_ms,\n",
        "            # \"max_diff\": max_diff,\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    out_csv = \"profiling/benchmark_results/softmax_seq_lengths.csv\"\n",
        "    df.to_csv(out_csv, index=False)\n",
        "\n",
        "    print(\"\\n===== Final Sequence Length Results =====\")\n",
        "    print(df)\n",
        "    print(f\"Saved â†’ {out_csv}\")\n",
        "\n",
        "# Run the sequence length benchmark\n",
        "benchmark_softmax_seq_lengths()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
